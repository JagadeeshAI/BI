{
  "best_global_step": 16044,
  "best_metric": 0.4684361549497848,
  "best_model_checkpoint": "./hf_trainer_output/checkpoint-16044",
  "epoch": 84.0,
  "eval_steps": 500,
  "global_step": 16044,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05235602094240838,
      "grad_norm": 3.6724939346313477,
      "learning_rate": 0.0002998586387434555,
      "loss": 5.1168,
      "step": 10
    },
    {
      "epoch": 0.10471204188481675,
      "grad_norm": 4.37814474105835,
      "learning_rate": 0.0002997015706806282,
      "loss": 4.844,
      "step": 20
    },
    {
      "epoch": 0.15706806282722513,
      "grad_norm": 4.12861967086792,
      "learning_rate": 0.000299544502617801,
      "loss": 4.6865,
      "step": 30
    },
    {
      "epoch": 0.2094240837696335,
      "grad_norm": 4.347696781158447,
      "learning_rate": 0.0002993874345549738,
      "loss": 4.5595,
      "step": 40
    },
    {
      "epoch": 0.2617801047120419,
      "grad_norm": 4.817787170410156,
      "learning_rate": 0.0002992303664921466,
      "loss": 4.3609,
      "step": 50
    },
    {
      "epoch": 0.31413612565445026,
      "grad_norm": 5.045619010925293,
      "learning_rate": 0.00029907329842931936,
      "loss": 4.2289,
      "step": 60
    },
    {
      "epoch": 0.36649214659685864,
      "grad_norm": 5.236090660095215,
      "learning_rate": 0.00029891623036649214,
      "loss": 4.0664,
      "step": 70
    },
    {
      "epoch": 0.418848167539267,
      "grad_norm": 5.908888816833496,
      "learning_rate": 0.0002987591623036649,
      "loss": 3.9707,
      "step": 80
    },
    {
      "epoch": 0.4712041884816754,
      "grad_norm": 5.179912090301514,
      "learning_rate": 0.00029860209424083765,
      "loss": 3.7944,
      "step": 90
    },
    {
      "epoch": 0.5235602094240838,
      "grad_norm": 6.270510673522949,
      "learning_rate": 0.00029844502617801044,
      "loss": 3.6599,
      "step": 100
    },
    {
      "epoch": 0.5759162303664922,
      "grad_norm": 5.2612080574035645,
      "learning_rate": 0.0002982879581151832,
      "loss": 3.5594,
      "step": 110
    },
    {
      "epoch": 0.6282722513089005,
      "grad_norm": 5.340776443481445,
      "learning_rate": 0.000298130890052356,
      "loss": 3.5753,
      "step": 120
    },
    {
      "epoch": 0.680628272251309,
      "grad_norm": 6.566280364990234,
      "learning_rate": 0.0002979738219895288,
      "loss": 3.5038,
      "step": 130
    },
    {
      "epoch": 0.7329842931937173,
      "grad_norm": 6.359260559082031,
      "learning_rate": 0.00029781675392670157,
      "loss": 3.2819,
      "step": 140
    },
    {
      "epoch": 0.7853403141361257,
      "grad_norm": 6.5299248695373535,
      "learning_rate": 0.0002976596858638743,
      "loss": 3.2349,
      "step": 150
    },
    {
      "epoch": 0.837696335078534,
      "grad_norm": 6.304718017578125,
      "learning_rate": 0.0002975026178010471,
      "loss": 3.2827,
      "step": 160
    },
    {
      "epoch": 0.8900523560209425,
      "grad_norm": 6.990729331970215,
      "learning_rate": 0.00029734554973821986,
      "loss": 3.0977,
      "step": 170
    },
    {
      "epoch": 0.9424083769633508,
      "grad_norm": 7.930517673492432,
      "learning_rate": 0.00029718848167539265,
      "loss": 3.1889,
      "step": 180
    },
    {
      "epoch": 0.9947643979057592,
      "grad_norm": 5.449270725250244,
      "learning_rate": 0.00029703141361256543,
      "loss": 3.1298,
      "step": 190
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.36585365853658536,
      "eval_loss": 3.2345337867736816,
      "eval_runtime": 0.7217,
      "eval_samples_per_second": 1931.587,
      "eval_steps_per_second": 30.484,
      "step": 191
    },
    {
      "epoch": 1.0471204188481675,
      "grad_norm": 5.950517177581787,
      "learning_rate": 0.0002968743455497382,
      "loss": 2.7443,
      "step": 200
    },
    {
      "epoch": 1.0994764397905759,
      "grad_norm": 6.371921539306641,
      "learning_rate": 0.00029671727748691094,
      "loss": 2.6405,
      "step": 210
    },
    {
      "epoch": 1.1518324607329844,
      "grad_norm": 6.09501314163208,
      "learning_rate": 0.0002965602094240837,
      "loss": 2.5647,
      "step": 220
    },
    {
      "epoch": 1.2041884816753927,
      "grad_norm": 7.496273040771484,
      "learning_rate": 0.0002964031413612565,
      "loss": 2.6325,
      "step": 230
    },
    {
      "epoch": 1.256544502617801,
      "grad_norm": 6.187106609344482,
      "learning_rate": 0.0002962460732984293,
      "loss": 2.6516,
      "step": 240
    },
    {
      "epoch": 1.3089005235602094,
      "grad_norm": 8.30312728881836,
      "learning_rate": 0.0002960890052356021,
      "loss": 2.6362,
      "step": 250
    },
    {
      "epoch": 1.3612565445026177,
      "grad_norm": 7.464670181274414,
      "learning_rate": 0.00029593193717277486,
      "loss": 2.5505,
      "step": 260
    },
    {
      "epoch": 1.4136125654450262,
      "grad_norm": 6.409999370574951,
      "learning_rate": 0.0002957748691099476,
      "loss": 2.4871,
      "step": 270
    },
    {
      "epoch": 1.4659685863874345,
      "grad_norm": 8.33585262298584,
      "learning_rate": 0.0002956178010471204,
      "loss": 2.4453,
      "step": 280
    },
    {
      "epoch": 1.518324607329843,
      "grad_norm": 7.862833499908447,
      "learning_rate": 0.00029546073298429316,
      "loss": 2.4626,
      "step": 290
    },
    {
      "epoch": 1.5706806282722514,
      "grad_norm": 8.908679008483887,
      "learning_rate": 0.00029530366492146594,
      "loss": 2.4623,
      "step": 300
    },
    {
      "epoch": 1.6230366492146597,
      "grad_norm": 6.773562431335449,
      "learning_rate": 0.0002951465968586387,
      "loss": 2.5299,
      "step": 310
    },
    {
      "epoch": 1.675392670157068,
      "grad_norm": 7.985607624053955,
      "learning_rate": 0.0002949895287958115,
      "loss": 2.5578,
      "step": 320
    },
    {
      "epoch": 1.7277486910994764,
      "grad_norm": 7.445786476135254,
      "learning_rate": 0.00029483246073298423,
      "loss": 2.4456,
      "step": 330
    },
    {
      "epoch": 1.7801047120418847,
      "grad_norm": 7.023166656494141,
      "learning_rate": 0.00029467539267015707,
      "loss": 2.4961,
      "step": 340
    },
    {
      "epoch": 1.8324607329842932,
      "grad_norm": 7.9346022605896,
      "learning_rate": 0.0002945183246073298,
      "loss": 2.5035,
      "step": 350
    },
    {
      "epoch": 1.8848167539267016,
      "grad_norm": 7.1831793785095215,
      "learning_rate": 0.0002943612565445026,
      "loss": 2.3315,
      "step": 360
    },
    {
      "epoch": 1.93717277486911,
      "grad_norm": 8.652823448181152,
      "learning_rate": 0.00029420418848167537,
      "loss": 2.3729,
      "step": 370
    },
    {
      "epoch": 1.9895287958115184,
      "grad_norm": 7.652769088745117,
      "learning_rate": 0.00029404712041884815,
      "loss": 2.3777,
      "step": 380
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4340028694404591,
      "eval_loss": 2.8975610733032227,
      "eval_runtime": 0.8496,
      "eval_samples_per_second": 1640.791,
      "eval_steps_per_second": 25.895,
      "step": 382
    },
    {
      "epoch": 2.0418848167539267,
      "grad_norm": 7.415346145629883,
      "learning_rate": 0.00029389005235602093,
      "loss": 1.9343,
      "step": 390
    },
    {
      "epoch": 2.094240837696335,
      "grad_norm": 6.5255351066589355,
      "learning_rate": 0.0002937329842931937,
      "loss": 1.7524,
      "step": 400
    },
    {
      "epoch": 2.1465968586387434,
      "grad_norm": 7.339776992797852,
      "learning_rate": 0.00029357591623036645,
      "loss": 1.8472,
      "step": 410
    },
    {
      "epoch": 2.1989528795811517,
      "grad_norm": 7.274675369262695,
      "learning_rate": 0.00029341884816753923,
      "loss": 1.9496,
      "step": 420
    },
    {
      "epoch": 2.25130890052356,
      "grad_norm": 7.991876125335693,
      "learning_rate": 0.000293261780104712,
      "loss": 1.8081,
      "step": 430
    },
    {
      "epoch": 2.303664921465969,
      "grad_norm": 6.5969672203063965,
      "learning_rate": 0.0002931047120418848,
      "loss": 1.8284,
      "step": 440
    },
    {
      "epoch": 2.356020942408377,
      "grad_norm": 7.979504585266113,
      "learning_rate": 0.0002929476439790576,
      "loss": 1.8363,
      "step": 450
    },
    {
      "epoch": 2.4083769633507854,
      "grad_norm": 8.165974617004395,
      "learning_rate": 0.00029279057591623036,
      "loss": 1.886,
      "step": 460
    },
    {
      "epoch": 2.4607329842931938,
      "grad_norm": 7.9306511878967285,
      "learning_rate": 0.0002926335078534031,
      "loss": 1.8547,
      "step": 470
    },
    {
      "epoch": 2.513089005235602,
      "grad_norm": 6.604848861694336,
      "learning_rate": 0.0002924764397905759,
      "loss": 1.8782,
      "step": 480
    },
    {
      "epoch": 2.5654450261780104,
      "grad_norm": 7.522655963897705,
      "learning_rate": 0.00029231937172774866,
      "loss": 1.9803,
      "step": 490
    },
    {
      "epoch": 2.6178010471204187,
      "grad_norm": 8.133637428283691,
      "learning_rate": 0.00029216230366492144,
      "loss": 1.924,
      "step": 500
    },
    {
      "epoch": 2.670157068062827,
      "grad_norm": 8.0064115524292,
      "learning_rate": 0.0002920052356020942,
      "loss": 2.0006,
      "step": 510
    },
    {
      "epoch": 2.7225130890052354,
      "grad_norm": 9.344991683959961,
      "learning_rate": 0.000291848167539267,
      "loss": 1.8908,
      "step": 520
    },
    {
      "epoch": 2.774869109947644,
      "grad_norm": 8.283634185791016,
      "learning_rate": 0.00029169109947643974,
      "loss": 1.8124,
      "step": 530
    },
    {
      "epoch": 2.8272251308900525,
      "grad_norm": 9.856435775756836,
      "learning_rate": 0.0002915340314136125,
      "loss": 1.9041,
      "step": 540
    },
    {
      "epoch": 2.8795811518324608,
      "grad_norm": 8.457040786743164,
      "learning_rate": 0.0002913769633507853,
      "loss": 1.8924,
      "step": 550
    },
    {
      "epoch": 2.931937172774869,
      "grad_norm": 9.205896377563477,
      "learning_rate": 0.0002912198952879581,
      "loss": 1.9364,
      "step": 560
    },
    {
      "epoch": 2.9842931937172774,
      "grad_norm": 9.008456230163574,
      "learning_rate": 0.00029106282722513087,
      "loss": 1.8729,
      "step": 570
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.46628407460545196,
      "eval_loss": 2.8305139541625977,
      "eval_runtime": 0.9148,
      "eval_samples_per_second": 1523.891,
      "eval_steps_per_second": 24.05,
      "step": 573
    },
    {
      "epoch": 3.0366492146596857,
      "grad_norm": 5.580865383148193,
      "learning_rate": 0.00029090575916230365,
      "loss": 1.6873,
      "step": 580
    },
    {
      "epoch": 3.089005235602094,
      "grad_norm": 6.258245468139648,
      "learning_rate": 0.00029074869109947644,
      "loss": 1.4688,
      "step": 590
    },
    {
      "epoch": 3.141361256544503,
      "grad_norm": 5.928934097290039,
      "learning_rate": 0.00029059162303664916,
      "loss": 1.4159,
      "step": 600
    },
    {
      "epoch": 3.193717277486911,
      "grad_norm": 6.148650169372559,
      "learning_rate": 0.00029043455497382195,
      "loss": 1.3957,
      "step": 610
    },
    {
      "epoch": 3.2460732984293195,
      "grad_norm": 7.492969036102295,
      "learning_rate": 0.00029027748691099473,
      "loss": 1.4293,
      "step": 620
    },
    {
      "epoch": 3.298429319371728,
      "grad_norm": 11.184059143066406,
      "learning_rate": 0.0002901204188481675,
      "loss": 1.5047,
      "step": 630
    },
    {
      "epoch": 3.350785340314136,
      "grad_norm": 6.810328483581543,
      "learning_rate": 0.0002899633507853403,
      "loss": 1.5142,
      "step": 640
    },
    {
      "epoch": 3.4031413612565444,
      "grad_norm": 8.400492668151855,
      "learning_rate": 0.0002898062827225131,
      "loss": 1.4451,
      "step": 650
    },
    {
      "epoch": 3.4554973821989527,
      "grad_norm": 8.761978149414062,
      "learning_rate": 0.0002896492146596858,
      "loss": 1.4608,
      "step": 660
    },
    {
      "epoch": 3.507853403141361,
      "grad_norm": 8.117511749267578,
      "learning_rate": 0.0002894921465968586,
      "loss": 1.4995,
      "step": 670
    },
    {
      "epoch": 3.5602094240837694,
      "grad_norm": 7.607695579528809,
      "learning_rate": 0.0002893350785340314,
      "loss": 1.5677,
      "step": 680
    },
    {
      "epoch": 3.612565445026178,
      "grad_norm": 9.54983139038086,
      "learning_rate": 0.00028917801047120416,
      "loss": 1.531,
      "step": 690
    },
    {
      "epoch": 3.6649214659685865,
      "grad_norm": 8.13460922241211,
      "learning_rate": 0.00028902094240837694,
      "loss": 1.5732,
      "step": 700
    },
    {
      "epoch": 3.717277486910995,
      "grad_norm": 7.445168972015381,
      "learning_rate": 0.0002888638743455497,
      "loss": 1.5149,
      "step": 710
    },
    {
      "epoch": 3.769633507853403,
      "grad_norm": 7.419155120849609,
      "learning_rate": 0.00028870680628272246,
      "loss": 1.4506,
      "step": 720
    },
    {
      "epoch": 3.8219895287958114,
      "grad_norm": 8.229398727416992,
      "learning_rate": 0.0002885497382198953,
      "loss": 1.5519,
      "step": 730
    },
    {
      "epoch": 3.8743455497382198,
      "grad_norm": 8.030768394470215,
      "learning_rate": 0.000288392670157068,
      "loss": 1.557,
      "step": 740
    },
    {
      "epoch": 3.9267015706806285,
      "grad_norm": 8.21743106842041,
      "learning_rate": 0.0002882356020942408,
      "loss": 1.6239,
      "step": 750
    },
    {
      "epoch": 3.979057591623037,
      "grad_norm": 7.846015930175781,
      "learning_rate": 0.0002880785340314136,
      "loss": 1.5657,
      "step": 760
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.4583931133428981,
      "eval_loss": 2.8679914474487305,
      "eval_runtime": 0.981,
      "eval_samples_per_second": 1420.966,
      "eval_steps_per_second": 22.426,
      "step": 764
    },
    {
      "epoch": 4.031413612565445,
      "grad_norm": 6.834514141082764,
      "learning_rate": 0.00028792146596858637,
      "loss": 1.3478,
      "step": 770
    },
    {
      "epoch": 4.0837696335078535,
      "grad_norm": 7.6856369972229,
      "learning_rate": 0.0002877643979057591,
      "loss": 1.2056,
      "step": 780
    },
    {
      "epoch": 4.136125654450262,
      "grad_norm": 6.182103157043457,
      "learning_rate": 0.00028760732984293194,
      "loss": 1.2047,
      "step": 790
    },
    {
      "epoch": 4.18848167539267,
      "grad_norm": 5.855922222137451,
      "learning_rate": 0.00028745026178010467,
      "loss": 1.2861,
      "step": 800
    },
    {
      "epoch": 4.2408376963350785,
      "grad_norm": 4.527009963989258,
      "learning_rate": 0.00028729319371727745,
      "loss": 1.201,
      "step": 810
    },
    {
      "epoch": 4.293193717277487,
      "grad_norm": 6.643332004547119,
      "learning_rate": 0.00028713612565445023,
      "loss": 1.2049,
      "step": 820
    },
    {
      "epoch": 4.345549738219895,
      "grad_norm": 6.826823711395264,
      "learning_rate": 0.000286979057591623,
      "loss": 1.2216,
      "step": 830
    },
    {
      "epoch": 4.397905759162303,
      "grad_norm": 7.353673934936523,
      "learning_rate": 0.00028682198952879575,
      "loss": 1.2547,
      "step": 840
    },
    {
      "epoch": 4.450261780104712,
      "grad_norm": 6.44692850112915,
      "learning_rate": 0.0002866649214659686,
      "loss": 1.3198,
      "step": 850
    },
    {
      "epoch": 4.50261780104712,
      "grad_norm": 5.793459892272949,
      "learning_rate": 0.0002865078534031413,
      "loss": 1.249,
      "step": 860
    },
    {
      "epoch": 4.554973821989529,
      "grad_norm": 6.395140171051025,
      "learning_rate": 0.00028635078534031415,
      "loss": 1.2966,
      "step": 870
    },
    {
      "epoch": 4.607329842931938,
      "grad_norm": 4.718147277832031,
      "learning_rate": 0.0002861937172774869,
      "loss": 1.2706,
      "step": 880
    },
    {
      "epoch": 4.659685863874346,
      "grad_norm": 8.2865629196167,
      "learning_rate": 0.00028603664921465966,
      "loss": 1.3229,
      "step": 890
    },
    {
      "epoch": 4.712041884816754,
      "grad_norm": 7.089879989624023,
      "learning_rate": 0.00028587958115183245,
      "loss": 1.3385,
      "step": 900
    },
    {
      "epoch": 4.7643979057591626,
      "grad_norm": 9.074563026428223,
      "learning_rate": 0.00028572251308900523,
      "loss": 1.2603,
      "step": 910
    },
    {
      "epoch": 4.816753926701571,
      "grad_norm": 8.367704391479492,
      "learning_rate": 0.00028556544502617796,
      "loss": 1.3786,
      "step": 920
    },
    {
      "epoch": 4.869109947643979,
      "grad_norm": 5.051718711853027,
      "learning_rate": 0.0002854083769633508,
      "loss": 1.3274,
      "step": 930
    },
    {
      "epoch": 4.9214659685863875,
      "grad_norm": 5.412168025970459,
      "learning_rate": 0.0002852513089005235,
      "loss": 1.3081,
      "step": 940
    },
    {
      "epoch": 4.973821989528796,
      "grad_norm": 9.084527969360352,
      "learning_rate": 0.0002850942408376963,
      "loss": 1.3393,
      "step": 950
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.45480631276901007,
      "eval_loss": 2.9498419761657715,
      "eval_runtime": 0.9463,
      "eval_samples_per_second": 1473.121,
      "eval_steps_per_second": 23.249,
      "step": 955
    },
    {
      "epoch": 5.026178010471204,
      "grad_norm": 4.314021110534668,
      "learning_rate": 0.0002849371727748691,
      "loss": 1.2362,
      "step": 960
    },
    {
      "epoch": 5.0785340314136125,
      "grad_norm": 6.203071117401123,
      "learning_rate": 0.0002847801047120419,
      "loss": 1.1119,
      "step": 970
    },
    {
      "epoch": 5.130890052356021,
      "grad_norm": 6.379215240478516,
      "learning_rate": 0.0002846230366492146,
      "loss": 1.1302,
      "step": 980
    },
    {
      "epoch": 5.183246073298429,
      "grad_norm": 6.824506759643555,
      "learning_rate": 0.00028446596858638744,
      "loss": 1.1402,
      "step": 990
    },
    {
      "epoch": 5.2356020942408374,
      "grad_norm": 4.3936944007873535,
      "learning_rate": 0.00028430890052356017,
      "loss": 1.131,
      "step": 1000
    },
    {
      "epoch": 5.287958115183246,
      "grad_norm": 7.092190265655518,
      "learning_rate": 0.00028415183246073295,
      "loss": 1.1421,
      "step": 1010
    },
    {
      "epoch": 5.340314136125654,
      "grad_norm": 6.728339195251465,
      "learning_rate": 0.00028399476439790574,
      "loss": 1.1584,
      "step": 1020
    },
    {
      "epoch": 5.392670157068062,
      "grad_norm": 6.572563648223877,
      "learning_rate": 0.0002838376963350785,
      "loss": 1.1349,
      "step": 1030
    },
    {
      "epoch": 5.445026178010472,
      "grad_norm": 7.279167175292969,
      "learning_rate": 0.0002836806282722513,
      "loss": 1.1117,
      "step": 1040
    },
    {
      "epoch": 5.49738219895288,
      "grad_norm": 7.46614408493042,
      "learning_rate": 0.0002835235602094241,
      "loss": 1.1672,
      "step": 1050
    },
    {
      "epoch": 5.549738219895288,
      "grad_norm": 5.1929707527160645,
      "learning_rate": 0.0002833664921465968,
      "loss": 1.1621,
      "step": 1060
    },
    {
      "epoch": 5.602094240837697,
      "grad_norm": 5.475687026977539,
      "learning_rate": 0.0002832094240837696,
      "loss": 1.1701,
      "step": 1070
    },
    {
      "epoch": 5.654450261780105,
      "grad_norm": 6.640726089477539,
      "learning_rate": 0.0002830523560209424,
      "loss": 1.2031,
      "step": 1080
    },
    {
      "epoch": 5.706806282722513,
      "grad_norm": 7.615060806274414,
      "learning_rate": 0.00028289528795811516,
      "loss": 1.1778,
      "step": 1090
    },
    {
      "epoch": 5.7591623036649215,
      "grad_norm": 7.515255928039551,
      "learning_rate": 0.00028273821989528795,
      "loss": 1.2012,
      "step": 1100
    },
    {
      "epoch": 5.81151832460733,
      "grad_norm": 6.59874153137207,
      "learning_rate": 0.00028258115183246073,
      "loss": 1.1106,
      "step": 1110
    },
    {
      "epoch": 5.863874345549738,
      "grad_norm": 7.3881306648254395,
      "learning_rate": 0.00028242408376963346,
      "loss": 1.1833,
      "step": 1120
    },
    {
      "epoch": 5.9162303664921465,
      "grad_norm": 8.407530784606934,
      "learning_rate": 0.00028226701570680624,
      "loss": 1.2234,
      "step": 1130
    },
    {
      "epoch": 5.968586387434555,
      "grad_norm": 7.955669403076172,
      "learning_rate": 0.000282109947643979,
      "loss": 1.2338,
      "step": 1140
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.46413199426111906,
      "eval_loss": 3.0060691833496094,
      "eval_runtime": 0.9542,
      "eval_samples_per_second": 1460.868,
      "eval_steps_per_second": 23.055,
      "step": 1146
    },
    {
      "epoch": 6.020942408376963,
      "grad_norm": 6.541180610656738,
      "learning_rate": 0.0002819528795811518,
      "loss": 1.1323,
      "step": 1150
    },
    {
      "epoch": 6.0732984293193715,
      "grad_norm": 5.954043388366699,
      "learning_rate": 0.0002817958115183246,
      "loss": 1.0259,
      "step": 1160
    },
    {
      "epoch": 6.12565445026178,
      "grad_norm": 8.461902618408203,
      "learning_rate": 0.0002816387434554974,
      "loss": 1.0722,
      "step": 1170
    },
    {
      "epoch": 6.178010471204188,
      "grad_norm": 5.413074016571045,
      "learning_rate": 0.00028148167539267016,
      "loss": 1.085,
      "step": 1180
    },
    {
      "epoch": 6.230366492146596,
      "grad_norm": 2.6906938552856445,
      "learning_rate": 0.0002813246073298429,
      "loss": 1.0846,
      "step": 1190
    },
    {
      "epoch": 6.282722513089006,
      "grad_norm": 5.24119758605957,
      "learning_rate": 0.00028116753926701567,
      "loss": 1.1121,
      "step": 1200
    },
    {
      "epoch": 6.335078534031414,
      "grad_norm": 5.491568565368652,
      "learning_rate": 0.00028101047120418846,
      "loss": 1.028,
      "step": 1210
    },
    {
      "epoch": 6.387434554973822,
      "grad_norm": 9.420539855957031,
      "learning_rate": 0.00028085340314136124,
      "loss": 1.0763,
      "step": 1220
    },
    {
      "epoch": 6.439790575916231,
      "grad_norm": 6.508111476898193,
      "learning_rate": 0.000280696335078534,
      "loss": 1.0476,
      "step": 1230
    },
    {
      "epoch": 6.492146596858639,
      "grad_norm": 5.9403076171875,
      "learning_rate": 0.0002805392670157068,
      "loss": 1.0954,
      "step": 1240
    },
    {
      "epoch": 6.544502617801047,
      "grad_norm": 5.57830810546875,
      "learning_rate": 0.00028038219895287953,
      "loss": 1.0996,
      "step": 1250
    },
    {
      "epoch": 6.596858638743456,
      "grad_norm": 5.644502639770508,
      "learning_rate": 0.0002802251308900523,
      "loss": 1.1108,
      "step": 1260
    },
    {
      "epoch": 6.649214659685864,
      "grad_norm": 5.373710632324219,
      "learning_rate": 0.0002800680628272251,
      "loss": 1.117,
      "step": 1270
    },
    {
      "epoch": 6.701570680628272,
      "grad_norm": 7.081669807434082,
      "learning_rate": 0.0002799109947643979,
      "loss": 1.0942,
      "step": 1280
    },
    {
      "epoch": 6.7539267015706805,
      "grad_norm": 6.942591667175293,
      "learning_rate": 0.00027975392670157067,
      "loss": 1.0938,
      "step": 1290
    },
    {
      "epoch": 6.806282722513089,
      "grad_norm": 5.777352333068848,
      "learning_rate": 0.00027959685863874345,
      "loss": 1.0913,
      "step": 1300
    },
    {
      "epoch": 6.858638743455497,
      "grad_norm": 6.671590805053711,
      "learning_rate": 0.0002794397905759162,
      "loss": 1.0996,
      "step": 1310
    },
    {
      "epoch": 6.9109947643979055,
      "grad_norm": 6.031998634338379,
      "learning_rate": 0.000279282722513089,
      "loss": 1.1239,
      "step": 1320
    },
    {
      "epoch": 6.963350785340314,
      "grad_norm": 6.20047664642334,
      "learning_rate": 0.00027912565445026175,
      "loss": 1.1287,
      "step": 1330
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.4383070301291248,
      "eval_loss": 3.064969778060913,
      "eval_runtime": 0.913,
      "eval_samples_per_second": 1526.876,
      "eval_steps_per_second": 24.097,
      "step": 1337
    },
    {
      "epoch": 7.015706806282722,
      "grad_norm": 3.5951642990112305,
      "learning_rate": 0.00027896858638743453,
      "loss": 1.0787,
      "step": 1340
    },
    {
      "epoch": 7.0680628272251305,
      "grad_norm": 4.640782356262207,
      "learning_rate": 0.0002788115183246073,
      "loss": 1.0238,
      "step": 1350
    },
    {
      "epoch": 7.12041884816754,
      "grad_norm": 2.7539868354797363,
      "learning_rate": 0.0002786544502617801,
      "loss": 1.0254,
      "step": 1360
    },
    {
      "epoch": 7.172774869109948,
      "grad_norm": 6.478612899780273,
      "learning_rate": 0.0002784973821989528,
      "loss": 1.0476,
      "step": 1370
    },
    {
      "epoch": 7.225130890052356,
      "grad_norm": 8.103344917297363,
      "learning_rate": 0.00027834031413612566,
      "loss": 1.0638,
      "step": 1380
    },
    {
      "epoch": 7.277486910994765,
      "grad_norm": 2.757619619369507,
      "learning_rate": 0.0002781832460732984,
      "loss": 1.0223,
      "step": 1390
    },
    {
      "epoch": 7.329842931937173,
      "grad_norm": 6.910790920257568,
      "learning_rate": 0.0002780261780104712,
      "loss": 1.0422,
      "step": 1400
    },
    {
      "epoch": 7.382198952879581,
      "grad_norm": 6.661773681640625,
      "learning_rate": 0.00027786910994764396,
      "loss": 1.1036,
      "step": 1410
    },
    {
      "epoch": 7.43455497382199,
      "grad_norm": 3.563415050506592,
      "learning_rate": 0.00027771204188481674,
      "loss": 1.0145,
      "step": 1420
    },
    {
      "epoch": 7.486910994764398,
      "grad_norm": 6.028726577758789,
      "learning_rate": 0.00027755497382198947,
      "loss": 1.04,
      "step": 1430
    },
    {
      "epoch": 7.539267015706806,
      "grad_norm": 6.037771701812744,
      "learning_rate": 0.0002773979057591623,
      "loss": 1.0313,
      "step": 1440
    },
    {
      "epoch": 7.591623036649215,
      "grad_norm": 6.618631362915039,
      "learning_rate": 0.00027724083769633504,
      "loss": 1.0561,
      "step": 1450
    },
    {
      "epoch": 7.643979057591623,
      "grad_norm": 7.042873382568359,
      "learning_rate": 0.0002770837696335078,
      "loss": 1.1007,
      "step": 1460
    },
    {
      "epoch": 7.696335078534031,
      "grad_norm": 6.975803375244141,
      "learning_rate": 0.0002769267015706806,
      "loss": 1.0573,
      "step": 1470
    },
    {
      "epoch": 7.7486910994764395,
      "grad_norm": 6.458019256591797,
      "learning_rate": 0.0002767696335078534,
      "loss": 1.1322,
      "step": 1480
    },
    {
      "epoch": 7.801047120418848,
      "grad_norm": 6.268755912780762,
      "learning_rate": 0.00027661256544502617,
      "loss": 1.0704,
      "step": 1490
    },
    {
      "epoch": 7.853403141361256,
      "grad_norm": 4.719828128814697,
      "learning_rate": 0.00027645549738219895,
      "loss": 1.0953,
      "step": 1500
    },
    {
      "epoch": 7.905759162303665,
      "grad_norm": 6.46837043762207,
      "learning_rate": 0.0002762984293193717,
      "loss": 1.0808,
      "step": 1510
    },
    {
      "epoch": 7.958115183246074,
      "grad_norm": 10.565526008605957,
      "learning_rate": 0.00027614136125654447,
      "loss": 1.094,
      "step": 1520
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.4533715925394548,
      "eval_loss": 3.1265885829925537,
      "eval_runtime": 0.9064,
      "eval_samples_per_second": 1537.892,
      "eval_steps_per_second": 24.271,
      "step": 1528
    },
    {
      "epoch": 8.010471204188482,
      "grad_norm": 6.3468780517578125,
      "learning_rate": 0.00027598429319371725,
      "loss": 1.0927,
      "step": 1530
    },
    {
      "epoch": 8.06282722513089,
      "grad_norm": 4.734595775604248,
      "learning_rate": 0.00027582722513089003,
      "loss": 1.0165,
      "step": 1540
    },
    {
      "epoch": 8.115183246073299,
      "grad_norm": 6.443619728088379,
      "learning_rate": 0.0002756701570680628,
      "loss": 1.04,
      "step": 1550
    },
    {
      "epoch": 8.167539267015707,
      "grad_norm": 8.044103622436523,
      "learning_rate": 0.0002755130890052356,
      "loss": 1.0076,
      "step": 1560
    },
    {
      "epoch": 8.219895287958115,
      "grad_norm": 3.8789243698120117,
      "learning_rate": 0.00027535602094240833,
      "loss": 1.0422,
      "step": 1570
    },
    {
      "epoch": 8.272251308900524,
      "grad_norm": 5.324503421783447,
      "learning_rate": 0.0002751989528795811,
      "loss": 1.0082,
      "step": 1580
    },
    {
      "epoch": 8.324607329842932,
      "grad_norm": 4.787650108337402,
      "learning_rate": 0.0002750418848167539,
      "loss": 1.0123,
      "step": 1590
    },
    {
      "epoch": 8.37696335078534,
      "grad_norm": 8.204489707946777,
      "learning_rate": 0.0002748848167539267,
      "loss": 1.0286,
      "step": 1600
    },
    {
      "epoch": 8.429319371727749,
      "grad_norm": 8.79919719696045,
      "learning_rate": 0.00027472774869109946,
      "loss": 1.0489,
      "step": 1610
    },
    {
      "epoch": 8.481675392670157,
      "grad_norm": 7.059916019439697,
      "learning_rate": 0.00027457068062827224,
      "loss": 1.0651,
      "step": 1620
    },
    {
      "epoch": 8.534031413612565,
      "grad_norm": 4.598770618438721,
      "learning_rate": 0.000274413612565445,
      "loss": 1.0091,
      "step": 1630
    },
    {
      "epoch": 8.586387434554974,
      "grad_norm": 4.42106294631958,
      "learning_rate": 0.00027425654450261776,
      "loss": 1.0255,
      "step": 1640
    },
    {
      "epoch": 8.638743455497382,
      "grad_norm": 5.510339736938477,
      "learning_rate": 0.00027409947643979054,
      "loss": 1.0546,
      "step": 1650
    },
    {
      "epoch": 8.69109947643979,
      "grad_norm": 4.337939262390137,
      "learning_rate": 0.0002739424083769633,
      "loss": 1.0472,
      "step": 1660
    },
    {
      "epoch": 8.743455497382199,
      "grad_norm": 4.26465368270874,
      "learning_rate": 0.0002737853403141361,
      "loss": 1.0417,
      "step": 1670
    },
    {
      "epoch": 8.795811518324607,
      "grad_norm": 8.648252487182617,
      "learning_rate": 0.0002736282722513089,
      "loss": 1.0776,
      "step": 1680
    },
    {
      "epoch": 8.848167539267015,
      "grad_norm": 4.222717761993408,
      "learning_rate": 0.00027347120418848167,
      "loss": 1.0473,
      "step": 1690
    },
    {
      "epoch": 8.900523560209423,
      "grad_norm": 5.820158004760742,
      "learning_rate": 0.0002733141361256544,
      "loss": 1.0545,
      "step": 1700
    },
    {
      "epoch": 8.952879581151832,
      "grad_norm": 6.826479434967041,
      "learning_rate": 0.0002731570680628272,
      "loss": 1.0281,
      "step": 1710
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.4483500717360115,
      "eval_loss": 3.172208547592163,
      "eval_runtime": 0.9063,
      "eval_samples_per_second": 1538.19,
      "eval_steps_per_second": 24.276,
      "step": 1719
    },
    {
      "epoch": 9.00523560209424,
      "grad_norm": 5.315700054168701,
      "learning_rate": 0.00027299999999999997,
      "loss": 1.0618,
      "step": 1720
    },
    {
      "epoch": 9.057591623036648,
      "grad_norm": 4.893139839172363,
      "learning_rate": 0.00027284293193717275,
      "loss": 0.9999,
      "step": 1730
    },
    {
      "epoch": 9.109947643979057,
      "grad_norm": 6.273837089538574,
      "learning_rate": 0.00027268586387434553,
      "loss": 1.0073,
      "step": 1740
    },
    {
      "epoch": 9.162303664921467,
      "grad_norm": 5.3236541748046875,
      "learning_rate": 0.0002725287958115183,
      "loss": 0.9702,
      "step": 1750
    },
    {
      "epoch": 9.214659685863875,
      "grad_norm": 5.960787296295166,
      "learning_rate": 0.00027237172774869105,
      "loss": 1.0024,
      "step": 1760
    },
    {
      "epoch": 9.267015706806284,
      "grad_norm": 3.4615399837493896,
      "learning_rate": 0.00027221465968586383,
      "loss": 1.0043,
      "step": 1770
    },
    {
      "epoch": 9.319371727748692,
      "grad_norm": 4.908249378204346,
      "learning_rate": 0.0002720575916230366,
      "loss": 1.0155,
      "step": 1780
    },
    {
      "epoch": 9.3717277486911,
      "grad_norm": 6.1206374168396,
      "learning_rate": 0.0002719005235602094,
      "loss": 0.9936,
      "step": 1790
    },
    {
      "epoch": 9.424083769633508,
      "grad_norm": 7.464108943939209,
      "learning_rate": 0.0002717434554973822,
      "loss": 1.0219,
      "step": 1800
    },
    {
      "epoch": 9.476439790575917,
      "grad_norm": 5.141566753387451,
      "learning_rate": 0.00027158638743455496,
      "loss": 1.057,
      "step": 1810
    },
    {
      "epoch": 9.528795811518325,
      "grad_norm": 5.532926082611084,
      "learning_rate": 0.0002714293193717277,
      "loss": 0.9974,
      "step": 1820
    },
    {
      "epoch": 9.581151832460733,
      "grad_norm": 6.965017795562744,
      "learning_rate": 0.00027127225130890053,
      "loss": 1.0382,
      "step": 1830
    },
    {
      "epoch": 9.633507853403142,
      "grad_norm": 5.370284557342529,
      "learning_rate": 0.00027111518324607326,
      "loss": 1.0126,
      "step": 1840
    },
    {
      "epoch": 9.68586387434555,
      "grad_norm": 6.658318042755127,
      "learning_rate": 0.00027095811518324604,
      "loss": 1.0422,
      "step": 1850
    },
    {
      "epoch": 9.738219895287958,
      "grad_norm": 5.280120372772217,
      "learning_rate": 0.0002708010471204188,
      "loss": 1.0418,
      "step": 1860
    },
    {
      "epoch": 9.790575916230367,
      "grad_norm": 6.116405010223389,
      "learning_rate": 0.0002706439790575916,
      "loss": 1.0142,
      "step": 1870
    },
    {
      "epoch": 9.842931937172775,
      "grad_norm": 4.926703929901123,
      "learning_rate": 0.00027048691099476434,
      "loss": 1.0028,
      "step": 1880
    },
    {
      "epoch": 9.895287958115183,
      "grad_norm": 6.2223005294799805,
      "learning_rate": 0.0002703298429319372,
      "loss": 0.9994,
      "step": 1890
    },
    {
      "epoch": 9.947643979057592,
      "grad_norm": 5.038272857666016,
      "learning_rate": 0.0002701727748691099,
      "loss": 1.0303,
      "step": 1900
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.500299453735352,
      "learning_rate": 0.0002700157068062827,
      "loss": 1.0042,
      "step": 1910
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.45050215208034433,
      "eval_loss": 3.1802494525909424,
      "eval_runtime": 0.8972,
      "eval_samples_per_second": 1553.711,
      "eval_steps_per_second": 24.521,
      "step": 1910
    },
    {
      "epoch": 10.052356020942408,
      "grad_norm": 3.8493175506591797,
      "learning_rate": 0.00026985863874345547,
      "loss": 1.0222,
      "step": 1920
    },
    {
      "epoch": 10.104712041884817,
      "grad_norm": 4.04854154586792,
      "learning_rate": 0.00026970157068062825,
      "loss": 0.9769,
      "step": 1930
    },
    {
      "epoch": 10.157068062827225,
      "grad_norm": 6.1122660636901855,
      "learning_rate": 0.00026954450261780104,
      "loss": 0.976,
      "step": 1940
    },
    {
      "epoch": 10.209424083769633,
      "grad_norm": 5.168984889984131,
      "learning_rate": 0.0002693874345549738,
      "loss": 0.9952,
      "step": 1950
    },
    {
      "epoch": 10.261780104712042,
      "grad_norm": 5.763420581817627,
      "learning_rate": 0.00026923036649214655,
      "loss": 0.9977,
      "step": 1960
    },
    {
      "epoch": 10.31413612565445,
      "grad_norm": 5.246893882751465,
      "learning_rate": 0.0002690732984293194,
      "loss": 0.9932,
      "step": 1970
    },
    {
      "epoch": 10.366492146596858,
      "grad_norm": 4.838987350463867,
      "learning_rate": 0.0002689162303664921,
      "loss": 0.9945,
      "step": 1980
    },
    {
      "epoch": 10.418848167539267,
      "grad_norm": 6.3164496421813965,
      "learning_rate": 0.0002687591623036649,
      "loss": 1.0285,
      "step": 1990
    },
    {
      "epoch": 10.471204188481675,
      "grad_norm": 6.837243556976318,
      "learning_rate": 0.0002686020942408377,
      "loss": 1.0024,
      "step": 2000
    },
    {
      "epoch": 10.523560209424083,
      "grad_norm": 5.001404762268066,
      "learning_rate": 0.00026844502617801047,
      "loss": 0.9784,
      "step": 2010
    },
    {
      "epoch": 10.575916230366492,
      "grad_norm": 4.20558500289917,
      "learning_rate": 0.0002682879581151832,
      "loss": 1.0429,
      "step": 2020
    },
    {
      "epoch": 10.6282722513089,
      "grad_norm": 5.897756576538086,
      "learning_rate": 0.00026813089005235603,
      "loss": 1.0082,
      "step": 2030
    },
    {
      "epoch": 10.680628272251308,
      "grad_norm": 7.864990711212158,
      "learning_rate": 0.00026797382198952876,
      "loss": 1.0125,
      "step": 2040
    },
    {
      "epoch": 10.732984293193716,
      "grad_norm": 8.494614601135254,
      "learning_rate": 0.00026781675392670154,
      "loss": 1.0132,
      "step": 2050
    },
    {
      "epoch": 10.785340314136125,
      "grad_norm": 5.459760665893555,
      "learning_rate": 0.00026765968586387433,
      "loss": 1.022,
      "step": 2060
    },
    {
      "epoch": 10.837696335078533,
      "grad_norm": 6.853332042694092,
      "learning_rate": 0.0002675026178010471,
      "loss": 1.0089,
      "step": 2070
    },
    {
      "epoch": 10.890052356020943,
      "grad_norm": 7.002579212188721,
      "learning_rate": 0.00026734554973821984,
      "loss": 1.0197,
      "step": 2080
    },
    {
      "epoch": 10.942408376963352,
      "grad_norm": 5.661505222320557,
      "learning_rate": 0.0002671884816753927,
      "loss": 1.0198,
      "step": 2090
    },
    {
      "epoch": 10.99476439790576,
      "grad_norm": 6.952909469604492,
      "learning_rate": 0.0002670314136125654,
      "loss": 1.0203,
      "step": 2100
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.43902439024390244,
      "eval_loss": 3.232185125350952,
      "eval_runtime": 0.9172,
      "eval_samples_per_second": 1519.9,
      "eval_steps_per_second": 23.987,
      "step": 2101
    },
    {
      "epoch": 11.047120418848168,
      "grad_norm": 4.736428260803223,
      "learning_rate": 0.0002668743455497382,
      "loss": 0.9989,
      "step": 2110
    },
    {
      "epoch": 11.099476439790577,
      "grad_norm": 6.079123497009277,
      "learning_rate": 0.000266717277486911,
      "loss": 0.9729,
      "step": 2120
    },
    {
      "epoch": 11.151832460732985,
      "grad_norm": 2.908322334289551,
      "learning_rate": 0.00026656020942408376,
      "loss": 0.9694,
      "step": 2130
    },
    {
      "epoch": 11.204188481675393,
      "grad_norm": 5.07352352142334,
      "learning_rate": 0.00026640314136125654,
      "loss": 0.9766,
      "step": 2140
    },
    {
      "epoch": 11.256544502617801,
      "grad_norm": 5.115133762359619,
      "learning_rate": 0.0002662460732984293,
      "loss": 0.9805,
      "step": 2150
    },
    {
      "epoch": 11.30890052356021,
      "grad_norm": 4.161392688751221,
      "learning_rate": 0.00026608900523560205,
      "loss": 0.989,
      "step": 2160
    },
    {
      "epoch": 11.361256544502618,
      "grad_norm": 6.039876461029053,
      "learning_rate": 0.00026593193717277483,
      "loss": 0.9753,
      "step": 2170
    },
    {
      "epoch": 11.413612565445026,
      "grad_norm": 4.647495269775391,
      "learning_rate": 0.0002657748691099476,
      "loss": 1.011,
      "step": 2180
    },
    {
      "epoch": 11.465968586387435,
      "grad_norm": 11.68349838256836,
      "learning_rate": 0.0002656178010471204,
      "loss": 1.0093,
      "step": 2190
    },
    {
      "epoch": 11.518324607329843,
      "grad_norm": 3.2610950469970703,
      "learning_rate": 0.0002654607329842932,
      "loss": 0.9934,
      "step": 2200
    },
    {
      "epoch": 11.570680628272251,
      "grad_norm": 7.149501323699951,
      "learning_rate": 0.00026530366492146597,
      "loss": 0.9948,
      "step": 2210
    },
    {
      "epoch": 11.62303664921466,
      "grad_norm": 4.515071868896484,
      "learning_rate": 0.0002651465968586387,
      "loss": 0.9754,
      "step": 2220
    },
    {
      "epoch": 11.675392670157068,
      "grad_norm": 4.364283084869385,
      "learning_rate": 0.0002649895287958115,
      "loss": 0.9871,
      "step": 2230
    },
    {
      "epoch": 11.727748691099476,
      "grad_norm": 7.396000385284424,
      "learning_rate": 0.000264848167539267,
      "loss": 1.0036,
      "step": 2240
    },
    {
      "epoch": 11.780104712041885,
      "grad_norm": 5.20100212097168,
      "learning_rate": 0.0002646910994764398,
      "loss": 1.0005,
      "step": 2250
    },
    {
      "epoch": 11.832460732984293,
      "grad_norm": 7.026703357696533,
      "learning_rate": 0.00026453403141361257,
      "loss": 0.9844,
      "step": 2260
    },
    {
      "epoch": 11.884816753926701,
      "grad_norm": 6.50162935256958,
      "learning_rate": 0.0002643769633507853,
      "loss": 0.9994,
      "step": 2270
    },
    {
      "epoch": 11.93717277486911,
      "grad_norm": 8.007960319519043,
      "learning_rate": 0.0002642198952879581,
      "loss": 1.0556,
      "step": 2280
    },
    {
      "epoch": 11.989528795811518,
      "grad_norm": 5.974736213684082,
      "learning_rate": 0.00026406282722513086,
      "loss": 1.0192,
      "step": 2290
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.44619799139167865,
      "eval_loss": 3.2157866954803467,
      "eval_runtime": 0.9175,
      "eval_samples_per_second": 1519.312,
      "eval_steps_per_second": 23.978,
      "step": 2292
    },
    {
      "epoch": 12.041884816753926,
      "grad_norm": 3.1597182750701904,
      "learning_rate": 0.00026390575916230365,
      "loss": 1.005,
      "step": 2300
    },
    {
      "epoch": 12.094240837696335,
      "grad_norm": 1.878179907798767,
      "learning_rate": 0.00026374869109947643,
      "loss": 0.9461,
      "step": 2310
    },
    {
      "epoch": 12.146596858638743,
      "grad_norm": 5.732183456420898,
      "learning_rate": 0.0002635916230366492,
      "loss": 0.9782,
      "step": 2320
    },
    {
      "epoch": 12.198952879581151,
      "grad_norm": 5.004897117614746,
      "learning_rate": 0.00026343455497382194,
      "loss": 0.9791,
      "step": 2330
    },
    {
      "epoch": 12.25130890052356,
      "grad_norm": 5.853230953216553,
      "learning_rate": 0.0002632774869109947,
      "loss": 0.9686,
      "step": 2340
    },
    {
      "epoch": 12.303664921465968,
      "grad_norm": 5.549874782562256,
      "learning_rate": 0.0002631204188481675,
      "loss": 0.9533,
      "step": 2350
    },
    {
      "epoch": 12.356020942408376,
      "grad_norm": 3.5126471519470215,
      "learning_rate": 0.0002629633507853403,
      "loss": 0.9516,
      "step": 2360
    },
    {
      "epoch": 12.408376963350785,
      "grad_norm": 2.3024511337280273,
      "learning_rate": 0.0002628062827225131,
      "loss": 0.9746,
      "step": 2370
    },
    {
      "epoch": 12.460732984293193,
      "grad_norm": 6.167176723480225,
      "learning_rate": 0.00026264921465968586,
      "loss": 0.9864,
      "step": 2380
    },
    {
      "epoch": 12.513089005235603,
      "grad_norm": 6.37570858001709,
      "learning_rate": 0.0002624921465968586,
      "loss": 1.0395,
      "step": 2390
    },
    {
      "epoch": 12.565445026178011,
      "grad_norm": 4.3390092849731445,
      "learning_rate": 0.0002623350785340314,
      "loss": 0.9711,
      "step": 2400
    },
    {
      "epoch": 12.61780104712042,
      "grad_norm": 6.310947418212891,
      "learning_rate": 0.00026217801047120415,
      "loss": 0.994,
      "step": 2410
    },
    {
      "epoch": 12.670157068062828,
      "grad_norm": 5.332211971282959,
      "learning_rate": 0.00026202094240837694,
      "loss": 1.004,
      "step": 2420
    },
    {
      "epoch": 12.722513089005236,
      "grad_norm": 5.306617259979248,
      "learning_rate": 0.0002618638743455497,
      "loss": 1.007,
      "step": 2430
    },
    {
      "epoch": 12.774869109947645,
      "grad_norm": 3.850919723510742,
      "learning_rate": 0.0002617068062827225,
      "loss": 0.9959,
      "step": 2440
    },
    {
      "epoch": 12.827225130890053,
      "grad_norm": 8.496650695800781,
      "learning_rate": 0.00026154973821989523,
      "loss": 1.0327,
      "step": 2450
    },
    {
      "epoch": 12.879581151832461,
      "grad_norm": 5.756275177001953,
      "learning_rate": 0.00026139267015706807,
      "loss": 1.0124,
      "step": 2460
    },
    {
      "epoch": 12.93193717277487,
      "grad_norm": 3.685960292816162,
      "learning_rate": 0.0002612356020942408,
      "loss": 0.9663,
      "step": 2470
    },
    {
      "epoch": 12.984293193717278,
      "grad_norm": 5.366655349731445,
      "learning_rate": 0.0002610785340314136,
      "loss": 1.0095,
      "step": 2480
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.4418938307030129,
      "eval_loss": 3.1990926265716553,
      "eval_runtime": 0.7997,
      "eval_samples_per_second": 1743.064,
      "eval_steps_per_second": 27.509,
      "step": 2483
    },
    {
      "epoch": 13.036649214659686,
      "grad_norm": 9.297334671020508,
      "learning_rate": 0.00026092146596858637,
      "loss": 0.9474,
      "step": 2490
    },
    {
      "epoch": 13.089005235602095,
      "grad_norm": 4.963329792022705,
      "learning_rate": 0.00026076439790575915,
      "loss": 0.9662,
      "step": 2500
    },
    {
      "epoch": 13.141361256544503,
      "grad_norm": 5.486927032470703,
      "learning_rate": 0.0002606073298429319,
      "loss": 0.9615,
      "step": 2510
    },
    {
      "epoch": 13.193717277486911,
      "grad_norm": 6.301897048950195,
      "learning_rate": 0.0002604502617801047,
      "loss": 0.973,
      "step": 2520
    },
    {
      "epoch": 13.24607329842932,
      "grad_norm": 7.0659379959106445,
      "learning_rate": 0.00026029319371727744,
      "loss": 0.9622,
      "step": 2530
    },
    {
      "epoch": 13.298429319371728,
      "grad_norm": 5.379415988922119,
      "learning_rate": 0.00026013612565445023,
      "loss": 0.9542,
      "step": 2540
    },
    {
      "epoch": 13.350785340314136,
      "grad_norm": 5.871641635894775,
      "learning_rate": 0.000259979057591623,
      "loss": 0.9642,
      "step": 2550
    },
    {
      "epoch": 13.403141361256544,
      "grad_norm": 1.4797660112380981,
      "learning_rate": 0.0002598219895287958,
      "loss": 0.951,
      "step": 2560
    },
    {
      "epoch": 13.455497382198953,
      "grad_norm": 4.878653526306152,
      "learning_rate": 0.0002596649214659686,
      "loss": 0.9595,
      "step": 2570
    },
    {
      "epoch": 13.507853403141361,
      "grad_norm": 3.3535995483398438,
      "learning_rate": 0.00025950785340314136,
      "loss": 0.995,
      "step": 2580
    },
    {
      "epoch": 13.56020942408377,
      "grad_norm": 1.5126572847366333,
      "learning_rate": 0.0002593507853403141,
      "loss": 0.9782,
      "step": 2590
    },
    {
      "epoch": 13.612565445026178,
      "grad_norm": 6.167747497558594,
      "learning_rate": 0.00025919371727748693,
      "loss": 0.9833,
      "step": 2600
    },
    {
      "epoch": 13.664921465968586,
      "grad_norm": 5.052262306213379,
      "learning_rate": 0.00025903664921465966,
      "loss": 0.9748,
      "step": 2610
    },
    {
      "epoch": 13.717277486910994,
      "grad_norm": 3.375643730163574,
      "learning_rate": 0.00025887958115183244,
      "loss": 0.9793,
      "step": 2620
    },
    {
      "epoch": 13.769633507853403,
      "grad_norm": 6.93586540222168,
      "learning_rate": 0.0002587225130890052,
      "loss": 0.9858,
      "step": 2630
    },
    {
      "epoch": 13.821989528795811,
      "grad_norm": 6.855938911437988,
      "learning_rate": 0.000258565445026178,
      "loss": 0.9752,
      "step": 2640
    },
    {
      "epoch": 13.87434554973822,
      "grad_norm": 5.004664897918701,
      "learning_rate": 0.00025840837696335074,
      "loss": 0.9694,
      "step": 2650
    },
    {
      "epoch": 13.926701570680628,
      "grad_norm": 5.798703670501709,
      "learning_rate": 0.0002582513089005235,
      "loss": 0.9719,
      "step": 2660
    },
    {
      "epoch": 13.979057591623036,
      "grad_norm": 5.135096073150635,
      "learning_rate": 0.0002580942408376963,
      "loss": 0.9942,
      "step": 2670
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.4583931133428981,
      "eval_loss": 3.1825103759765625,
      "eval_runtime": 0.918,
      "eval_samples_per_second": 1518.453,
      "eval_steps_per_second": 23.964,
      "step": 2674
    },
    {
      "epoch": 14.031413612565444,
      "grad_norm": 6.230432510375977,
      "learning_rate": 0.0002579371727748691,
      "loss": 0.9395,
      "step": 2680
    },
    {
      "epoch": 14.083769633507853,
      "grad_norm": 1.4881306886672974,
      "learning_rate": 0.00025778010471204187,
      "loss": 0.9434,
      "step": 2690
    },
    {
      "epoch": 14.136125654450261,
      "grad_norm": 3.0080976486206055,
      "learning_rate": 0.00025762303664921465,
      "loss": 0.9558,
      "step": 2700
    },
    {
      "epoch": 14.188481675392671,
      "grad_norm": 1.7967246770858765,
      "learning_rate": 0.00025746596858638744,
      "loss": 0.9444,
      "step": 2710
    },
    {
      "epoch": 14.24083769633508,
      "grad_norm": 3.2199511528015137,
      "learning_rate": 0.00025730890052356016,
      "loss": 0.9374,
      "step": 2720
    },
    {
      "epoch": 14.293193717277488,
      "grad_norm": 4.84318208694458,
      "learning_rate": 0.00025715183246073295,
      "loss": 0.9691,
      "step": 2730
    },
    {
      "epoch": 14.345549738219896,
      "grad_norm": 4.723613262176514,
      "learning_rate": 0.00025699476439790573,
      "loss": 0.9549,
      "step": 2740
    },
    {
      "epoch": 14.397905759162304,
      "grad_norm": 1.8823027610778809,
      "learning_rate": 0.0002568376963350785,
      "loss": 0.946,
      "step": 2750
    },
    {
      "epoch": 14.450261780104713,
      "grad_norm": 9.019396781921387,
      "learning_rate": 0.0002566806282722513,
      "loss": 0.9924,
      "step": 2760
    },
    {
      "epoch": 14.502617801047121,
      "grad_norm": 5.689244747161865,
      "learning_rate": 0.0002565235602094241,
      "loss": 0.9801,
      "step": 2770
    },
    {
      "epoch": 14.55497382198953,
      "grad_norm": 8.246169090270996,
      "learning_rate": 0.0002563664921465968,
      "loss": 0.9913,
      "step": 2780
    },
    {
      "epoch": 14.607329842931938,
      "grad_norm": 2.269321918487549,
      "learning_rate": 0.0002562094240837696,
      "loss": 0.9806,
      "step": 2790
    },
    {
      "epoch": 14.659685863874346,
      "grad_norm": 6.014847278594971,
      "learning_rate": 0.0002560523560209424,
      "loss": 0.9825,
      "step": 2800
    },
    {
      "epoch": 14.712041884816754,
      "grad_norm": 2.2583258152008057,
      "learning_rate": 0.00025589528795811516,
      "loss": 0.9708,
      "step": 2810
    },
    {
      "epoch": 14.764397905759163,
      "grad_norm": 6.573582649230957,
      "learning_rate": 0.00025573821989528794,
      "loss": 0.9777,
      "step": 2820
    },
    {
      "epoch": 14.81675392670157,
      "grad_norm": 6.432953834533691,
      "learning_rate": 0.0002555811518324607,
      "loss": 0.9755,
      "step": 2830
    },
    {
      "epoch": 14.86910994764398,
      "grad_norm": 7.194171905517578,
      "learning_rate": 0.00025542408376963345,
      "loss": 0.9788,
      "step": 2840
    },
    {
      "epoch": 14.921465968586388,
      "grad_norm": 9.092597007751465,
      "learning_rate": 0.00025526701570680624,
      "loss": 0.9963,
      "step": 2850
    },
    {
      "epoch": 14.973821989528796,
      "grad_norm": 3.3725697994232178,
      "learning_rate": 0.000255109947643979,
      "loss": 0.9816,
      "step": 2860
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.4383070301291248,
      "eval_loss": 3.243436813354492,
      "eval_runtime": 0.9029,
      "eval_samples_per_second": 1543.942,
      "eval_steps_per_second": 24.366,
      "step": 2865
    },
    {
      "epoch": 15.026178010471204,
      "grad_norm": 3.289292097091675,
      "learning_rate": 0.0002549528795811518,
      "loss": 0.9359,
      "step": 2870
    },
    {
      "epoch": 15.078534031413612,
      "grad_norm": 6.5848708152771,
      "learning_rate": 0.0002547958115183246,
      "loss": 0.9498,
      "step": 2880
    },
    {
      "epoch": 15.13089005235602,
      "grad_norm": 3.1252923011779785,
      "learning_rate": 0.00025463874345549737,
      "loss": 0.9663,
      "step": 2890
    },
    {
      "epoch": 15.18324607329843,
      "grad_norm": 2.6333649158477783,
      "learning_rate": 0.0002544816753926701,
      "loss": 0.9375,
      "step": 2900
    },
    {
      "epoch": 15.235602094240837,
      "grad_norm": 1.9914342164993286,
      "learning_rate": 0.00025432460732984294,
      "loss": 0.9436,
      "step": 2910
    },
    {
      "epoch": 15.287958115183246,
      "grad_norm": 6.256479740142822,
      "learning_rate": 0.00025416753926701567,
      "loss": 0.9252,
      "step": 2920
    },
    {
      "epoch": 15.340314136125654,
      "grad_norm": 6.018425941467285,
      "learning_rate": 0.00025401047120418845,
      "loss": 0.9743,
      "step": 2930
    },
    {
      "epoch": 15.392670157068062,
      "grad_norm": 6.084320068359375,
      "learning_rate": 0.00025385340314136123,
      "loss": 0.9509,
      "step": 2940
    },
    {
      "epoch": 15.44502617801047,
      "grad_norm": 5.649432182312012,
      "learning_rate": 0.000253696335078534,
      "loss": 0.9442,
      "step": 2950
    },
    {
      "epoch": 15.497382198952879,
      "grad_norm": 5.058189392089844,
      "learning_rate": 0.00025353926701570675,
      "loss": 0.9519,
      "step": 2960
    },
    {
      "epoch": 15.549738219895287,
      "grad_norm": 6.898540496826172,
      "learning_rate": 0.0002533821989528796,
      "loss": 0.9714,
      "step": 2970
    },
    {
      "epoch": 15.602094240837696,
      "grad_norm": 5.7015061378479,
      "learning_rate": 0.0002532251308900523,
      "loss": 0.9563,
      "step": 2980
    },
    {
      "epoch": 15.654450261780104,
      "grad_norm": 6.81047248840332,
      "learning_rate": 0.0002530680628272251,
      "loss": 0.953,
      "step": 2990
    },
    {
      "epoch": 15.706806282722512,
      "grad_norm": 3.6852238178253174,
      "learning_rate": 0.0002529109947643979,
      "loss": 0.9861,
      "step": 3000
    },
    {
      "epoch": 15.75916230366492,
      "grad_norm": 3.9548585414886475,
      "learning_rate": 0.00025275392670157066,
      "loss": 0.9645,
      "step": 3010
    },
    {
      "epoch": 15.81151832460733,
      "grad_norm": 2.976097822189331,
      "learning_rate": 0.00025259685863874344,
      "loss": 0.954,
      "step": 3020
    },
    {
      "epoch": 15.863874345549739,
      "grad_norm": 4.609081268310547,
      "learning_rate": 0.00025243979057591623,
      "loss": 0.9611,
      "step": 3030
    },
    {
      "epoch": 15.916230366492147,
      "grad_norm": 6.6883440017700195,
      "learning_rate": 0.00025228272251308896,
      "loss": 0.9566,
      "step": 3040
    },
    {
      "epoch": 15.968586387434556,
      "grad_norm": 4.87616491317749,
      "learning_rate": 0.0002521256544502618,
      "loss": 0.9554,
      "step": 3050
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.4368723098995696,
      "eval_loss": 3.3323702812194824,
      "eval_runtime": 0.978,
      "eval_samples_per_second": 1425.41,
      "eval_steps_per_second": 22.496,
      "step": 3056
    },
    {
      "epoch": 16.020942408376964,
      "grad_norm": 4.837764263153076,
      "learning_rate": 0.0002519685863874345,
      "loss": 0.9168,
      "step": 3060
    },
    {
      "epoch": 16.073298429319372,
      "grad_norm": 5.21181058883667,
      "learning_rate": 0.0002518115183246073,
      "loss": 0.9631,
      "step": 3070
    },
    {
      "epoch": 16.12565445026178,
      "grad_norm": 3.6355552673339844,
      "learning_rate": 0.0002516544502617801,
      "loss": 0.9368,
      "step": 3080
    },
    {
      "epoch": 16.17801047120419,
      "grad_norm": 9.11032485961914,
      "learning_rate": 0.0002514973821989529,
      "loss": 0.9496,
      "step": 3090
    },
    {
      "epoch": 16.230366492146597,
      "grad_norm": 4.365641117095947,
      "learning_rate": 0.0002513403141361256,
      "loss": 0.928,
      "step": 3100
    },
    {
      "epoch": 16.282722513089006,
      "grad_norm": 6.993988037109375,
      "learning_rate": 0.00025118324607329844,
      "loss": 0.9339,
      "step": 3110
    },
    {
      "epoch": 16.335078534031414,
      "grad_norm": 2.7662179470062256,
      "learning_rate": 0.00025102617801047117,
      "loss": 0.9523,
      "step": 3120
    },
    {
      "epoch": 16.387434554973822,
      "grad_norm": 9.754866600036621,
      "learning_rate": 0.00025086910994764395,
      "loss": 0.9356,
      "step": 3130
    },
    {
      "epoch": 16.43979057591623,
      "grad_norm": 6.395421028137207,
      "learning_rate": 0.00025071204188481674,
      "loss": 0.9442,
      "step": 3140
    },
    {
      "epoch": 16.49214659685864,
      "grad_norm": 5.181407451629639,
      "learning_rate": 0.0002505549738219895,
      "loss": 0.9681,
      "step": 3150
    },
    {
      "epoch": 16.544502617801047,
      "grad_norm": 6.194027900695801,
      "learning_rate": 0.0002503979057591623,
      "loss": 0.9559,
      "step": 3160
    },
    {
      "epoch": 16.596858638743456,
      "grad_norm": 4.200610160827637,
      "learning_rate": 0.0002502408376963351,
      "loss": 0.9786,
      "step": 3170
    },
    {
      "epoch": 16.649214659685864,
      "grad_norm": 1.261246681213379,
      "learning_rate": 0.0002500837696335078,
      "loss": 0.9431,
      "step": 3180
    },
    {
      "epoch": 16.701570680628272,
      "grad_norm": 7.655255317687988,
      "learning_rate": 0.0002499267015706806,
      "loss": 0.9846,
      "step": 3190
    },
    {
      "epoch": 16.75392670157068,
      "grad_norm": 5.642587661743164,
      "learning_rate": 0.0002497696335078534,
      "loss": 0.964,
      "step": 3200
    },
    {
      "epoch": 16.80628272251309,
      "grad_norm": 6.937356472015381,
      "learning_rate": 0.00024961256544502616,
      "loss": 0.9703,
      "step": 3210
    },
    {
      "epoch": 16.858638743455497,
      "grad_norm": 5.079150199890137,
      "learning_rate": 0.00024945549738219895,
      "loss": 0.958,
      "step": 3220
    },
    {
      "epoch": 16.910994764397905,
      "grad_norm": 2.379265546798706,
      "learning_rate": 0.00024929842931937173,
      "loss": 0.992,
      "step": 3230
    },
    {
      "epoch": 16.963350785340314,
      "grad_norm": 5.7106404304504395,
      "learning_rate": 0.00024914136125654446,
      "loss": 0.9631,
      "step": 3240
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.445480631276901,
      "eval_loss": 3.2195844650268555,
      "eval_runtime": 0.91,
      "eval_samples_per_second": 1531.922,
      "eval_steps_per_second": 24.177,
      "step": 3247
    },
    {
      "epoch": 17.015706806282722,
      "grad_norm": 0.5450201630592346,
      "learning_rate": 0.00024898429319371724,
      "loss": 0.941,
      "step": 3250
    },
    {
      "epoch": 17.06806282722513,
      "grad_norm": 3.354996681213379,
      "learning_rate": 0.00024882722513089,
      "loss": 0.9254,
      "step": 3260
    },
    {
      "epoch": 17.12041884816754,
      "grad_norm": 2.3900973796844482,
      "learning_rate": 0.0002486701570680628,
      "loss": 0.9233,
      "step": 3270
    },
    {
      "epoch": 17.172774869109947,
      "grad_norm": 4.864617824554443,
      "learning_rate": 0.0002485130890052356,
      "loss": 0.9498,
      "step": 3280
    },
    {
      "epoch": 17.225130890052355,
      "grad_norm": 6.386783123016357,
      "learning_rate": 0.0002483560209424084,
      "loss": 0.9353,
      "step": 3290
    },
    {
      "epoch": 17.277486910994764,
      "grad_norm": 2.1336300373077393,
      "learning_rate": 0.0002481989528795811,
      "loss": 0.9392,
      "step": 3300
    },
    {
      "epoch": 17.329842931937172,
      "grad_norm": 3.0052707195281982,
      "learning_rate": 0.0002480418848167539,
      "loss": 0.9563,
      "step": 3310
    },
    {
      "epoch": 17.38219895287958,
      "grad_norm": 8.400447845458984,
      "learning_rate": 0.00024788481675392667,
      "loss": 0.9511,
      "step": 3320
    },
    {
      "epoch": 17.43455497382199,
      "grad_norm": 4.645837306976318,
      "learning_rate": 0.00024772774869109945,
      "loss": 0.9395,
      "step": 3330
    },
    {
      "epoch": 17.486910994764397,
      "grad_norm": 6.032843112945557,
      "learning_rate": 0.00024757068062827224,
      "loss": 0.9374,
      "step": 3340
    },
    {
      "epoch": 17.539267015706805,
      "grad_norm": 3.4415063858032227,
      "learning_rate": 0.000247413612565445,
      "loss": 0.9583,
      "step": 3350
    },
    {
      "epoch": 17.591623036649214,
      "grad_norm": 10.41012191772461,
      "learning_rate": 0.0002472565445026178,
      "loss": 0.936,
      "step": 3360
    },
    {
      "epoch": 17.643979057591622,
      "grad_norm": 4.530182361602783,
      "learning_rate": 0.00024709947643979053,
      "loss": 0.9256,
      "step": 3370
    },
    {
      "epoch": 17.69633507853403,
      "grad_norm": 4.892843246459961,
      "learning_rate": 0.0002469424083769633,
      "loss": 0.9467,
      "step": 3380
    },
    {
      "epoch": 17.74869109947644,
      "grad_norm": 3.0998542308807373,
      "learning_rate": 0.0002467853403141361,
      "loss": 0.9464,
      "step": 3390
    },
    {
      "epoch": 17.801047120418847,
      "grad_norm": 2.2833268642425537,
      "learning_rate": 0.0002466282722513089,
      "loss": 0.9589,
      "step": 3400
    },
    {
      "epoch": 17.853403141361255,
      "grad_norm": 5.384421348571777,
      "learning_rate": 0.00024647120418848167,
      "loss": 0.9411,
      "step": 3410
    },
    {
      "epoch": 17.905759162303664,
      "grad_norm": 8.272317886352539,
      "learning_rate": 0.00024631413612565445,
      "loss": 0.9734,
      "step": 3420
    },
    {
      "epoch": 17.958115183246072,
      "grad_norm": 6.842702865600586,
      "learning_rate": 0.0002461570680628272,
      "loss": 0.9583,
      "step": 3430
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.43543758967001434,
      "eval_loss": 3.324028253555298,
      "eval_runtime": 0.9839,
      "eval_samples_per_second": 1416.759,
      "eval_steps_per_second": 22.359,
      "step": 3438
    },
    {
      "epoch": 18.01047120418848,
      "grad_norm": 6.317230701446533,
      "learning_rate": 0.00024599999999999996,
      "loss": 0.9595,
      "step": 3440
    },
    {
      "epoch": 18.06282722513089,
      "grad_norm": 3.273141384124756,
      "learning_rate": 0.00024584293193717275,
      "loss": 0.9269,
      "step": 3450
    },
    {
      "epoch": 18.115183246073297,
      "grad_norm": 2.729588508605957,
      "learning_rate": 0.00024568586387434553,
      "loss": 0.9294,
      "step": 3460
    },
    {
      "epoch": 18.167539267015705,
      "grad_norm": 3.7809338569641113,
      "learning_rate": 0.0002455287958115183,
      "loss": 0.9543,
      "step": 3470
    },
    {
      "epoch": 18.219895287958114,
      "grad_norm": 5.688356399536133,
      "learning_rate": 0.0002453717277486911,
      "loss": 0.9292,
      "step": 3480
    },
    {
      "epoch": 18.272251308900522,
      "grad_norm": 1.3243045806884766,
      "learning_rate": 0.0002452146596858638,
      "loss": 0.907,
      "step": 3490
    },
    {
      "epoch": 18.324607329842934,
      "grad_norm": 5.500797271728516,
      "learning_rate": 0.00024505759162303666,
      "loss": 0.9502,
      "step": 3500
    },
    {
      "epoch": 18.376963350785342,
      "grad_norm": 5.033331394195557,
      "learning_rate": 0.0002449005235602094,
      "loss": 0.938,
      "step": 3510
    },
    {
      "epoch": 18.42931937172775,
      "grad_norm": 3.576995849609375,
      "learning_rate": 0.0002447434554973822,
      "loss": 0.9631,
      "step": 3520
    },
    {
      "epoch": 18.48167539267016,
      "grad_norm": 3.518975019454956,
      "learning_rate": 0.00024458638743455496,
      "loss": 0.9475,
      "step": 3530
    },
    {
      "epoch": 18.534031413612567,
      "grad_norm": 2.211581230163574,
      "learning_rate": 0.00024442931937172774,
      "loss": 0.915,
      "step": 3540
    },
    {
      "epoch": 18.586387434554975,
      "grad_norm": 7.814332485198975,
      "learning_rate": 0.00024427225130890047,
      "loss": 0.9439,
      "step": 3550
    },
    {
      "epoch": 18.638743455497384,
      "grad_norm": 3.691056966781616,
      "learning_rate": 0.00024411518324607328,
      "loss": 0.9218,
      "step": 3560
    },
    {
      "epoch": 18.691099476439792,
      "grad_norm": 5.24208402633667,
      "learning_rate": 0.00024395811518324606,
      "loss": 0.9424,
      "step": 3570
    },
    {
      "epoch": 18.7434554973822,
      "grad_norm": 5.9505534172058105,
      "learning_rate": 0.00024380104712041882,
      "loss": 0.9465,
      "step": 3580
    },
    {
      "epoch": 18.79581151832461,
      "grad_norm": 5.4977850914001465,
      "learning_rate": 0.0002436439790575916,
      "loss": 0.9519,
      "step": 3590
    },
    {
      "epoch": 18.848167539267017,
      "grad_norm": 3.647977590560913,
      "learning_rate": 0.00024348691099476439,
      "loss": 0.9453,
      "step": 3600
    },
    {
      "epoch": 18.900523560209425,
      "grad_norm": 6.282252788543701,
      "learning_rate": 0.00024332984293193714,
      "loss": 0.9208,
      "step": 3610
    },
    {
      "epoch": 18.952879581151834,
      "grad_norm": 2.5029518604278564,
      "learning_rate": 0.00024317277486910993,
      "loss": 0.9216,
      "step": 3620
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.4533715925394548,
      "eval_loss": 3.2351484298706055,
      "eval_runtime": 0.9338,
      "eval_samples_per_second": 1492.817,
      "eval_steps_per_second": 23.56,
      "step": 3629
    },
    {
      "epoch": 19.005235602094242,
      "grad_norm": 4.971636772155762,
      "learning_rate": 0.0002430157068062827,
      "loss": 0.9632,
      "step": 3630
    },
    {
      "epoch": 19.05759162303665,
      "grad_norm": 4.611411094665527,
      "learning_rate": 0.0002428586387434555,
      "loss": 0.9339,
      "step": 3640
    },
    {
      "epoch": 19.10994764397906,
      "grad_norm": 5.368856906890869,
      "learning_rate": 0.00024270157068062825,
      "loss": 0.9529,
      "step": 3650
    },
    {
      "epoch": 19.162303664921467,
      "grad_norm": 2.729729175567627,
      "learning_rate": 0.000242544502617801,
      "loss": 0.9277,
      "step": 3660
    },
    {
      "epoch": 19.214659685863875,
      "grad_norm": 2.7297263145446777,
      "learning_rate": 0.00024238743455497381,
      "loss": 0.9356,
      "step": 3670
    },
    {
      "epoch": 19.267015706806284,
      "grad_norm": 3.8555915355682373,
      "learning_rate": 0.00024223036649214657,
      "loss": 0.9292,
      "step": 3680
    },
    {
      "epoch": 19.319371727748692,
      "grad_norm": 4.4901227951049805,
      "learning_rate": 0.00024207329842931933,
      "loss": 0.9284,
      "step": 3690
    },
    {
      "epoch": 19.3717277486911,
      "grad_norm": 4.446022987365723,
      "learning_rate": 0.00024191623036649214,
      "loss": 0.9196,
      "step": 3700
    },
    {
      "epoch": 19.42408376963351,
      "grad_norm": 4.18642520904541,
      "learning_rate": 0.0002417591623036649,
      "loss": 0.9368,
      "step": 3710
    },
    {
      "epoch": 19.476439790575917,
      "grad_norm": 7.039414882659912,
      "learning_rate": 0.00024160209424083765,
      "loss": 0.9274,
      "step": 3720
    },
    {
      "epoch": 19.528795811518325,
      "grad_norm": 1.8750059604644775,
      "learning_rate": 0.00024144502617801046,
      "loss": 0.9257,
      "step": 3730
    },
    {
      "epoch": 19.581151832460733,
      "grad_norm": 7.912045955657959,
      "learning_rate": 0.00024128795811518322,
      "loss": 0.973,
      "step": 3740
    },
    {
      "epoch": 19.63350785340314,
      "grad_norm": 4.1753692626953125,
      "learning_rate": 0.00024113089005235597,
      "loss": 0.9426,
      "step": 3750
    },
    {
      "epoch": 19.68586387434555,
      "grad_norm": 6.475871562957764,
      "learning_rate": 0.00024097382198952878,
      "loss": 0.9123,
      "step": 3760
    },
    {
      "epoch": 19.73821989528796,
      "grad_norm": 5.266847133636475,
      "learning_rate": 0.00024081675392670154,
      "loss": 0.9638,
      "step": 3770
    },
    {
      "epoch": 19.790575916230367,
      "grad_norm": 4.466669082641602,
      "learning_rate": 0.00024065968586387435,
      "loss": 0.9208,
      "step": 3780
    },
    {
      "epoch": 19.842931937172775,
      "grad_norm": 3.811245918273926,
      "learning_rate": 0.0002405026178010471,
      "loss": 0.9564,
      "step": 3790
    },
    {
      "epoch": 19.895287958115183,
      "grad_norm": 5.038189888000488,
      "learning_rate": 0.00024034554973821986,
      "loss": 0.9287,
      "step": 3800
    },
    {
      "epoch": 19.94764397905759,
      "grad_norm": 3.2731635570526123,
      "learning_rate": 0.00024018848167539267,
      "loss": 0.9271,
      "step": 3810
    },
    {
      "epoch": 20.0,
      "grad_norm": 7.466418743133545,
      "learning_rate": 0.00024003141361256543,
      "loss": 0.9453,
      "step": 3820
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.445480631276901,
      "eval_loss": 3.2661514282226562,
      "eval_runtime": 1.0005,
      "eval_samples_per_second": 1393.328,
      "eval_steps_per_second": 21.989,
      "step": 3820
    },
    {
      "epoch": 20.05235602094241,
      "grad_norm": 7.368626594543457,
      "learning_rate": 0.00023987434554973818,
      "loss": 0.9168,
      "step": 3830
    },
    {
      "epoch": 20.104712041884817,
      "grad_norm": 6.349880695343018,
      "learning_rate": 0.000239717277486911,
      "loss": 0.9167,
      "step": 3840
    },
    {
      "epoch": 20.157068062827225,
      "grad_norm": 2.5451879501342773,
      "learning_rate": 0.00023956020942408375,
      "loss": 0.9014,
      "step": 3850
    },
    {
      "epoch": 20.209424083769633,
      "grad_norm": 4.643126964569092,
      "learning_rate": 0.0002394031413612565,
      "loss": 0.8974,
      "step": 3860
    },
    {
      "epoch": 20.26178010471204,
      "grad_norm": 2.867861747741699,
      "learning_rate": 0.00023924607329842932,
      "loss": 0.9251,
      "step": 3870
    },
    {
      "epoch": 20.31413612565445,
      "grad_norm": 3.1874728202819824,
      "learning_rate": 0.00023908900523560207,
      "loss": 0.9383,
      "step": 3880
    },
    {
      "epoch": 20.36649214659686,
      "grad_norm": 2.4984631538391113,
      "learning_rate": 0.00023893193717277483,
      "loss": 0.9306,
      "step": 3890
    },
    {
      "epoch": 20.418848167539267,
      "grad_norm": 7.123283386230469,
      "learning_rate": 0.00023877486910994764,
      "loss": 0.9422,
      "step": 3900
    },
    {
      "epoch": 20.471204188481675,
      "grad_norm": 4.822319984436035,
      "learning_rate": 0.0002386178010471204,
      "loss": 0.9349,
      "step": 3910
    },
    {
      "epoch": 20.523560209424083,
      "grad_norm": 5.328761100769043,
      "learning_rate": 0.00023846073298429315,
      "loss": 0.946,
      "step": 3920
    },
    {
      "epoch": 20.57591623036649,
      "grad_norm": 2.668616533279419,
      "learning_rate": 0.00023830366492146596,
      "loss": 0.9429,
      "step": 3930
    },
    {
      "epoch": 20.6282722513089,
      "grad_norm": 6.490002632141113,
      "learning_rate": 0.00023814659685863872,
      "loss": 0.9503,
      "step": 3940
    },
    {
      "epoch": 20.680628272251308,
      "grad_norm": 3.4508039951324463,
      "learning_rate": 0.0002379895287958115,
      "loss": 0.931,
      "step": 3950
    },
    {
      "epoch": 20.732984293193716,
      "grad_norm": 5.753974437713623,
      "learning_rate": 0.00023783246073298428,
      "loss": 0.9192,
      "step": 3960
    },
    {
      "epoch": 20.785340314136125,
      "grad_norm": 3.220883846282959,
      "learning_rate": 0.00023767539267015704,
      "loss": 0.9306,
      "step": 3970
    },
    {
      "epoch": 20.837696335078533,
      "grad_norm": 6.813930034637451,
      "learning_rate": 0.00023751832460732982,
      "loss": 0.9558,
      "step": 3980
    },
    {
      "epoch": 20.89005235602094,
      "grad_norm": 6.470665454864502,
      "learning_rate": 0.0002373612565445026,
      "loss": 0.9077,
      "step": 3990
    },
    {
      "epoch": 20.94240837696335,
      "grad_norm": 1.7716290950775146,
      "learning_rate": 0.00023720418848167536,
      "loss": 0.9241,
      "step": 4000
    },
    {
      "epoch": 20.994764397905758,
      "grad_norm": 4.5022664070129395,
      "learning_rate": 0.00023704712041884815,
      "loss": 0.9276,
      "step": 4010
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.4447632711621234,
      "eval_loss": 3.321326494216919,
      "eval_runtime": 0.9195,
      "eval_samples_per_second": 1516.023,
      "eval_steps_per_second": 23.926,
      "step": 4011
    },
    {
      "epoch": 21.047120418848166,
      "grad_norm": 4.191717147827148,
      "learning_rate": 0.00023689005235602093,
      "loss": 0.9055,
      "step": 4020
    },
    {
      "epoch": 21.099476439790575,
      "grad_norm": 3.325164556503296,
      "learning_rate": 0.00023673298429319369,
      "loss": 0.9118,
      "step": 4030
    },
    {
      "epoch": 21.151832460732983,
      "grad_norm": 1.6240181922912598,
      "learning_rate": 0.00023657591623036647,
      "loss": 0.91,
      "step": 4040
    },
    {
      "epoch": 21.20418848167539,
      "grad_norm": 5.190341472625732,
      "learning_rate": 0.00023641884816753925,
      "loss": 0.9232,
      "step": 4050
    },
    {
      "epoch": 21.2565445026178,
      "grad_norm": 6.93896484375,
      "learning_rate": 0.000236261780104712,
      "loss": 0.9465,
      "step": 4060
    },
    {
      "epoch": 21.308900523560208,
      "grad_norm": 4.845643520355225,
      "learning_rate": 0.0002361047120418848,
      "loss": 0.9472,
      "step": 4070
    },
    {
      "epoch": 21.361256544502616,
      "grad_norm": 4.325143337249756,
      "learning_rate": 0.00023594764397905758,
      "loss": 0.914,
      "step": 4080
    },
    {
      "epoch": 21.413612565445025,
      "grad_norm": 2.198265790939331,
      "learning_rate": 0.00023579057591623036,
      "loss": 0.9315,
      "step": 4090
    },
    {
      "epoch": 21.465968586387433,
      "grad_norm": 3.1504647731781006,
      "learning_rate": 0.00023563350785340311,
      "loss": 0.9222,
      "step": 4100
    },
    {
      "epoch": 21.51832460732984,
      "grad_norm": 3.538858413696289,
      "learning_rate": 0.0002354764397905759,
      "loss": 0.9388,
      "step": 4110
    },
    {
      "epoch": 21.57068062827225,
      "grad_norm": 3.904648780822754,
      "learning_rate": 0.00023531937172774868,
      "loss": 0.9276,
      "step": 4120
    },
    {
      "epoch": 21.62303664921466,
      "grad_norm": 6.617264747619629,
      "learning_rate": 0.00023516230366492144,
      "loss": 0.929,
      "step": 4130
    },
    {
      "epoch": 21.675392670157066,
      "grad_norm": 6.886886119842529,
      "learning_rate": 0.00023500523560209422,
      "loss": 0.9319,
      "step": 4140
    },
    {
      "epoch": 21.727748691099478,
      "grad_norm": 5.839188575744629,
      "learning_rate": 0.000234848167539267,
      "loss": 0.9094,
      "step": 4150
    },
    {
      "epoch": 21.780104712041886,
      "grad_norm": 0.8735700249671936,
      "learning_rate": 0.00023469109947643976,
      "loss": 0.9284,
      "step": 4160
    },
    {
      "epoch": 21.832460732984295,
      "grad_norm": 5.694913864135742,
      "learning_rate": 0.00023453403141361254,
      "loss": 0.9339,
      "step": 4170
    },
    {
      "epoch": 21.884816753926703,
      "grad_norm": 3.2726259231567383,
      "learning_rate": 0.00023437696335078533,
      "loss": 0.9007,
      "step": 4180
    },
    {
      "epoch": 21.93717277486911,
      "grad_norm": 2.1928000450134277,
      "learning_rate": 0.00023421989528795808,
      "loss": 0.9186,
      "step": 4190
    },
    {
      "epoch": 21.98952879581152,
      "grad_norm": 5.995898246765137,
      "learning_rate": 0.00023406282722513087,
      "loss": 0.921,
      "step": 4200
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.44763271162123386,
      "eval_loss": 3.305919647216797,
      "eval_runtime": 0.9808,
      "eval_samples_per_second": 1421.319,
      "eval_steps_per_second": 22.431,
      "step": 4202
    },
    {
      "epoch": 22.041884816753928,
      "grad_norm": 4.629039287567139,
      "learning_rate": 0.00023390575916230365,
      "loss": 0.8928,
      "step": 4210
    },
    {
      "epoch": 22.094240837696336,
      "grad_norm": 3.22707200050354,
      "learning_rate": 0.0002337486910994764,
      "loss": 0.912,
      "step": 4220
    },
    {
      "epoch": 22.146596858638745,
      "grad_norm": 5.948202133178711,
      "learning_rate": 0.0002335916230366492,
      "loss": 0.9033,
      "step": 4230
    },
    {
      "epoch": 22.198952879581153,
      "grad_norm": 4.219340801239014,
      "learning_rate": 0.00023343455497382197,
      "loss": 0.9054,
      "step": 4240
    },
    {
      "epoch": 22.25130890052356,
      "grad_norm": 4.9460625648498535,
      "learning_rate": 0.00023327748691099473,
      "loss": 0.9124,
      "step": 4250
    },
    {
      "epoch": 22.30366492146597,
      "grad_norm": 5.094200611114502,
      "learning_rate": 0.00023313612565445022,
      "loss": 0.9156,
      "step": 4260
    },
    {
      "epoch": 22.356020942408378,
      "grad_norm": 3.045931577682495,
      "learning_rate": 0.00023297905759162303,
      "loss": 0.9064,
      "step": 4270
    },
    {
      "epoch": 22.408376963350786,
      "grad_norm": 2.9894025325775146,
      "learning_rate": 0.0002328219895287958,
      "loss": 0.9245,
      "step": 4280
    },
    {
      "epoch": 22.460732984293195,
      "grad_norm": 1.7897893190383911,
      "learning_rate": 0.00023266492146596855,
      "loss": 0.9184,
      "step": 4290
    },
    {
      "epoch": 22.513089005235603,
      "grad_norm": 2.62532901763916,
      "learning_rate": 0.00023250785340314136,
      "loss": 0.904,
      "step": 4300
    },
    {
      "epoch": 22.56544502617801,
      "grad_norm": 4.282922267913818,
      "learning_rate": 0.0002323507853403141,
      "loss": 0.9098,
      "step": 4310
    },
    {
      "epoch": 22.61780104712042,
      "grad_norm": 8.534503936767578,
      "learning_rate": 0.00023219371727748687,
      "loss": 0.9189,
      "step": 4320
    },
    {
      "epoch": 22.670157068062828,
      "grad_norm": 7.56268310546875,
      "learning_rate": 0.00023203664921465968,
      "loss": 0.9361,
      "step": 4330
    },
    {
      "epoch": 22.722513089005236,
      "grad_norm": 4.166850566864014,
      "learning_rate": 0.00023187958115183243,
      "loss": 0.9259,
      "step": 4340
    },
    {
      "epoch": 22.774869109947645,
      "grad_norm": 2.619162082672119,
      "learning_rate": 0.0002317225130890052,
      "loss": 0.9267,
      "step": 4350
    },
    {
      "epoch": 22.827225130890053,
      "grad_norm": 8.854317665100098,
      "learning_rate": 0.000231565445026178,
      "loss": 0.9069,
      "step": 4360
    },
    {
      "epoch": 22.87958115183246,
      "grad_norm": 7.185293674468994,
      "learning_rate": 0.00023140837696335076,
      "loss": 0.9456,
      "step": 4370
    },
    {
      "epoch": 22.93193717277487,
      "grad_norm": 3.310300827026367,
      "learning_rate": 0.0002312513089005235,
      "loss": 0.921,
      "step": 4380
    },
    {
      "epoch": 22.984293193717278,
      "grad_norm": 3.865115165710449,
      "learning_rate": 0.00023109424083769632,
      "loss": 0.9323,
      "step": 4390
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.44045911047345765,
      "eval_loss": 3.3055543899536133,
      "eval_runtime": 0.8948,
      "eval_samples_per_second": 1557.816,
      "eval_steps_per_second": 24.585,
      "step": 4393
    },
    {
      "epoch": 23.036649214659686,
      "grad_norm": 3.4093523025512695,
      "learning_rate": 0.00023093717277486908,
      "loss": 0.9171,
      "step": 4400
    },
    {
      "epoch": 23.089005235602095,
      "grad_norm": 1.4831397533416748,
      "learning_rate": 0.0002307801047120419,
      "loss": 0.8992,
      "step": 4410
    },
    {
      "epoch": 23.141361256544503,
      "grad_norm": 1.4500569105148315,
      "learning_rate": 0.00023062303664921465,
      "loss": 0.9096,
      "step": 4420
    },
    {
      "epoch": 23.19371727748691,
      "grad_norm": 6.384472370147705,
      "learning_rate": 0.0002304659685863874,
      "loss": 0.9247,
      "step": 4430
    },
    {
      "epoch": 23.24607329842932,
      "grad_norm": 0.6266248822212219,
      "learning_rate": 0.0002303089005235602,
      "loss": 0.8838,
      "step": 4440
    },
    {
      "epoch": 23.298429319371728,
      "grad_norm": 5.6426167488098145,
      "learning_rate": 0.00023015183246073297,
      "loss": 0.9172,
      "step": 4450
    },
    {
      "epoch": 23.350785340314136,
      "grad_norm": 3.0895988941192627,
      "learning_rate": 0.00022999476439790572,
      "loss": 0.8975,
      "step": 4460
    },
    {
      "epoch": 23.403141361256544,
      "grad_norm": 5.633493900299072,
      "learning_rate": 0.00022983769633507854,
      "loss": 0.9313,
      "step": 4470
    },
    {
      "epoch": 23.455497382198953,
      "grad_norm": 4.479482173919678,
      "learning_rate": 0.0002296806282722513,
      "loss": 0.9093,
      "step": 4480
    },
    {
      "epoch": 23.50785340314136,
      "grad_norm": 9.66997241973877,
      "learning_rate": 0.00022952356020942405,
      "loss": 0.9388,
      "step": 4490
    },
    {
      "epoch": 23.56020942408377,
      "grad_norm": 10.766029357910156,
      "learning_rate": 0.00022936649214659686,
      "loss": 0.912,
      "step": 4500
    },
    {
      "epoch": 23.612565445026178,
      "grad_norm": 2.862661123275757,
      "learning_rate": 0.00022920942408376961,
      "loss": 0.9266,
      "step": 4510
    },
    {
      "epoch": 23.664921465968586,
      "grad_norm": 6.124692440032959,
      "learning_rate": 0.00022905235602094237,
      "loss": 0.9121,
      "step": 4520
    },
    {
      "epoch": 23.717277486910994,
      "grad_norm": 0.561856210231781,
      "learning_rate": 0.00022889528795811518,
      "loss": 0.8871,
      "step": 4530
    },
    {
      "epoch": 23.769633507853403,
      "grad_norm": 6.598700523376465,
      "learning_rate": 0.00022873821989528794,
      "loss": 0.9188,
      "step": 4540
    },
    {
      "epoch": 23.82198952879581,
      "grad_norm": 5.593700885772705,
      "learning_rate": 0.00022858115183246072,
      "loss": 0.9212,
      "step": 4550
    },
    {
      "epoch": 23.87434554973822,
      "grad_norm": 3.7023072242736816,
      "learning_rate": 0.0002284240837696335,
      "loss": 0.9383,
      "step": 4560
    },
    {
      "epoch": 23.926701570680628,
      "grad_norm": 4.358371257781982,
      "learning_rate": 0.00022826701570680626,
      "loss": 0.9531,
      "step": 4570
    },
    {
      "epoch": 23.979057591623036,
      "grad_norm": 4.120236396789551,
      "learning_rate": 0.00022810994764397904,
      "loss": 0.9285,
      "step": 4580
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.4411764705882353,
      "eval_loss": 3.292165994644165,
      "eval_runtime": 1.0249,
      "eval_samples_per_second": 1360.113,
      "eval_steps_per_second": 21.465,
      "step": 4584
    },
    {
      "epoch": 24.031413612565444,
      "grad_norm": 3.9259371757507324,
      "learning_rate": 0.00022795287958115183,
      "loss": 0.904,
      "step": 4590
    },
    {
      "epoch": 24.083769633507853,
      "grad_norm": 9.73690414428711,
      "learning_rate": 0.00022779581151832458,
      "loss": 0.9045,
      "step": 4600
    },
    {
      "epoch": 24.13612565445026,
      "grad_norm": 1.270725965499878,
      "learning_rate": 0.00022763874345549737,
      "loss": 0.9063,
      "step": 4610
    },
    {
      "epoch": 24.18848167539267,
      "grad_norm": 9.674847602844238,
      "learning_rate": 0.00022748167539267015,
      "loss": 0.8946,
      "step": 4620
    },
    {
      "epoch": 24.240837696335078,
      "grad_norm": 1.3021501302719116,
      "learning_rate": 0.0002273246073298429,
      "loss": 0.9101,
      "step": 4630
    },
    {
      "epoch": 24.293193717277486,
      "grad_norm": 6.860429286956787,
      "learning_rate": 0.0002271675392670157,
      "loss": 0.8956,
      "step": 4640
    },
    {
      "epoch": 24.345549738219894,
      "grad_norm": 11.485658645629883,
      "learning_rate": 0.00022701047120418847,
      "loss": 0.9306,
      "step": 4650
    },
    {
      "epoch": 24.397905759162303,
      "grad_norm": 2.856876850128174,
      "learning_rate": 0.00022685340314136123,
      "loss": 0.9229,
      "step": 4660
    },
    {
      "epoch": 24.45026178010471,
      "grad_norm": 3.9611926078796387,
      "learning_rate": 0.000226696335078534,
      "loss": 0.9181,
      "step": 4670
    },
    {
      "epoch": 24.50261780104712,
      "grad_norm": 3.2218515872955322,
      "learning_rate": 0.0002265392670157068,
      "loss": 0.9357,
      "step": 4680
    },
    {
      "epoch": 24.554973821989527,
      "grad_norm": 2.1931843757629395,
      "learning_rate": 0.00022638219895287955,
      "loss": 0.9143,
      "step": 4690
    },
    {
      "epoch": 24.607329842931936,
      "grad_norm": 6.005626201629639,
      "learning_rate": 0.00022622513089005233,
      "loss": 0.9264,
      "step": 4700
    },
    {
      "epoch": 24.659685863874344,
      "grad_norm": 4.8805952072143555,
      "learning_rate": 0.00022606806282722512,
      "loss": 0.9361,
      "step": 4710
    },
    {
      "epoch": 24.712041884816752,
      "grad_norm": 4.063103199005127,
      "learning_rate": 0.0002259109947643979,
      "loss": 0.9076,
      "step": 4720
    },
    {
      "epoch": 24.76439790575916,
      "grad_norm": 5.611328125,
      "learning_rate": 0.00022575392670157066,
      "loss": 0.9376,
      "step": 4730
    },
    {
      "epoch": 24.81675392670157,
      "grad_norm": 1.1901427507400513,
      "learning_rate": 0.00022559685863874344,
      "loss": 0.9335,
      "step": 4740
    },
    {
      "epoch": 24.869109947643977,
      "grad_norm": 5.168900012969971,
      "learning_rate": 0.00022543979057591622,
      "loss": 0.9221,
      "step": 4750
    },
    {
      "epoch": 24.921465968586386,
      "grad_norm": 4.589201927185059,
      "learning_rate": 0.00022528272251308898,
      "loss": 0.931,
      "step": 4760
    },
    {
      "epoch": 24.973821989528794,
      "grad_norm": 6.389994144439697,
      "learning_rate": 0.00022512565445026176,
      "loss": 0.9278,
      "step": 4770
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.4469153515064562,
      "eval_loss": 3.316126823425293,
      "eval_runtime": 0.9487,
      "eval_samples_per_second": 1469.33,
      "eval_steps_per_second": 23.189,
      "step": 4775
    },
    {
      "epoch": 25.026178010471206,
      "grad_norm": 0.5007871389389038,
      "learning_rate": 0.00022496858638743455,
      "loss": 0.9092,
      "step": 4780
    },
    {
      "epoch": 25.078534031413614,
      "grad_norm": 4.458266258239746,
      "learning_rate": 0.0002248115183246073,
      "loss": 0.9218,
      "step": 4790
    },
    {
      "epoch": 25.130890052356023,
      "grad_norm": 5.061496257781982,
      "learning_rate": 0.00022465445026178008,
      "loss": 0.8923,
      "step": 4800
    },
    {
      "epoch": 25.18324607329843,
      "grad_norm": 3.281191349029541,
      "learning_rate": 0.00022449738219895287,
      "loss": 0.9026,
      "step": 4810
    },
    {
      "epoch": 25.23560209424084,
      "grad_norm": 2.994739055633545,
      "learning_rate": 0.00022434031413612562,
      "loss": 0.9248,
      "step": 4820
    },
    {
      "epoch": 25.287958115183248,
      "grad_norm": 6.737112522125244,
      "learning_rate": 0.0002241832460732984,
      "loss": 0.9153,
      "step": 4830
    },
    {
      "epoch": 25.340314136125656,
      "grad_norm": 6.863494396209717,
      "learning_rate": 0.0002240261780104712,
      "loss": 0.9177,
      "step": 4840
    },
    {
      "epoch": 25.392670157068064,
      "grad_norm": 1.068621277809143,
      "learning_rate": 0.00022386910994764395,
      "loss": 0.8978,
      "step": 4850
    },
    {
      "epoch": 25.445026178010473,
      "grad_norm": 3.6791844367980957,
      "learning_rate": 0.00022371204188481676,
      "loss": 0.9096,
      "step": 4860
    },
    {
      "epoch": 25.49738219895288,
      "grad_norm": 4.351377964019775,
      "learning_rate": 0.0002235549738219895,
      "loss": 0.9021,
      "step": 4870
    },
    {
      "epoch": 25.54973821989529,
      "grad_norm": 3.2154717445373535,
      "learning_rate": 0.00022339790575916227,
      "loss": 0.9321,
      "step": 4880
    },
    {
      "epoch": 25.602094240837697,
      "grad_norm": 5.903324127197266,
      "learning_rate": 0.00022324083769633508,
      "loss": 0.9074,
      "step": 4890
    },
    {
      "epoch": 25.654450261780106,
      "grad_norm": 5.102843761444092,
      "learning_rate": 0.00022308376963350784,
      "loss": 0.947,
      "step": 4900
    },
    {
      "epoch": 25.706806282722514,
      "grad_norm": 4.932746887207031,
      "learning_rate": 0.0002229267015706806,
      "loss": 0.9527,
      "step": 4910
    },
    {
      "epoch": 25.759162303664922,
      "grad_norm": 5.881234645843506,
      "learning_rate": 0.0002227696335078534,
      "loss": 0.9159,
      "step": 4920
    },
    {
      "epoch": 25.81151832460733,
      "grad_norm": 6.436763763427734,
      "learning_rate": 0.00022261256544502616,
      "loss": 0.9342,
      "step": 4930
    },
    {
      "epoch": 25.86387434554974,
      "grad_norm": 4.226039886474609,
      "learning_rate": 0.00022245549738219891,
      "loss": 0.9396,
      "step": 4940
    },
    {
      "epoch": 25.916230366492147,
      "grad_norm": 7.513915538787842,
      "learning_rate": 0.00022229842931937172,
      "loss": 0.9238,
      "step": 4950
    },
    {
      "epoch": 25.968586387434556,
      "grad_norm": 3.846266984939575,
      "learning_rate": 0.00022214136125654448,
      "loss": 0.9083,
      "step": 4960
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.4411764705882353,
      "eval_loss": 3.385538339614868,
      "eval_runtime": 0.9349,
      "eval_samples_per_second": 1491.099,
      "eval_steps_per_second": 23.532,
      "step": 4966
    },
    {
      "epoch": 26.020942408376964,
      "grad_norm": 1.810573935508728,
      "learning_rate": 0.00022198429319371724,
      "loss": 0.9189,
      "step": 4970
    },
    {
      "epoch": 26.073298429319372,
      "grad_norm": 2.9135382175445557,
      "learning_rate": 0.00022182722513089005,
      "loss": 0.8873,
      "step": 4980
    },
    {
      "epoch": 26.12565445026178,
      "grad_norm": 1.4473216533660889,
      "learning_rate": 0.0002216701570680628,
      "loss": 0.8957,
      "step": 4990
    },
    {
      "epoch": 26.17801047120419,
      "grad_norm": 4.615304946899414,
      "learning_rate": 0.00022151308900523556,
      "loss": 0.9099,
      "step": 5000
    },
    {
      "epoch": 26.230366492146597,
      "grad_norm": 1.138534665107727,
      "learning_rate": 0.00022135602094240837,
      "loss": 0.9046,
      "step": 5010
    },
    {
      "epoch": 26.282722513089006,
      "grad_norm": 5.856922149658203,
      "learning_rate": 0.00022119895287958113,
      "loss": 0.8926,
      "step": 5020
    },
    {
      "epoch": 26.335078534031414,
      "grad_norm": 6.502886772155762,
      "learning_rate": 0.0002210418848167539,
      "loss": 0.9084,
      "step": 5030
    },
    {
      "epoch": 26.387434554973822,
      "grad_norm": 3.5934317111968994,
      "learning_rate": 0.0002208848167539267,
      "loss": 0.8945,
      "step": 5040
    },
    {
      "epoch": 26.43979057591623,
      "grad_norm": 5.271275997161865,
      "learning_rate": 0.00022072774869109945,
      "loss": 0.9031,
      "step": 5050
    },
    {
      "epoch": 26.49214659685864,
      "grad_norm": 4.587697505950928,
      "learning_rate": 0.00022057068062827223,
      "loss": 0.9043,
      "step": 5060
    },
    {
      "epoch": 26.544502617801047,
      "grad_norm": 3.9913294315338135,
      "learning_rate": 0.00022041361256544502,
      "loss": 0.9005,
      "step": 5070
    },
    {
      "epoch": 26.596858638743456,
      "grad_norm": 2.7008979320526123,
      "learning_rate": 0.00022025654450261777,
      "loss": 0.901,
      "step": 5080
    },
    {
      "epoch": 26.649214659685864,
      "grad_norm": 6.198349952697754,
      "learning_rate": 0.00022009947643979055,
      "loss": 0.9163,
      "step": 5090
    },
    {
      "epoch": 26.701570680628272,
      "grad_norm": 2.3758020401000977,
      "learning_rate": 0.00021994240837696334,
      "loss": 0.9083,
      "step": 5100
    },
    {
      "epoch": 26.75392670157068,
      "grad_norm": 8.450272560119629,
      "learning_rate": 0.0002197853403141361,
      "loss": 0.93,
      "step": 5110
    },
    {
      "epoch": 26.80628272251309,
      "grad_norm": 3.1885342597961426,
      "learning_rate": 0.00021962827225130888,
      "loss": 0.9113,
      "step": 5120
    },
    {
      "epoch": 26.858638743455497,
      "grad_norm": 5.818608283996582,
      "learning_rate": 0.00021947120418848166,
      "loss": 0.9073,
      "step": 5130
    },
    {
      "epoch": 26.910994764397905,
      "grad_norm": 3.3084356784820557,
      "learning_rate": 0.00021931413612565442,
      "loss": 0.9162,
      "step": 5140
    },
    {
      "epoch": 26.963350785340314,
      "grad_norm": 6.028090953826904,
      "learning_rate": 0.0002191570680628272,
      "loss": 0.9099,
      "step": 5150
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.42252510760401724,
      "eval_loss": 3.495011806488037,
      "eval_runtime": 0.9968,
      "eval_samples_per_second": 1398.48,
      "eval_steps_per_second": 22.071,
      "step": 5157
    },
    {
      "epoch": 27.015706806282722,
      "grad_norm": 0.4627296030521393,
      "learning_rate": 0.00021899999999999998,
      "loss": 0.9205,
      "step": 5160
    },
    {
      "epoch": 27.06806282722513,
      "grad_norm": 3.1533708572387695,
      "learning_rate": 0.00021884293193717277,
      "loss": 0.8906,
      "step": 5170
    },
    {
      "epoch": 27.12041884816754,
      "grad_norm": 5.3618669509887695,
      "learning_rate": 0.00021868586387434552,
      "loss": 0.8948,
      "step": 5180
    },
    {
      "epoch": 27.172774869109947,
      "grad_norm": 0.9291394352912903,
      "learning_rate": 0.0002185287958115183,
      "loss": 0.8908,
      "step": 5190
    },
    {
      "epoch": 27.225130890052355,
      "grad_norm": 4.103740692138672,
      "learning_rate": 0.0002183717277486911,
      "loss": 0.897,
      "step": 5200
    },
    {
      "epoch": 27.277486910994764,
      "grad_norm": 8.505743026733398,
      "learning_rate": 0.00021821465968586385,
      "loss": 0.9092,
      "step": 5210
    },
    {
      "epoch": 27.329842931937172,
      "grad_norm": 3.632603883743286,
      "learning_rate": 0.00021805759162303663,
      "loss": 0.8976,
      "step": 5220
    },
    {
      "epoch": 27.38219895287958,
      "grad_norm": 1.2458301782608032,
      "learning_rate": 0.0002179005235602094,
      "loss": 0.9059,
      "step": 5230
    },
    {
      "epoch": 27.43455497382199,
      "grad_norm": 4.17633056640625,
      "learning_rate": 0.00021774345549738217,
      "loss": 0.9096,
      "step": 5240
    },
    {
      "epoch": 27.486910994764397,
      "grad_norm": 7.549589157104492,
      "learning_rate": 0.00021758638743455495,
      "loss": 0.9303,
      "step": 5250
    },
    {
      "epoch": 27.539267015706805,
      "grad_norm": 5.048033237457275,
      "learning_rate": 0.00021742931937172773,
      "loss": 0.9009,
      "step": 5260
    },
    {
      "epoch": 27.591623036649214,
      "grad_norm": 4.969552516937256,
      "learning_rate": 0.0002172722513089005,
      "loss": 0.9072,
      "step": 5270
    },
    {
      "epoch": 27.643979057591622,
      "grad_norm": 6.305933952331543,
      "learning_rate": 0.00021711518324607327,
      "loss": 0.9097,
      "step": 5280
    },
    {
      "epoch": 27.69633507853403,
      "grad_norm": 6.475690841674805,
      "learning_rate": 0.00021695811518324606,
      "loss": 0.9062,
      "step": 5290
    },
    {
      "epoch": 27.74869109947644,
      "grad_norm": 6.010825157165527,
      "learning_rate": 0.00021680104712041881,
      "loss": 0.9234,
      "step": 5300
    },
    {
      "epoch": 27.801047120418847,
      "grad_norm": 5.881443023681641,
      "learning_rate": 0.0002166439790575916,
      "loss": 0.9017,
      "step": 5310
    },
    {
      "epoch": 27.853403141361255,
      "grad_norm": 7.113446235656738,
      "learning_rate": 0.00021648691099476438,
      "loss": 0.9194,
      "step": 5320
    },
    {
      "epoch": 27.905759162303664,
      "grad_norm": 5.348800182342529,
      "learning_rate": 0.00021632984293193714,
      "loss": 0.922,
      "step": 5330
    },
    {
      "epoch": 27.958115183246072,
      "grad_norm": 4.751761436462402,
      "learning_rate": 0.00021617277486910995,
      "loss": 0.9146,
      "step": 5340
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.4418938307030129,
      "eval_loss": 3.348332166671753,
      "eval_runtime": 1.014,
      "eval_samples_per_second": 1374.805,
      "eval_steps_per_second": 21.697,
      "step": 5348
    },
    {
      "epoch": 28.01047120418848,
      "grad_norm": 5.240410327911377,
      "learning_rate": 0.0002160157068062827,
      "loss": 0.9235,
      "step": 5350
    },
    {
      "epoch": 28.06282722513089,
      "grad_norm": 4.025855541229248,
      "learning_rate": 0.00021585863874345546,
      "loss": 0.8824,
      "step": 5360
    },
    {
      "epoch": 28.115183246073297,
      "grad_norm": 1.4666121006011963,
      "learning_rate": 0.00021570157068062827,
      "loss": 0.9182,
      "step": 5370
    },
    {
      "epoch": 28.167539267015705,
      "grad_norm": 3.862703323364258,
      "learning_rate": 0.00021554450261780103,
      "loss": 0.8851,
      "step": 5380
    },
    {
      "epoch": 28.219895287958114,
      "grad_norm": 3.5670900344848633,
      "learning_rate": 0.00021538743455497378,
      "loss": 0.8987,
      "step": 5390
    },
    {
      "epoch": 28.272251308900522,
      "grad_norm": 5.693488121032715,
      "learning_rate": 0.0002152303664921466,
      "loss": 0.9034,
      "step": 5400
    },
    {
      "epoch": 28.324607329842934,
      "grad_norm": 4.528549671173096,
      "learning_rate": 0.00021507329842931935,
      "loss": 0.8937,
      "step": 5410
    },
    {
      "epoch": 28.376963350785342,
      "grad_norm": 4.0816121101379395,
      "learning_rate": 0.0002149162303664921,
      "loss": 0.8989,
      "step": 5420
    },
    {
      "epoch": 28.42931937172775,
      "grad_norm": 3.0351979732513428,
      "learning_rate": 0.00021475916230366491,
      "loss": 0.8887,
      "step": 5430
    },
    {
      "epoch": 28.48167539267016,
      "grad_norm": 0.4338034391403198,
      "learning_rate": 0.00021460209424083767,
      "loss": 0.8838,
      "step": 5440
    },
    {
      "epoch": 28.534031413612567,
      "grad_norm": 6.778226375579834,
      "learning_rate": 0.00021444502617801043,
      "loss": 0.9129,
      "step": 5450
    },
    {
      "epoch": 28.586387434554975,
      "grad_norm": 7.646393775939941,
      "learning_rate": 0.00021428795811518324,
      "loss": 0.8949,
      "step": 5460
    },
    {
      "epoch": 28.638743455497384,
      "grad_norm": 1.4773341417312622,
      "learning_rate": 0.000214130890052356,
      "loss": 0.8965,
      "step": 5470
    },
    {
      "epoch": 28.691099476439792,
      "grad_norm": 4.7266082763671875,
      "learning_rate": 0.0002139738219895288,
      "loss": 0.9187,
      "step": 5480
    },
    {
      "epoch": 28.7434554973822,
      "grad_norm": 0.8254387378692627,
      "learning_rate": 0.00021381675392670156,
      "loss": 0.9185,
      "step": 5490
    },
    {
      "epoch": 28.79581151832461,
      "grad_norm": 2.4924814701080322,
      "learning_rate": 0.00021365968586387432,
      "loss": 0.9267,
      "step": 5500
    },
    {
      "epoch": 28.848167539267017,
      "grad_norm": 0.6097091436386108,
      "learning_rate": 0.00021350261780104713,
      "loss": 0.8955,
      "step": 5510
    },
    {
      "epoch": 28.900523560209425,
      "grad_norm": 1.4300745725631714,
      "learning_rate": 0.00021334554973821988,
      "loss": 0.8968,
      "step": 5520
    },
    {
      "epoch": 28.952879581151834,
      "grad_norm": 7.500454425811768,
      "learning_rate": 0.00021318848167539264,
      "loss": 0.9005,
      "step": 5530
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.44619799139167865,
      "eval_loss": 3.417250394821167,
      "eval_runtime": 1.014,
      "eval_samples_per_second": 1374.758,
      "eval_steps_per_second": 21.696,
      "step": 5539
    },
    {
      "epoch": 29.005235602094242,
      "grad_norm": 13.277689933776855,
      "learning_rate": 0.00021303141361256545,
      "loss": 0.9023,
      "step": 5540
    },
    {
      "epoch": 29.05759162303665,
      "grad_norm": 7.559353351593018,
      "learning_rate": 0.0002128743455497382,
      "loss": 0.8853,
      "step": 5550
    },
    {
      "epoch": 29.10994764397906,
      "grad_norm": 2.3704934120178223,
      "learning_rate": 0.00021271727748691096,
      "loss": 0.8808,
      "step": 5560
    },
    {
      "epoch": 29.162303664921467,
      "grad_norm": 2.534377336502075,
      "learning_rate": 0.00021256020942408377,
      "loss": 0.9009,
      "step": 5570
    },
    {
      "epoch": 29.214659685863875,
      "grad_norm": 4.206779956817627,
      "learning_rate": 0.00021240314136125653,
      "loss": 0.902,
      "step": 5580
    },
    {
      "epoch": 29.267015706806284,
      "grad_norm": 0.4169387221336365,
      "learning_rate": 0.00021224607329842928,
      "loss": 0.8873,
      "step": 5590
    },
    {
      "epoch": 29.319371727748692,
      "grad_norm": 0.5740642547607422,
      "learning_rate": 0.0002120890052356021,
      "loss": 0.8807,
      "step": 5600
    },
    {
      "epoch": 29.3717277486911,
      "grad_norm": 0.19254934787750244,
      "learning_rate": 0.00021193193717277485,
      "loss": 0.8798,
      "step": 5610
    },
    {
      "epoch": 29.42408376963351,
      "grad_norm": 1.1990994215011597,
      "learning_rate": 0.0002117748691099476,
      "loss": 0.8988,
      "step": 5620
    },
    {
      "epoch": 29.476439790575917,
      "grad_norm": 7.878045082092285,
      "learning_rate": 0.00021161780104712042,
      "loss": 0.902,
      "step": 5630
    },
    {
      "epoch": 29.528795811518325,
      "grad_norm": 0.5820636749267578,
      "learning_rate": 0.00021146073298429317,
      "loss": 0.8882,
      "step": 5640
    },
    {
      "epoch": 29.581151832460733,
      "grad_norm": 2.614326238632202,
      "learning_rate": 0.00021130366492146596,
      "loss": 0.8874,
      "step": 5650
    },
    {
      "epoch": 29.63350785340314,
      "grad_norm": 2.8661346435546875,
      "learning_rate": 0.00021114659685863874,
      "loss": 0.8899,
      "step": 5660
    },
    {
      "epoch": 29.68586387434555,
      "grad_norm": 4.620906352996826,
      "learning_rate": 0.0002109895287958115,
      "loss": 0.8892,
      "step": 5670
    },
    {
      "epoch": 29.73821989528796,
      "grad_norm": 4.9959235191345215,
      "learning_rate": 0.00021083246073298428,
      "loss": 0.8882,
      "step": 5680
    },
    {
      "epoch": 29.790575916230367,
      "grad_norm": 5.331345081329346,
      "learning_rate": 0.00021067539267015706,
      "loss": 0.8874,
      "step": 5690
    },
    {
      "epoch": 29.842931937172775,
      "grad_norm": 0.9076821208000183,
      "learning_rate": 0.00021051832460732982,
      "loss": 0.8807,
      "step": 5700
    },
    {
      "epoch": 29.895287958115183,
      "grad_norm": 2.398728847503662,
      "learning_rate": 0.0002103612565445026,
      "loss": 0.8955,
      "step": 5710
    },
    {
      "epoch": 29.94764397905759,
      "grad_norm": 0.5039041638374329,
      "learning_rate": 0.00021020418848167539,
      "loss": 0.9043,
      "step": 5720
    },
    {
      "epoch": 30.0,
      "grad_norm": Infinity,
      "learning_rate": 0.00021004712041884814,
      "loss": 0.9346,
      "step": 5730
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.4261119081779053,
      "eval_loss": 3.486844778060913,
      "eval_runtime": 1.0791,
      "eval_samples_per_second": 1291.811,
      "eval_steps_per_second": 20.387,
      "step": 5730
    },
    {
      "epoch": 30.05235602094241,
      "grad_norm": 3.5968449115753174,
      "learning_rate": 0.00020990575916230364,
      "loss": 0.8986,
      "step": 5740
    },
    {
      "epoch": 30.104712041884817,
      "grad_norm": 3.9796195030212402,
      "learning_rate": 0.00020974869109947642,
      "loss": 0.8979,
      "step": 5750
    },
    {
      "epoch": 30.157068062827225,
      "grad_norm": 6.601965427398682,
      "learning_rate": 0.0002095916230366492,
      "loss": 0.8984,
      "step": 5760
    },
    {
      "epoch": 30.209424083769633,
      "grad_norm": 2.2185585498809814,
      "learning_rate": 0.00020943455497382196,
      "loss": 0.8902,
      "step": 5770
    },
    {
      "epoch": 30.26178010471204,
      "grad_norm": 2.6332530975341797,
      "learning_rate": 0.00020927748691099474,
      "loss": 0.8966,
      "step": 5780
    },
    {
      "epoch": 30.31413612565445,
      "grad_norm": 0.5771524906158447,
      "learning_rate": 0.00020912041884816752,
      "loss": 0.9071,
      "step": 5790
    },
    {
      "epoch": 30.36649214659686,
      "grad_norm": 2.6946732997894287,
      "learning_rate": 0.0002089633507853403,
      "loss": 0.8929,
      "step": 5800
    },
    {
      "epoch": 30.418848167539267,
      "grad_norm": 1.8176028728485107,
      "learning_rate": 0.00020880628272251306,
      "loss": 0.9106,
      "step": 5810
    },
    {
      "epoch": 30.471204188481675,
      "grad_norm": 6.002224922180176,
      "learning_rate": 0.00020864921465968585,
      "loss": 0.8955,
      "step": 5820
    },
    {
      "epoch": 30.523560209424083,
      "grad_norm": 6.014835357666016,
      "learning_rate": 0.00020849214659685863,
      "loss": 0.8896,
      "step": 5830
    },
    {
      "epoch": 30.57591623036649,
      "grad_norm": 4.391509532928467,
      "learning_rate": 0.0002083350785340314,
      "loss": 0.8967,
      "step": 5840
    },
    {
      "epoch": 30.6282722513089,
      "grad_norm": 5.107600212097168,
      "learning_rate": 0.00020817801047120417,
      "loss": 0.9019,
      "step": 5850
    },
    {
      "epoch": 30.680628272251308,
      "grad_norm": 2.5238401889801025,
      "learning_rate": 0.00020802094240837695,
      "loss": 0.8971,
      "step": 5860
    },
    {
      "epoch": 30.732984293193716,
      "grad_norm": 2.3448715209960938,
      "learning_rate": 0.0002078638743455497,
      "loss": 0.8898,
      "step": 5870
    },
    {
      "epoch": 30.785340314136125,
      "grad_norm": 1.8020200729370117,
      "learning_rate": 0.0002077068062827225,
      "loss": 0.8982,
      "step": 5880
    },
    {
      "epoch": 30.837696335078533,
      "grad_norm": 13.169652938842773,
      "learning_rate": 0.00020754973821989528,
      "loss": 0.9165,
      "step": 5890
    },
    {
      "epoch": 30.89005235602094,
      "grad_norm": 0.9950005412101746,
      "learning_rate": 0.00020739267015706803,
      "loss": 0.8881,
      "step": 5900
    },
    {
      "epoch": 30.94240837696335,
      "grad_norm": 3.2983298301696777,
      "learning_rate": 0.00020723560209424082,
      "loss": 0.9066,
      "step": 5910
    },
    {
      "epoch": 30.994764397905758,
      "grad_norm": 6.761884689331055,
      "learning_rate": 0.0002070785340314136,
      "loss": 0.8912,
      "step": 5920
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.4261119081779053,
      "eval_loss": 3.4679152965545654,
      "eval_runtime": 1.0252,
      "eval_samples_per_second": 1359.672,
      "eval_steps_per_second": 21.458,
      "step": 5921
    },
    {
      "epoch": 31.047120418848166,
      "grad_norm": 2.326115608215332,
      "learning_rate": 0.00020692146596858635,
      "loss": 0.8881,
      "step": 5930
    },
    {
      "epoch": 31.099476439790575,
      "grad_norm": 3.937774896621704,
      "learning_rate": 0.00020676439790575916,
      "loss": 0.8954,
      "step": 5940
    },
    {
      "epoch": 31.151832460732983,
      "grad_norm": 3.5824360847473145,
      "learning_rate": 0.00020660732984293192,
      "loss": 0.8798,
      "step": 5950
    },
    {
      "epoch": 31.20418848167539,
      "grad_norm": 3.03885817527771,
      "learning_rate": 0.00020645026178010468,
      "loss": 0.9011,
      "step": 5960
    },
    {
      "epoch": 31.2565445026178,
      "grad_norm": 4.681279182434082,
      "learning_rate": 0.0002062931937172775,
      "loss": 0.9042,
      "step": 5970
    },
    {
      "epoch": 31.308900523560208,
      "grad_norm": 2.592540740966797,
      "learning_rate": 0.00020613612565445024,
      "loss": 0.9101,
      "step": 5980
    },
    {
      "epoch": 31.361256544502616,
      "grad_norm": 4.232303619384766,
      "learning_rate": 0.000205979057591623,
      "loss": 0.9022,
      "step": 5990
    },
    {
      "epoch": 31.413612565445025,
      "grad_norm": 6.980221271514893,
      "learning_rate": 0.0002058219895287958,
      "loss": 0.8819,
      "step": 6000
    },
    {
      "epoch": 31.465968586387433,
      "grad_norm": 3.054452419281006,
      "learning_rate": 0.00020566492146596857,
      "loss": 0.8928,
      "step": 6010
    },
    {
      "epoch": 31.51832460732984,
      "grad_norm": 0.7954784631729126,
      "learning_rate": 0.00020550785340314132,
      "loss": 0.9008,
      "step": 6020
    },
    {
      "epoch": 31.57068062827225,
      "grad_norm": 0.5354886651039124,
      "learning_rate": 0.00020535078534031413,
      "loss": 0.8759,
      "step": 6030
    },
    {
      "epoch": 31.62303664921466,
      "grad_norm": 2.0499632358551025,
      "learning_rate": 0.0002051937172774869,
      "loss": 0.8888,
      "step": 6040
    },
    {
      "epoch": 31.675392670157066,
      "grad_norm": 2.9583325386047363,
      "learning_rate": 0.00020503664921465965,
      "loss": 0.8834,
      "step": 6050
    },
    {
      "epoch": 31.727748691099478,
      "grad_norm": 7.248188495635986,
      "learning_rate": 0.00020487958115183246,
      "loss": 0.8834,
      "step": 6060
    },
    {
      "epoch": 31.780104712041886,
      "grad_norm": 5.494792938232422,
      "learning_rate": 0.0002047225130890052,
      "loss": 0.9166,
      "step": 6070
    },
    {
      "epoch": 31.832460732984295,
      "grad_norm": 1.967870831489563,
      "learning_rate": 0.00020456544502617797,
      "loss": 0.891,
      "step": 6080
    },
    {
      "epoch": 31.884816753926703,
      "grad_norm": 0.43990254402160645,
      "learning_rate": 0.00020440837696335078,
      "loss": 0.9046,
      "step": 6090
    },
    {
      "epoch": 31.93717277486911,
      "grad_norm": 3.945645332336426,
      "learning_rate": 0.00020425130890052353,
      "loss": 0.9177,
      "step": 6100
    },
    {
      "epoch": 31.98952879581152,
      "grad_norm": 5.449366092681885,
      "learning_rate": 0.00020409424083769634,
      "loss": 0.9122,
      "step": 6110
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.42395982783357244,
      "eval_loss": 3.4556665420532227,
      "eval_runtime": 1.0107,
      "eval_samples_per_second": 1379.277,
      "eval_steps_per_second": 21.768,
      "step": 6112
    },
    {
      "epoch": 32.04188481675393,
      "grad_norm": 2.0182745456695557,
      "learning_rate": 0.0002039371727748691,
      "loss": 0.8728,
      "step": 6120
    },
    {
      "epoch": 32.09424083769633,
      "grad_norm": 0.4591633975505829,
      "learning_rate": 0.00020378010471204186,
      "loss": 0.8985,
      "step": 6130
    },
    {
      "epoch": 32.146596858638745,
      "grad_norm": 1.1509827375411987,
      "learning_rate": 0.00020362303664921467,
      "loss": 0.8979,
      "step": 6140
    },
    {
      "epoch": 32.19895287958115,
      "grad_norm": 0.6617569923400879,
      "learning_rate": 0.00020346596858638742,
      "loss": 0.8942,
      "step": 6150
    },
    {
      "epoch": 32.25130890052356,
      "grad_norm": 0.7408877015113831,
      "learning_rate": 0.00020330890052356018,
      "loss": 0.8918,
      "step": 6160
    },
    {
      "epoch": 32.303664921465966,
      "grad_norm": 6.003191947937012,
      "learning_rate": 0.000203151832460733,
      "loss": 0.8934,
      "step": 6170
    },
    {
      "epoch": 32.35602094240838,
      "grad_norm": 3.7138583660125732,
      "learning_rate": 0.00020299476439790575,
      "loss": 0.8984,
      "step": 6180
    },
    {
      "epoch": 32.40837696335078,
      "grad_norm": 0.6658864617347717,
      "learning_rate": 0.0002028376963350785,
      "loss": 0.9027,
      "step": 6190
    },
    {
      "epoch": 32.460732984293195,
      "grad_norm": 3.3892598152160645,
      "learning_rate": 0.0002026806282722513,
      "loss": 0.8857,
      "step": 6200
    },
    {
      "epoch": 32.5130890052356,
      "grad_norm": 2.3606035709381104,
      "learning_rate": 0.00020252356020942407,
      "loss": 0.8775,
      "step": 6210
    },
    {
      "epoch": 32.56544502617801,
      "grad_norm": 0.40229564905166626,
      "learning_rate": 0.00020236649214659682,
      "loss": 0.9202,
      "step": 6220
    },
    {
      "epoch": 32.617801047120416,
      "grad_norm": 5.4677534103393555,
      "learning_rate": 0.00020220942408376964,
      "loss": 0.8998,
      "step": 6230
    },
    {
      "epoch": 32.67015706806283,
      "grad_norm": 2.027402877807617,
      "learning_rate": 0.0002020523560209424,
      "loss": 0.9168,
      "step": 6240
    },
    {
      "epoch": 32.72251308900523,
      "grad_norm": 3.8585610389709473,
      "learning_rate": 0.00020189528795811517,
      "loss": 0.9013,
      "step": 6250
    },
    {
      "epoch": 32.774869109947645,
      "grad_norm": 2.695096731185913,
      "learning_rate": 0.00020173821989528796,
      "loss": 0.9175,
      "step": 6260
    },
    {
      "epoch": 32.82722513089005,
      "grad_norm": 6.475466728210449,
      "learning_rate": 0.00020158115183246071,
      "loss": 0.8956,
      "step": 6270
    },
    {
      "epoch": 32.87958115183246,
      "grad_norm": 0.19708669185638428,
      "learning_rate": 0.0002014240837696335,
      "loss": 0.8925,
      "step": 6280
    },
    {
      "epoch": 32.931937172774866,
      "grad_norm": 1.6328208446502686,
      "learning_rate": 0.00020126701570680628,
      "loss": 0.9054,
      "step": 6290
    },
    {
      "epoch": 32.98429319371728,
      "grad_norm": 0.4746222496032715,
      "learning_rate": 0.00020110994764397904,
      "loss": 0.9292,
      "step": 6300
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.4340028694404591,
      "eval_loss": 3.4573476314544678,
      "eval_runtime": 1.0186,
      "eval_samples_per_second": 1368.584,
      "eval_steps_per_second": 21.599,
      "step": 6303
    },
    {
      "epoch": 33.03664921465968,
      "grad_norm": 0.17743699252605438,
      "learning_rate": 0.00020095287958115182,
      "loss": 0.8765,
      "step": 6310
    },
    {
      "epoch": 33.089005235602095,
      "grad_norm": 0.9974305629730225,
      "learning_rate": 0.00020079581151832458,
      "loss": 0.8688,
      "step": 6320
    },
    {
      "epoch": 33.1413612565445,
      "grad_norm": 3.577094078063965,
      "learning_rate": 0.00020063874345549736,
      "loss": 0.8824,
      "step": 6330
    },
    {
      "epoch": 33.19371727748691,
      "grad_norm": 1.7965129613876343,
      "learning_rate": 0.00020048167539267014,
      "loss": 0.877,
      "step": 6340
    },
    {
      "epoch": 33.246073298429316,
      "grad_norm": 5.237298965454102,
      "learning_rate": 0.0002003246073298429,
      "loss": 0.874,
      "step": 6350
    },
    {
      "epoch": 33.29842931937173,
      "grad_norm": 4.15986442565918,
      "learning_rate": 0.00020016753926701568,
      "loss": 0.883,
      "step": 6360
    },
    {
      "epoch": 33.35078534031413,
      "grad_norm": 0.7156725525856018,
      "learning_rate": 0.00020001047120418847,
      "loss": 0.8858,
      "step": 6370
    },
    {
      "epoch": 33.403141361256544,
      "grad_norm": 4.18245267868042,
      "learning_rate": 0.00019985340314136122,
      "loss": 0.8812,
      "step": 6380
    },
    {
      "epoch": 33.455497382198956,
      "grad_norm": 5.136134147644043,
      "learning_rate": 0.000199696335078534,
      "loss": 0.888,
      "step": 6390
    },
    {
      "epoch": 33.50785340314136,
      "grad_norm": 6.500699043273926,
      "learning_rate": 0.0001995392670157068,
      "loss": 0.8695,
      "step": 6400
    },
    {
      "epoch": 33.56020942408377,
      "grad_norm": 0.21842709183692932,
      "learning_rate": 0.00019938219895287954,
      "loss": 0.8787,
      "step": 6410
    },
    {
      "epoch": 33.61256544502618,
      "grad_norm": 4.157350063323975,
      "learning_rate": 0.00019922513089005235,
      "loss": 0.8783,
      "step": 6420
    },
    {
      "epoch": 33.66492146596859,
      "grad_norm": 2.7592289447784424,
      "learning_rate": 0.0001990680628272251,
      "loss": 0.8903,
      "step": 6430
    },
    {
      "epoch": 33.717277486910994,
      "grad_norm": 3.4454574584960938,
      "learning_rate": 0.00019891099476439787,
      "loss": 0.895,
      "step": 6440
    },
    {
      "epoch": 33.769633507853406,
      "grad_norm": 5.748818874359131,
      "learning_rate": 0.00019875392670157068,
      "loss": 0.9042,
      "step": 6450
    },
    {
      "epoch": 33.82198952879581,
      "grad_norm": 2.558729887008667,
      "learning_rate": 0.00019859685863874343,
      "loss": 0.8845,
      "step": 6460
    },
    {
      "epoch": 33.87434554973822,
      "grad_norm": 13.902070999145508,
      "learning_rate": 0.0001984397905759162,
      "loss": 0.8968,
      "step": 6470
    },
    {
      "epoch": 33.92670157068063,
      "grad_norm": 1.3210813999176025,
      "learning_rate": 0.000198282722513089,
      "loss": 0.8925,
      "step": 6480
    },
    {
      "epoch": 33.97905759162304,
      "grad_norm": 6.117773056030273,
      "learning_rate": 0.00019812565445026176,
      "loss": 0.891,
      "step": 6490
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.4332855093256815,
      "eval_loss": 3.5137741565704346,
      "eval_runtime": 1.0295,
      "eval_samples_per_second": 1354.06,
      "eval_steps_per_second": 21.37,
      "step": 6494
    },
    {
      "epoch": 34.031413612565444,
      "grad_norm": 6.058084487915039,
      "learning_rate": 0.0001979685863874345,
      "loss": 0.8779,
      "step": 6500
    },
    {
      "epoch": 34.083769633507856,
      "grad_norm": 5.26999568939209,
      "learning_rate": 0.00019781151832460732,
      "loss": 0.8793,
      "step": 6510
    },
    {
      "epoch": 34.13612565445026,
      "grad_norm": 2.6287569999694824,
      "learning_rate": 0.00019765445026178008,
      "loss": 0.8882,
      "step": 6520
    },
    {
      "epoch": 34.18848167539267,
      "grad_norm": 5.764302730560303,
      "learning_rate": 0.00019749738219895283,
      "loss": 0.9134,
      "step": 6530
    },
    {
      "epoch": 34.24083769633508,
      "grad_norm": 5.2447357177734375,
      "learning_rate": 0.00019734031413612565,
      "loss": 0.8921,
      "step": 6540
    },
    {
      "epoch": 34.29319371727749,
      "grad_norm": 2.4477055072784424,
      "learning_rate": 0.0001971832460732984,
      "loss": 0.909,
      "step": 6550
    },
    {
      "epoch": 34.345549738219894,
      "grad_norm": 3.386936664581299,
      "learning_rate": 0.0001970261780104712,
      "loss": 0.9071,
      "step": 6560
    },
    {
      "epoch": 34.397905759162306,
      "grad_norm": 1.9813920259475708,
      "learning_rate": 0.00019686910994764397,
      "loss": 0.8871,
      "step": 6570
    },
    {
      "epoch": 34.45026178010471,
      "grad_norm": 2.132678270339966,
      "learning_rate": 0.00019671204188481672,
      "loss": 0.8858,
      "step": 6580
    },
    {
      "epoch": 34.50261780104712,
      "grad_norm": 3.6439359188079834,
      "learning_rate": 0.00019655497382198953,
      "loss": 0.8927,
      "step": 6590
    },
    {
      "epoch": 34.55497382198953,
      "grad_norm": 10.013519287109375,
      "learning_rate": 0.0001963979057591623,
      "loss": 0.8943,
      "step": 6600
    },
    {
      "epoch": 34.60732984293194,
      "grad_norm": 2.4397964477539062,
      "learning_rate": 0.00019624083769633505,
      "loss": 0.9047,
      "step": 6610
    },
    {
      "epoch": 34.659685863874344,
      "grad_norm": 2.6411681175231934,
      "learning_rate": 0.00019608376963350786,
      "loss": 0.893,
      "step": 6620
    },
    {
      "epoch": 34.712041884816756,
      "grad_norm": 7.433165073394775,
      "learning_rate": 0.0001959267015706806,
      "loss": 0.928,
      "step": 6630
    },
    {
      "epoch": 34.76439790575916,
      "grad_norm": 0.31841281056404114,
      "learning_rate": 0.00019576963350785337,
      "loss": 0.8979,
      "step": 6640
    },
    {
      "epoch": 34.81675392670157,
      "grad_norm": 6.105173110961914,
      "learning_rate": 0.00019561256544502618,
      "loss": 0.9171,
      "step": 6650
    },
    {
      "epoch": 34.86910994764398,
      "grad_norm": 3.8216700553894043,
      "learning_rate": 0.00019545549738219894,
      "loss": 0.8863,
      "step": 6660
    },
    {
      "epoch": 34.92146596858639,
      "grad_norm": 4.742198944091797,
      "learning_rate": 0.0001952984293193717,
      "loss": 0.888,
      "step": 6670
    },
    {
      "epoch": 34.973821989528794,
      "grad_norm": 6.799996376037598,
      "learning_rate": 0.0001951413612565445,
      "loss": 0.8922,
      "step": 6680
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.4282639885222382,
      "eval_loss": 3.533689260482788,
      "eval_runtime": 1.1012,
      "eval_samples_per_second": 1265.943,
      "eval_steps_per_second": 19.979,
      "step": 6685
    },
    {
      "epoch": 35.026178010471206,
      "grad_norm": 3.1217055320739746,
      "learning_rate": 0.00019498429319371726,
      "loss": 0.8941,
      "step": 6690
    },
    {
      "epoch": 35.07853403141361,
      "grad_norm": 3.221560478210449,
      "learning_rate": 0.00019482722513089001,
      "loss": 0.8847,
      "step": 6700
    },
    {
      "epoch": 35.13089005235602,
      "grad_norm": 3.6294915676116943,
      "learning_rate": 0.00019467015706806283,
      "loss": 0.9027,
      "step": 6710
    },
    {
      "epoch": 35.18324607329843,
      "grad_norm": 4.208133220672607,
      "learning_rate": 0.00019451308900523558,
      "loss": 0.893,
      "step": 6720
    },
    {
      "epoch": 35.23560209424084,
      "grad_norm": 10.47813892364502,
      "learning_rate": 0.00019435602094240836,
      "loss": 0.8778,
      "step": 6730
    },
    {
      "epoch": 35.287958115183244,
      "grad_norm": 1.0421737432479858,
      "learning_rate": 0.00019419895287958115,
      "loss": 0.8817,
      "step": 6740
    },
    {
      "epoch": 35.340314136125656,
      "grad_norm": 4.929754257202148,
      "learning_rate": 0.0001940418848167539,
      "loss": 0.8836,
      "step": 6750
    },
    {
      "epoch": 35.39267015706806,
      "grad_norm": 2.563767671585083,
      "learning_rate": 0.0001938848167539267,
      "loss": 0.8873,
      "step": 6760
    },
    {
      "epoch": 35.44502617801047,
      "grad_norm": 10.821688652038574,
      "learning_rate": 0.00019372774869109947,
      "loss": 0.8916,
      "step": 6770
    },
    {
      "epoch": 35.49738219895288,
      "grad_norm": 3.6690852642059326,
      "learning_rate": 0.00019357068062827223,
      "loss": 0.9177,
      "step": 6780
    },
    {
      "epoch": 35.54973821989529,
      "grad_norm": 2.832219123840332,
      "learning_rate": 0.000193413612565445,
      "loss": 0.8789,
      "step": 6790
    },
    {
      "epoch": 35.602094240837694,
      "grad_norm": 0.8773018717765808,
      "learning_rate": 0.0001932565445026178,
      "loss": 0.87,
      "step": 6800
    },
    {
      "epoch": 35.654450261780106,
      "grad_norm": 0.960731029510498,
      "learning_rate": 0.00019309947643979055,
      "loss": 0.911,
      "step": 6810
    },
    {
      "epoch": 35.70680628272251,
      "grad_norm": 0.42209964990615845,
      "learning_rate": 0.00019294240837696333,
      "loss": 0.8695,
      "step": 6820
    },
    {
      "epoch": 35.75916230366492,
      "grad_norm": 0.26736006140708923,
      "learning_rate": 0.00019278534031413612,
      "loss": 0.8624,
      "step": 6830
    },
    {
      "epoch": 35.81151832460733,
      "grad_norm": 0.456714391708374,
      "learning_rate": 0.00019262827225130887,
      "loss": 0.8812,
      "step": 6840
    },
    {
      "epoch": 35.86387434554974,
      "grad_norm": 2.791926145553589,
      "learning_rate": 0.00019247120418848166,
      "loss": 0.8692,
      "step": 6850
    },
    {
      "epoch": 35.916230366492144,
      "grad_norm": 0.2905442714691162,
      "learning_rate": 0.00019231413612565444,
      "loss": 0.8901,
      "step": 6860
    },
    {
      "epoch": 35.968586387434556,
      "grad_norm": 7.391862869262695,
      "learning_rate": 0.00019215706806282722,
      "loss": 0.8844,
      "step": 6870
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.43615494978479197,
      "eval_loss": 3.4995298385620117,
      "eval_runtime": 1.0123,
      "eval_samples_per_second": 1377.101,
      "eval_steps_per_second": 21.733,
      "step": 6876
    },
    {
      "epoch": 36.02094240837696,
      "grad_norm": 0.11520438641309738,
      "learning_rate": 0.00019199999999999998,
      "loss": 0.8727,
      "step": 6880
    },
    {
      "epoch": 36.07329842931937,
      "grad_norm": 1.3432608842849731,
      "learning_rate": 0.00019184293193717276,
      "loss": 0.8797,
      "step": 6890
    },
    {
      "epoch": 36.12565445026178,
      "grad_norm": 7.485064506530762,
      "learning_rate": 0.00019168586387434554,
      "loss": 0.8859,
      "step": 6900
    },
    {
      "epoch": 36.17801047120419,
      "grad_norm": 3.036963939666748,
      "learning_rate": 0.0001915287958115183,
      "loss": 0.8946,
      "step": 6910
    },
    {
      "epoch": 36.230366492146594,
      "grad_norm": 0.36487850546836853,
      "learning_rate": 0.00019137172774869108,
      "loss": 0.8903,
      "step": 6920
    },
    {
      "epoch": 36.282722513089006,
      "grad_norm": 0.566230058670044,
      "learning_rate": 0.00019121465968586387,
      "loss": 0.8764,
      "step": 6930
    },
    {
      "epoch": 36.33507853403141,
      "grad_norm": 0.47658416628837585,
      "learning_rate": 0.00019105759162303662,
      "loss": 0.8734,
      "step": 6940
    },
    {
      "epoch": 36.38743455497382,
      "grad_norm": 0.8328772187232971,
      "learning_rate": 0.0001909005235602094,
      "loss": 0.8669,
      "step": 6950
    },
    {
      "epoch": 36.43979057591623,
      "grad_norm": 5.247679233551025,
      "learning_rate": 0.0001907434554973822,
      "loss": 0.8914,
      "step": 6960
    },
    {
      "epoch": 36.49214659685864,
      "grad_norm": 5.1580095291137695,
      "learning_rate": 0.00019058638743455495,
      "loss": 0.8721,
      "step": 6970
    },
    {
      "epoch": 36.544502617801044,
      "grad_norm": 5.66508674621582,
      "learning_rate": 0.00019042931937172773,
      "loss": 0.8817,
      "step": 6980
    },
    {
      "epoch": 36.596858638743456,
      "grad_norm": 1.468522548675537,
      "learning_rate": 0.0001902722513089005,
      "loss": 0.9053,
      "step": 6990
    },
    {
      "epoch": 36.64921465968587,
      "grad_norm": 5.926736831665039,
      "learning_rate": 0.00019011518324607327,
      "loss": 0.8899,
      "step": 7000
    },
    {
      "epoch": 36.70157068062827,
      "grad_norm": 6.88711404800415,
      "learning_rate": 0.00018995811518324605,
      "loss": 0.886,
      "step": 7010
    },
    {
      "epoch": 36.753926701570684,
      "grad_norm": 0.23534075915813446,
      "learning_rate": 0.00018980104712041883,
      "loss": 0.8943,
      "step": 7020
    },
    {
      "epoch": 36.80628272251309,
      "grad_norm": 2.933980703353882,
      "learning_rate": 0.0001896439790575916,
      "loss": 0.9007,
      "step": 7030
    },
    {
      "epoch": 36.8586387434555,
      "grad_norm": 2.6822004318237305,
      "learning_rate": 0.0001894869109947644,
      "loss": 0.8952,
      "step": 7040
    },
    {
      "epoch": 36.910994764397905,
      "grad_norm": 3.5138344764709473,
      "learning_rate": 0.00018932984293193716,
      "loss": 0.8891,
      "step": 7050
    },
    {
      "epoch": 36.96335078534032,
      "grad_norm": 9.09427261352539,
      "learning_rate": 0.00018917277486910991,
      "loss": 0.9217,
      "step": 7060
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.4246771879483501,
      "eval_loss": 3.5573439598083496,
      "eval_runtime": 0.9766,
      "eval_samples_per_second": 1427.376,
      "eval_steps_per_second": 22.527,
      "step": 7067
    },
    {
      "epoch": 37.01570680628272,
      "grad_norm": 0.8229116201400757,
      "learning_rate": 0.00018901570680628272,
      "loss": 0.8869,
      "step": 7070
    },
    {
      "epoch": 37.068062827225134,
      "grad_norm": 0.9595739245414734,
      "learning_rate": 0.00018885863874345548,
      "loss": 0.8721,
      "step": 7080
    },
    {
      "epoch": 37.12041884816754,
      "grad_norm": 3.8280935287475586,
      "learning_rate": 0.00018870157068062824,
      "loss": 0.8846,
      "step": 7090
    },
    {
      "epoch": 37.17277486910995,
      "grad_norm": 4.184846878051758,
      "learning_rate": 0.00018854450261780105,
      "loss": 0.8829,
      "step": 7100
    },
    {
      "epoch": 37.225130890052355,
      "grad_norm": 5.271324634552002,
      "learning_rate": 0.0001883874345549738,
      "loss": 0.885,
      "step": 7110
    },
    {
      "epoch": 37.27748691099477,
      "grad_norm": 14.005910873413086,
      "learning_rate": 0.00018823036649214656,
      "loss": 0.8758,
      "step": 7120
    },
    {
      "epoch": 37.32984293193717,
      "grad_norm": 1.8915735483169556,
      "learning_rate": 0.00018807329842931937,
      "loss": 0.8741,
      "step": 7130
    },
    {
      "epoch": 37.382198952879584,
      "grad_norm": 5.375593662261963,
      "learning_rate": 0.00018791623036649213,
      "loss": 0.8742,
      "step": 7140
    },
    {
      "epoch": 37.43455497382199,
      "grad_norm": 0.5705545544624329,
      "learning_rate": 0.00018775916230366488,
      "loss": 0.8809,
      "step": 7150
    },
    {
      "epoch": 37.4869109947644,
      "grad_norm": 5.294356822967529,
      "learning_rate": 0.0001876020942408377,
      "loss": 0.8957,
      "step": 7160
    },
    {
      "epoch": 37.539267015706805,
      "grad_norm": 5.348252773284912,
      "learning_rate": 0.00018744502617801045,
      "loss": 0.8868,
      "step": 7170
    },
    {
      "epoch": 37.59162303664922,
      "grad_norm": 2.4586877822875977,
      "learning_rate": 0.00018728795811518326,
      "loss": 0.8794,
      "step": 7180
    },
    {
      "epoch": 37.64397905759162,
      "grad_norm": 3.721689462661743,
      "learning_rate": 0.00018713089005235601,
      "loss": 0.8739,
      "step": 7190
    },
    {
      "epoch": 37.696335078534034,
      "grad_norm": 1.935177206993103,
      "learning_rate": 0.00018697382198952877,
      "loss": 0.8872,
      "step": 7200
    },
    {
      "epoch": 37.74869109947644,
      "grad_norm": 1.895619511604309,
      "learning_rate": 0.00018681675392670158,
      "loss": 0.8751,
      "step": 7210
    },
    {
      "epoch": 37.80104712041885,
      "grad_norm": 4.6594624519348145,
      "learning_rate": 0.00018665968586387434,
      "loss": 0.8856,
      "step": 7220
    },
    {
      "epoch": 37.853403141361255,
      "grad_norm": 7.033782005310059,
      "learning_rate": 0.0001865026178010471,
      "loss": 0.8909,
      "step": 7230
    },
    {
      "epoch": 37.90575916230367,
      "grad_norm": 8.082782745361328,
      "learning_rate": 0.00018634554973821988,
      "loss": 0.8823,
      "step": 7240
    },
    {
      "epoch": 37.95811518324607,
      "grad_norm": 9.649083137512207,
      "learning_rate": 0.00018618848167539266,
      "loss": 0.9157,
      "step": 7250
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.42037302725968434,
      "eval_loss": 3.4973034858703613,
      "eval_runtime": 0.9646,
      "eval_samples_per_second": 1445.129,
      "eval_steps_per_second": 22.807,
      "step": 7258
    },
    {
      "epoch": 38.010471204188484,
      "grad_norm": 0.7844100594520569,
      "learning_rate": 0.00018603141361256542,
      "loss": 0.9004,
      "step": 7260
    },
    {
      "epoch": 38.06282722513089,
      "grad_norm": 0.27646493911743164,
      "learning_rate": 0.0001858743455497382,
      "loss": 0.8744,
      "step": 7270
    },
    {
      "epoch": 38.1151832460733,
      "grad_norm": 0.18345427513122559,
      "learning_rate": 0.00018571727748691098,
      "loss": 0.8647,
      "step": 7280
    },
    {
      "epoch": 38.167539267015705,
      "grad_norm": 0.37750083208084106,
      "learning_rate": 0.00018556020942408374,
      "loss": 0.8792,
      "step": 7290
    },
    {
      "epoch": 38.21989528795812,
      "grad_norm": 4.048274040222168,
      "learning_rate": 0.00018540314136125652,
      "loss": 0.8741,
      "step": 7300
    },
    {
      "epoch": 38.27225130890052,
      "grad_norm": 1.6215440034866333,
      "learning_rate": 0.0001852460732984293,
      "loss": 0.8818,
      "step": 7310
    },
    {
      "epoch": 38.324607329842934,
      "grad_norm": 5.11925745010376,
      "learning_rate": 0.00018508900523560206,
      "loss": 0.8742,
      "step": 7320
    },
    {
      "epoch": 38.37696335078534,
      "grad_norm": 7.340001106262207,
      "learning_rate": 0.00018493193717277484,
      "loss": 0.886,
      "step": 7330
    },
    {
      "epoch": 38.42931937172775,
      "grad_norm": 0.3025946617126465,
      "learning_rate": 0.00018477486910994763,
      "loss": 0.8733,
      "step": 7340
    },
    {
      "epoch": 38.481675392670155,
      "grad_norm": 5.740711688995361,
      "learning_rate": 0.0001846178010471204,
      "loss": 0.8709,
      "step": 7350
    },
    {
      "epoch": 38.53403141361257,
      "grad_norm": 1.194070816040039,
      "learning_rate": 0.00018446073298429317,
      "loss": 0.8755,
      "step": 7360
    },
    {
      "epoch": 38.58638743455497,
      "grad_norm": 2.8997855186462402,
      "learning_rate": 0.00018430366492146595,
      "loss": 0.8899,
      "step": 7370
    },
    {
      "epoch": 38.638743455497384,
      "grad_norm": 5.6539626121521,
      "learning_rate": 0.00018414659685863873,
      "loss": 0.8791,
      "step": 7380
    },
    {
      "epoch": 38.69109947643979,
      "grad_norm": 0.5068509578704834,
      "learning_rate": 0.0001839895287958115,
      "loss": 0.8939,
      "step": 7390
    },
    {
      "epoch": 38.7434554973822,
      "grad_norm": 0.23757946491241455,
      "learning_rate": 0.00018383246073298427,
      "loss": 0.8858,
      "step": 7400
    },
    {
      "epoch": 38.795811518324605,
      "grad_norm": 3.185112237930298,
      "learning_rate": 0.00018367539267015706,
      "loss": 0.8784,
      "step": 7410
    },
    {
      "epoch": 38.84816753926702,
      "grad_norm": 1.6531343460083008,
      "learning_rate": 0.0001835183246073298,
      "loss": 0.8749,
      "step": 7420
    },
    {
      "epoch": 38.90052356020942,
      "grad_norm": 2.1768808364868164,
      "learning_rate": 0.0001833612565445026,
      "loss": 0.8827,
      "step": 7430
    },
    {
      "epoch": 38.952879581151834,
      "grad_norm": 0.48523518443107605,
      "learning_rate": 0.00018320418848167538,
      "loss": 0.8814,
      "step": 7440
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.4253945480631277,
      "eval_loss": 3.543062210083008,
      "eval_runtime": 1.0502,
      "eval_samples_per_second": 1327.4,
      "eval_steps_per_second": 20.949,
      "step": 7449
    },
    {
      "epoch": 39.00523560209424,
      "grad_norm": 5.045412063598633,
      "learning_rate": 0.00018304712041884814,
      "loss": 0.8775,
      "step": 7450
    },
    {
      "epoch": 39.05759162303665,
      "grad_norm": 8.473188400268555,
      "learning_rate": 0.00018289005235602092,
      "loss": 0.8671,
      "step": 7460
    },
    {
      "epoch": 39.109947643979055,
      "grad_norm": 0.09330934286117554,
      "learning_rate": 0.0001827329842931937,
      "loss": 0.8799,
      "step": 7470
    },
    {
      "epoch": 39.16230366492147,
      "grad_norm": 1.7322334051132202,
      "learning_rate": 0.00018257591623036646,
      "loss": 0.8772,
      "step": 7480
    },
    {
      "epoch": 39.21465968586387,
      "grad_norm": 2.0060532093048096,
      "learning_rate": 0.00018241884816753927,
      "loss": 0.8821,
      "step": 7490
    },
    {
      "epoch": 39.26701570680628,
      "grad_norm": 3.301259994506836,
      "learning_rate": 0.00018226178010471202,
      "loss": 0.8809,
      "step": 7500
    },
    {
      "epoch": 39.31937172774869,
      "grad_norm": 4.241349220275879,
      "learning_rate": 0.00018210471204188478,
      "loss": 0.8892,
      "step": 7510
    },
    {
      "epoch": 39.3717277486911,
      "grad_norm": 0.23123179376125336,
      "learning_rate": 0.0001819476439790576,
      "loss": 0.8777,
      "step": 7520
    },
    {
      "epoch": 39.424083769633505,
      "grad_norm": 0.34837061166763306,
      "learning_rate": 0.00018179057591623035,
      "loss": 0.8696,
      "step": 7530
    },
    {
      "epoch": 39.47643979057592,
      "grad_norm": 3.860405683517456,
      "learning_rate": 0.0001816335078534031,
      "loss": 0.882,
      "step": 7540
    },
    {
      "epoch": 39.52879581151832,
      "grad_norm": 1.2808356285095215,
      "learning_rate": 0.00018147643979057591,
      "loss": 0.8663,
      "step": 7550
    },
    {
      "epoch": 39.58115183246073,
      "grad_norm": 0.18311691284179688,
      "learning_rate": 0.00018131937172774867,
      "loss": 0.8805,
      "step": 7560
    },
    {
      "epoch": 39.63350785340314,
      "grad_norm": 6.432370662689209,
      "learning_rate": 0.00018116230366492143,
      "loss": 0.8756,
      "step": 7570
    },
    {
      "epoch": 39.68586387434555,
      "grad_norm": 1.135343313217163,
      "learning_rate": 0.00018100523560209424,
      "loss": 0.8782,
      "step": 7580
    },
    {
      "epoch": 39.738219895287955,
      "grad_norm": 0.17374950647354126,
      "learning_rate": 0.000180848167539267,
      "loss": 0.873,
      "step": 7590
    },
    {
      "epoch": 39.79057591623037,
      "grad_norm": 3.0031614303588867,
      "learning_rate": 0.00018069109947643975,
      "loss": 0.8702,
      "step": 7600
    },
    {
      "epoch": 39.84293193717277,
      "grad_norm": 8.905095100402832,
      "learning_rate": 0.00018053403141361256,
      "loss": 0.8877,
      "step": 7610
    },
    {
      "epoch": 39.89528795811518,
      "grad_norm": 2.7513394355773926,
      "learning_rate": 0.00018037696335078532,
      "loss": 0.8842,
      "step": 7620
    },
    {
      "epoch": 39.94764397905759,
      "grad_norm": 2.191561698913574,
      "learning_rate": 0.00018021989528795813,
      "loss": 0.8851,
      "step": 7630
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.1377054452896118,
      "learning_rate": 0.00018006282722513088,
      "loss": 0.8915,
      "step": 7640
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.4261119081779053,
      "eval_loss": 3.5668976306915283,
      "eval_runtime": 0.9703,
      "eval_samples_per_second": 1436.647,
      "eval_steps_per_second": 22.673,
      "step": 7640
    },
    {
      "epoch": 40.05235602094241,
      "grad_norm": 1.5603083372116089,
      "learning_rate": 0.00017990575916230364,
      "loss": 0.8597,
      "step": 7650
    },
    {
      "epoch": 40.10471204188482,
      "grad_norm": 2.809798240661621,
      "learning_rate": 0.00017974869109947645,
      "loss": 0.8847,
      "step": 7660
    },
    {
      "epoch": 40.15706806282723,
      "grad_norm": 0.1590212732553482,
      "learning_rate": 0.0001795916230366492,
      "loss": 0.8674,
      "step": 7670
    },
    {
      "epoch": 40.20942408376963,
      "grad_norm": 2.1867613792419434,
      "learning_rate": 0.00017943455497382196,
      "loss": 0.8964,
      "step": 7680
    },
    {
      "epoch": 40.261780104712045,
      "grad_norm": 0.4738655984401703,
      "learning_rate": 0.00017927748691099477,
      "loss": 0.8733,
      "step": 7690
    },
    {
      "epoch": 40.31413612565445,
      "grad_norm": 13.905584335327148,
      "learning_rate": 0.00017912041884816753,
      "loss": 0.8736,
      "step": 7700
    },
    {
      "epoch": 40.36649214659686,
      "grad_norm": 2.763801336288452,
      "learning_rate": 0.00017896335078534028,
      "loss": 0.8896,
      "step": 7710
    },
    {
      "epoch": 40.41884816753927,
      "grad_norm": 1.8588443994522095,
      "learning_rate": 0.0001788062827225131,
      "loss": 0.871,
      "step": 7720
    },
    {
      "epoch": 40.47120418848168,
      "grad_norm": 2.39029598236084,
      "learning_rate": 0.00017864921465968585,
      "loss": 0.874,
      "step": 7730
    },
    {
      "epoch": 40.52356020942408,
      "grad_norm": 4.431617736816406,
      "learning_rate": 0.0001784921465968586,
      "loss": 0.9008,
      "step": 7740
    },
    {
      "epoch": 40.575916230366495,
      "grad_norm": 4.060434341430664,
      "learning_rate": 0.00017833507853403142,
      "loss": 0.8821,
      "step": 7750
    },
    {
      "epoch": 40.6282722513089,
      "grad_norm": 5.25760555267334,
      "learning_rate": 0.00017817801047120417,
      "loss": 0.8866,
      "step": 7760
    },
    {
      "epoch": 40.68062827225131,
      "grad_norm": 4.991254806518555,
      "learning_rate": 0.00017802094240837693,
      "loss": 0.9017,
      "step": 7770
    },
    {
      "epoch": 40.73298429319372,
      "grad_norm": 6.298446178436279,
      "learning_rate": 0.00017786387434554974,
      "loss": 0.9161,
      "step": 7780
    },
    {
      "epoch": 40.78534031413613,
      "grad_norm": 0.7591876983642578,
      "learning_rate": 0.0001777068062827225,
      "loss": 0.8736,
      "step": 7790
    },
    {
      "epoch": 40.83769633507853,
      "grad_norm": 2.0565292835235596,
      "learning_rate": 0.00017754973821989528,
      "loss": 0.886,
      "step": 7800
    },
    {
      "epoch": 40.890052356020945,
      "grad_norm": 5.1941351890563965,
      "learning_rate": 0.00017739267015706806,
      "loss": 0.8783,
      "step": 7810
    },
    {
      "epoch": 40.94240837696335,
      "grad_norm": 1.5998879671096802,
      "learning_rate": 0.00017723560209424082,
      "loss": 0.881,
      "step": 7820
    },
    {
      "epoch": 40.99476439790576,
      "grad_norm": 2.829516887664795,
      "learning_rate": 0.0001770785340314136,
      "loss": 0.8711,
      "step": 7830
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.42395982783357244,
      "eval_loss": 3.5412588119506836,
      "eval_runtime": 1.036,
      "eval_samples_per_second": 1345.52,
      "eval_steps_per_second": 21.235,
      "step": 7831
    },
    {
      "epoch": 41.047120418848166,
      "grad_norm": 3.013062000274658,
      "learning_rate": 0.00017692146596858638,
      "loss": 0.8766,
      "step": 7840
    },
    {
      "epoch": 41.09947643979058,
      "grad_norm": 0.7995008230209351,
      "learning_rate": 0.00017676439790575914,
      "loss": 0.8684,
      "step": 7850
    },
    {
      "epoch": 41.15183246073298,
      "grad_norm": 0.09367688745260239,
      "learning_rate": 0.00017660732984293192,
      "loss": 0.8773,
      "step": 7860
    },
    {
      "epoch": 41.204188481675395,
      "grad_norm": 4.558823585510254,
      "learning_rate": 0.0001764502617801047,
      "loss": 0.8708,
      "step": 7870
    },
    {
      "epoch": 41.2565445026178,
      "grad_norm": 0.9304805994033813,
      "learning_rate": 0.00017629319371727746,
      "loss": 0.8785,
      "step": 7880
    },
    {
      "epoch": 41.30890052356021,
      "grad_norm": 2.578702449798584,
      "learning_rate": 0.00017613612565445025,
      "loss": 0.8697,
      "step": 7890
    },
    {
      "epoch": 41.361256544502616,
      "grad_norm": 0.9359664916992188,
      "learning_rate": 0.00017597905759162303,
      "loss": 0.8834,
      "step": 7900
    },
    {
      "epoch": 41.41361256544503,
      "grad_norm": 5.9061174392700195,
      "learning_rate": 0.00017582198952879579,
      "loss": 0.874,
      "step": 7910
    },
    {
      "epoch": 41.46596858638743,
      "grad_norm": 0.17152175307273865,
      "learning_rate": 0.00017566492146596857,
      "loss": 0.8658,
      "step": 7920
    },
    {
      "epoch": 41.518324607329845,
      "grad_norm": 0.2789976894855499,
      "learning_rate": 0.00017550785340314135,
      "loss": 0.8661,
      "step": 7930
    },
    {
      "epoch": 41.57068062827225,
      "grad_norm": 1.9778907299041748,
      "learning_rate": 0.00017535078534031414,
      "loss": 0.8681,
      "step": 7940
    },
    {
      "epoch": 41.62303664921466,
      "grad_norm": 1.9211406707763672,
      "learning_rate": 0.0001751937172774869,
      "loss": 0.8632,
      "step": 7950
    },
    {
      "epoch": 41.675392670157066,
      "grad_norm": 0.3726493716239929,
      "learning_rate": 0.00017503664921465967,
      "loss": 0.8656,
      "step": 7960
    },
    {
      "epoch": 41.72774869109948,
      "grad_norm": 6.671728610992432,
      "learning_rate": 0.00017487958115183246,
      "loss": 0.8744,
      "step": 7970
    },
    {
      "epoch": 41.78010471204188,
      "grad_norm": 5.602478504180908,
      "learning_rate": 0.00017472251308900521,
      "loss": 0.8826,
      "step": 7980
    },
    {
      "epoch": 41.832460732984295,
      "grad_norm": 0.26786673069000244,
      "learning_rate": 0.000174565445026178,
      "loss": 0.8749,
      "step": 7990
    },
    {
      "epoch": 41.8848167539267,
      "grad_norm": 5.8061203956604,
      "learning_rate": 0.00017440837696335078,
      "loss": 0.8894,
      "step": 8000
    },
    {
      "epoch": 41.93717277486911,
      "grad_norm": 2.9290623664855957,
      "learning_rate": 0.00017425130890052354,
      "loss": 0.8672,
      "step": 8010
    },
    {
      "epoch": 41.989528795811516,
      "grad_norm": 2.901445150375366,
      "learning_rate": 0.00017409424083769632,
      "loss": 0.8856,
      "step": 8020
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.4418938307030129,
      "eval_loss": 3.4567527770996094,
      "eval_runtime": 1.1423,
      "eval_samples_per_second": 1220.396,
      "eval_steps_per_second": 19.26,
      "step": 8022
    },
    {
      "epoch": 42.04188481675393,
      "grad_norm": 0.12078097462654114,
      "learning_rate": 0.0001739371727748691,
      "loss": 0.863,
      "step": 8030
    },
    {
      "epoch": 42.09424083769633,
      "grad_norm": 0.12559179961681366,
      "learning_rate": 0.00017378010471204186,
      "loss": 0.8636,
      "step": 8040
    },
    {
      "epoch": 42.146596858638745,
      "grad_norm": 5.1742424964904785,
      "learning_rate": 0.00017362303664921464,
      "loss": 0.8712,
      "step": 8050
    },
    {
      "epoch": 42.19895287958115,
      "grad_norm": 4.336700439453125,
      "learning_rate": 0.00017346596858638743,
      "loss": 0.8677,
      "step": 8060
    },
    {
      "epoch": 42.25130890052356,
      "grad_norm": 0.11241746693849564,
      "learning_rate": 0.00017330890052356018,
      "loss": 0.858,
      "step": 8070
    },
    {
      "epoch": 42.303664921465966,
      "grad_norm": 1.2846341133117676,
      "learning_rate": 0.00017315183246073297,
      "loss": 0.8642,
      "step": 8080
    },
    {
      "epoch": 42.35602094240838,
      "grad_norm": 0.2905155420303345,
      "learning_rate": 0.00017299476439790575,
      "loss": 0.8599,
      "step": 8090
    },
    {
      "epoch": 42.40837696335078,
      "grad_norm": 5.454336166381836,
      "learning_rate": 0.0001728376963350785,
      "loss": 0.8977,
      "step": 8100
    },
    {
      "epoch": 42.460732984293195,
      "grad_norm": 8.245217323303223,
      "learning_rate": 0.00017268062827225132,
      "loss": 0.8657,
      "step": 8110
    },
    {
      "epoch": 42.5130890052356,
      "grad_norm": 1.1763010025024414,
      "learning_rate": 0.00017252356020942407,
      "loss": 0.8652,
      "step": 8120
    },
    {
      "epoch": 42.56544502617801,
      "grad_norm": 0.7066327333450317,
      "learning_rate": 0.00017236649214659683,
      "loss": 0.8693,
      "step": 8130
    },
    {
      "epoch": 42.617801047120416,
      "grad_norm": 0.32675638794898987,
      "learning_rate": 0.00017220942408376964,
      "loss": 0.8791,
      "step": 8140
    },
    {
      "epoch": 42.67015706806283,
      "grad_norm": 0.1398167461156845,
      "learning_rate": 0.0001720523560209424,
      "loss": 0.8625,
      "step": 8150
    },
    {
      "epoch": 42.72251308900523,
      "grad_norm": 7.660865306854248,
      "learning_rate": 0.00017189528795811515,
      "loss": 0.8826,
      "step": 8160
    },
    {
      "epoch": 42.774869109947645,
      "grad_norm": 2.2253456115722656,
      "learning_rate": 0.00017173821989528796,
      "loss": 0.8721,
      "step": 8170
    },
    {
      "epoch": 42.82722513089005,
      "grad_norm": 0.10427983850240707,
      "learning_rate": 0.00017158115183246072,
      "loss": 0.8839,
      "step": 8180
    },
    {
      "epoch": 42.87958115183246,
      "grad_norm": 0.4268842041492462,
      "learning_rate": 0.00017142408376963347,
      "loss": 0.8776,
      "step": 8190
    },
    {
      "epoch": 42.931937172774866,
      "grad_norm": 0.1584721952676773,
      "learning_rate": 0.00017126701570680628,
      "loss": 0.8759,
      "step": 8200
    },
    {
      "epoch": 42.98429319371728,
      "grad_norm": 2.8378491401672363,
      "learning_rate": 0.00017110994764397904,
      "loss": 0.8605,
      "step": 8210
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.4261119081779053,
      "eval_loss": 3.601407051086426,
      "eval_runtime": 0.9666,
      "eval_samples_per_second": 1442.161,
      "eval_steps_per_second": 22.76,
      "step": 8213
    },
    {
      "epoch": 43.03664921465968,
      "grad_norm": 4.844811916351318,
      "learning_rate": 0.0001709528795811518,
      "loss": 0.8762,
      "step": 8220
    },
    {
      "epoch": 43.089005235602095,
      "grad_norm": 3.9386918544769287,
      "learning_rate": 0.0001707958115183246,
      "loss": 0.8687,
      "step": 8230
    },
    {
      "epoch": 43.1413612565445,
      "grad_norm": 0.7342615127563477,
      "learning_rate": 0.00017063874345549736,
      "loss": 0.864,
      "step": 8240
    },
    {
      "epoch": 43.19371727748691,
      "grad_norm": 0.12610185146331787,
      "learning_rate": 0.00017048167539267015,
      "loss": 0.8684,
      "step": 8250
    },
    {
      "epoch": 43.246073298429316,
      "grad_norm": 8.575234413146973,
      "learning_rate": 0.00017032460732984293,
      "loss": 0.8706,
      "step": 8260
    },
    {
      "epoch": 43.29842931937173,
      "grad_norm": 3.663238286972046,
      "learning_rate": 0.00017016753926701568,
      "loss": 0.8587,
      "step": 8270
    },
    {
      "epoch": 43.35078534031413,
      "grad_norm": 0.9884971380233765,
      "learning_rate": 0.00017001047120418847,
      "loss": 0.8593,
      "step": 8280
    },
    {
      "epoch": 43.403141361256544,
      "grad_norm": 0.27920377254486084,
      "learning_rate": 0.00016985340314136125,
      "loss": 0.8612,
      "step": 8290
    },
    {
      "epoch": 43.455497382198956,
      "grad_norm": 1.1622172594070435,
      "learning_rate": 0.000169696335078534,
      "loss": 0.8703,
      "step": 8300
    },
    {
      "epoch": 43.50785340314136,
      "grad_norm": 3.8409712314605713,
      "learning_rate": 0.0001695392670157068,
      "loss": 0.8791,
      "step": 8310
    },
    {
      "epoch": 43.56020942408377,
      "grad_norm": 5.185661315917969,
      "learning_rate": 0.00016938219895287957,
      "loss": 0.8801,
      "step": 8320
    },
    {
      "epoch": 43.61256544502618,
      "grad_norm": 3.296241521835327,
      "learning_rate": 0.00016922513089005233,
      "loss": 0.8876,
      "step": 8330
    },
    {
      "epoch": 43.66492146596859,
      "grad_norm": 3.9340603351593018,
      "learning_rate": 0.0001690680628272251,
      "loss": 0.893,
      "step": 8340
    },
    {
      "epoch": 43.717277486910994,
      "grad_norm": 7.15818452835083,
      "learning_rate": 0.0001689109947643979,
      "loss": 0.8965,
      "step": 8350
    },
    {
      "epoch": 43.769633507853406,
      "grad_norm": 7.370948314666748,
      "learning_rate": 0.00016875392670157065,
      "loss": 0.8931,
      "step": 8360
    },
    {
      "epoch": 43.82198952879581,
      "grad_norm": 1.2016737461090088,
      "learning_rate": 0.00016859685863874344,
      "loss": 0.8646,
      "step": 8370
    },
    {
      "epoch": 43.87434554973822,
      "grad_norm": 0.6423865556716919,
      "learning_rate": 0.00016843979057591622,
      "loss": 0.8913,
      "step": 8380
    },
    {
      "epoch": 43.92670157068063,
      "grad_norm": 5.391338348388672,
      "learning_rate": 0.00016828272251308898,
      "loss": 0.8781,
      "step": 8390
    },
    {
      "epoch": 43.97905759162304,
      "grad_norm": 5.317162990570068,
      "learning_rate": 0.00016812565445026176,
      "loss": 0.9181,
      "step": 8400
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.4282639885222382,
      "eval_loss": 3.5377259254455566,
      "eval_runtime": 0.9765,
      "eval_samples_per_second": 1427.565,
      "eval_steps_per_second": 22.53,
      "step": 8404
    },
    {
      "epoch": 44.031413612565444,
      "grad_norm": 5.33836030960083,
      "learning_rate": 0.00016796858638743454,
      "loss": 0.8752,
      "step": 8410
    },
    {
      "epoch": 44.083769633507856,
      "grad_norm": 1.1849853992462158,
      "learning_rate": 0.00016781151832460733,
      "loss": 0.8944,
      "step": 8420
    },
    {
      "epoch": 44.13612565445026,
      "grad_norm": 2.3248190879821777,
      "learning_rate": 0.00016765445026178008,
      "loss": 0.8651,
      "step": 8430
    },
    {
      "epoch": 44.18848167539267,
      "grad_norm": 1.0333101749420166,
      "learning_rate": 0.00016749738219895286,
      "loss": 0.8659,
      "step": 8440
    },
    {
      "epoch": 44.24083769633508,
      "grad_norm": 0.5567013621330261,
      "learning_rate": 0.00016734031413612565,
      "loss": 0.8831,
      "step": 8450
    },
    {
      "epoch": 44.29319371727749,
      "grad_norm": 7.3960652351379395,
      "learning_rate": 0.0001671832460732984,
      "loss": 0.8719,
      "step": 8460
    },
    {
      "epoch": 44.345549738219894,
      "grad_norm": 0.8639482855796814,
      "learning_rate": 0.0001670261780104712,
      "loss": 0.8627,
      "step": 8470
    },
    {
      "epoch": 44.397905759162306,
      "grad_norm": 4.234057903289795,
      "learning_rate": 0.00016686910994764397,
      "loss": 0.8734,
      "step": 8480
    },
    {
      "epoch": 44.45026178010471,
      "grad_norm": 0.14087240397930145,
      "learning_rate": 0.00016671204188481673,
      "loss": 0.8631,
      "step": 8490
    },
    {
      "epoch": 44.50261780104712,
      "grad_norm": 1.6935052871704102,
      "learning_rate": 0.0001665549738219895,
      "loss": 0.8717,
      "step": 8500
    },
    {
      "epoch": 44.55497382198953,
      "grad_norm": 1.032800316810608,
      "learning_rate": 0.0001663979057591623,
      "loss": 0.877,
      "step": 8510
    },
    {
      "epoch": 44.60732984293194,
      "grad_norm": 8.013199806213379,
      "learning_rate": 0.00016624083769633505,
      "loss": 0.8693,
      "step": 8520
    },
    {
      "epoch": 44.659685863874344,
      "grad_norm": 2.1414241790771484,
      "learning_rate": 0.00016608376963350783,
      "loss": 0.8886,
      "step": 8530
    },
    {
      "epoch": 44.712041884816756,
      "grad_norm": 3.086233139038086,
      "learning_rate": 0.00016592670157068062,
      "loss": 0.8803,
      "step": 8540
    },
    {
      "epoch": 44.76439790575916,
      "grad_norm": 7.433290481567383,
      "learning_rate": 0.00016576963350785337,
      "loss": 0.8826,
      "step": 8550
    },
    {
      "epoch": 44.81675392670157,
      "grad_norm": 9.448569297790527,
      "learning_rate": 0.00016561256544502618,
      "loss": 0.8641,
      "step": 8560
    },
    {
      "epoch": 44.86910994764398,
      "grad_norm": 5.897265911102295,
      "learning_rate": 0.00016545549738219894,
      "loss": 0.8755,
      "step": 8570
    },
    {
      "epoch": 44.92146596858639,
      "grad_norm": 1.7248929738998413,
      "learning_rate": 0.0001652984293193717,
      "loss": 0.8676,
      "step": 8580
    },
    {
      "epoch": 44.973821989528794,
      "grad_norm": 3.962534189224243,
      "learning_rate": 0.0001651413612565445,
      "loss": 0.878,
      "step": 8590
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.4268292682926829,
      "eval_loss": 3.6534981727600098,
      "eval_runtime": 0.9991,
      "eval_samples_per_second": 1395.316,
      "eval_steps_per_second": 22.021,
      "step": 8595
    },
    {
      "epoch": 45.026178010471206,
      "grad_norm": 2.6344096660614014,
      "learning_rate": 0.00016498429319371726,
      "loss": 0.8668,
      "step": 8600
    },
    {
      "epoch": 45.07853403141361,
      "grad_norm": 1.5717328786849976,
      "learning_rate": 0.00016482722513089002,
      "loss": 0.8799,
      "step": 8610
    },
    {
      "epoch": 45.13089005235602,
      "grad_norm": 5.452965259552002,
      "learning_rate": 0.00016467015706806283,
      "loss": 0.8658,
      "step": 8620
    },
    {
      "epoch": 45.18324607329843,
      "grad_norm": 0.13844645023345947,
      "learning_rate": 0.00016451308900523558,
      "loss": 0.8627,
      "step": 8630
    },
    {
      "epoch": 45.23560209424084,
      "grad_norm": 1.816784381866455,
      "learning_rate": 0.00016435602094240834,
      "loss": 0.8618,
      "step": 8640
    },
    {
      "epoch": 45.287958115183244,
      "grad_norm": 0.11898251622915268,
      "learning_rate": 0.00016419895287958115,
      "loss": 0.8659,
      "step": 8650
    },
    {
      "epoch": 45.340314136125656,
      "grad_norm": 0.17158463597297668,
      "learning_rate": 0.0001640418848167539,
      "loss": 0.8613,
      "step": 8660
    },
    {
      "epoch": 45.39267015706806,
      "grad_norm": 0.08062546700239182,
      "learning_rate": 0.00016388481675392666,
      "loss": 0.8688,
      "step": 8670
    },
    {
      "epoch": 45.44502617801047,
      "grad_norm": 0.1299777776002884,
      "learning_rate": 0.00016372774869109947,
      "loss": 0.8714,
      "step": 8680
    },
    {
      "epoch": 45.49738219895288,
      "grad_norm": 0.605143129825592,
      "learning_rate": 0.00016357068062827223,
      "loss": 0.8637,
      "step": 8690
    },
    {
      "epoch": 45.54973821989529,
      "grad_norm": 0.2444799393415451,
      "learning_rate": 0.00016341361256544499,
      "loss": 0.861,
      "step": 8700
    },
    {
      "epoch": 45.602094240837694,
      "grad_norm": 11.27369499206543,
      "learning_rate": 0.0001632565445026178,
      "loss": 0.8713,
      "step": 8710
    },
    {
      "epoch": 45.654450261780106,
      "grad_norm": 3.848196268081665,
      "learning_rate": 0.00016309947643979055,
      "loss": 0.8673,
      "step": 8720
    },
    {
      "epoch": 45.70680628272251,
      "grad_norm": 0.25810113549232483,
      "learning_rate": 0.00016294240837696336,
      "loss": 0.8671,
      "step": 8730
    },
    {
      "epoch": 45.75916230366492,
      "grad_norm": 0.6880022883415222,
      "learning_rate": 0.00016278534031413612,
      "loss": 0.8771,
      "step": 8740
    },
    {
      "epoch": 45.81151832460733,
      "grad_norm": 1.2192192077636719,
      "learning_rate": 0.00016262827225130887,
      "loss": 0.8691,
      "step": 8750
    },
    {
      "epoch": 45.86387434554974,
      "grad_norm": 2.5078125,
      "learning_rate": 0.00016247120418848168,
      "loss": 0.8608,
      "step": 8760
    },
    {
      "epoch": 45.916230366492144,
      "grad_norm": 0.9230841994285583,
      "learning_rate": 0.00016231413612565444,
      "loss": 0.8757,
      "step": 8770
    },
    {
      "epoch": 45.968586387434556,
      "grad_norm": 0.39312100410461426,
      "learning_rate": 0.0001621570680628272,
      "loss": 0.8828,
      "step": 8780
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.42754662840746055,
      "eval_loss": 3.6044580936431885,
      "eval_runtime": 1.0317,
      "eval_samples_per_second": 1351.19,
      "eval_steps_per_second": 21.324,
      "step": 8786
    },
    {
      "epoch": 46.02094240837696,
      "grad_norm": 0.5643126368522644,
      "learning_rate": 0.000162,
      "loss": 0.8793,
      "step": 8790
    },
    {
      "epoch": 46.07329842931937,
      "grad_norm": 7.735987186431885,
      "learning_rate": 0.00016184293193717276,
      "loss": 0.8681,
      "step": 8800
    },
    {
      "epoch": 46.12565445026178,
      "grad_norm": 5.976812839508057,
      "learning_rate": 0.00016168586387434552,
      "loss": 0.8698,
      "step": 8810
    },
    {
      "epoch": 46.17801047120419,
      "grad_norm": 0.08365253359079361,
      "learning_rate": 0.00016152879581151833,
      "loss": 0.8838,
      "step": 8820
    },
    {
      "epoch": 46.230366492146594,
      "grad_norm": 0.20305266976356506,
      "learning_rate": 0.00016137172774869109,
      "loss": 0.8595,
      "step": 8830
    },
    {
      "epoch": 46.282722513089006,
      "grad_norm": 0.3253413736820221,
      "learning_rate": 0.00016121465968586384,
      "loss": 0.8635,
      "step": 8840
    },
    {
      "epoch": 46.33507853403141,
      "grad_norm": 0.4717187285423279,
      "learning_rate": 0.00016105759162303665,
      "loss": 0.8575,
      "step": 8850
    },
    {
      "epoch": 46.38743455497382,
      "grad_norm": 0.7693751454353333,
      "learning_rate": 0.0001609005235602094,
      "loss": 0.859,
      "step": 8860
    },
    {
      "epoch": 46.43979057591623,
      "grad_norm": 2.6647212505340576,
      "learning_rate": 0.0001607434554973822,
      "loss": 0.8622,
      "step": 8870
    },
    {
      "epoch": 46.49214659685864,
      "grad_norm": 1.6997350454330444,
      "learning_rate": 0.00016058638743455498,
      "loss": 0.8568,
      "step": 8880
    },
    {
      "epoch": 46.544502617801044,
      "grad_norm": 0.10326211154460907,
      "learning_rate": 0.00016042931937172773,
      "loss": 0.8709,
      "step": 8890
    },
    {
      "epoch": 46.596858638743456,
      "grad_norm": 4.172383785247803,
      "learning_rate": 0.00016027225130890051,
      "loss": 0.8841,
      "step": 8900
    },
    {
      "epoch": 46.64921465968587,
      "grad_norm": 0.18663866817951202,
      "learning_rate": 0.0001601151832460733,
      "loss": 0.858,
      "step": 8910
    },
    {
      "epoch": 46.70157068062827,
      "grad_norm": 3.471569299697876,
      "learning_rate": 0.00015995811518324605,
      "loss": 0.866,
      "step": 8920
    },
    {
      "epoch": 46.753926701570684,
      "grad_norm": 0.9260599613189697,
      "learning_rate": 0.00015980104712041884,
      "loss": 0.8653,
      "step": 8930
    },
    {
      "epoch": 46.80628272251309,
      "grad_norm": 7.628881931304932,
      "learning_rate": 0.00015964397905759162,
      "loss": 0.8765,
      "step": 8940
    },
    {
      "epoch": 46.8586387434555,
      "grad_norm": 4.38925313949585,
      "learning_rate": 0.00015948691099476438,
      "loss": 0.8583,
      "step": 8950
    },
    {
      "epoch": 46.910994764397905,
      "grad_norm": 0.9655048251152039,
      "learning_rate": 0.00015932984293193716,
      "loss": 0.8751,
      "step": 8960
    },
    {
      "epoch": 46.96335078534032,
      "grad_norm": 0.3892422616481781,
      "learning_rate": 0.00015917277486910994,
      "loss": 0.8682,
      "step": 8970
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.445480631276901,
      "eval_loss": 3.555670976638794,
      "eval_runtime": 1.012,
      "eval_samples_per_second": 1377.508,
      "eval_steps_per_second": 21.74,
      "step": 8977
    },
    {
      "epoch": 47.01570680628272,
      "grad_norm": 5.626297950744629,
      "learning_rate": 0.0001590157068062827,
      "loss": 0.8715,
      "step": 8980
    },
    {
      "epoch": 47.068062827225134,
      "grad_norm": 0.1255321204662323,
      "learning_rate": 0.00015885863874345548,
      "loss": 0.856,
      "step": 8990
    },
    {
      "epoch": 47.12041884816754,
      "grad_norm": 3.366899251937866,
      "learning_rate": 0.00015870157068062827,
      "loss": 0.8693,
      "step": 9000
    },
    {
      "epoch": 47.17277486910995,
      "grad_norm": 2.8155345916748047,
      "learning_rate": 0.00015854450261780102,
      "loss": 0.8674,
      "step": 9010
    },
    {
      "epoch": 47.225130890052355,
      "grad_norm": 2.4475085735321045,
      "learning_rate": 0.0001583874345549738,
      "loss": 0.856,
      "step": 9020
    },
    {
      "epoch": 47.27748691099477,
      "grad_norm": 0.12948670983314514,
      "learning_rate": 0.0001582303664921466,
      "loss": 0.8635,
      "step": 9030
    },
    {
      "epoch": 47.32984293193717,
      "grad_norm": 3.6847009658813477,
      "learning_rate": 0.00015807329842931937,
      "loss": 0.8644,
      "step": 9040
    },
    {
      "epoch": 47.382198952879584,
      "grad_norm": 3.0306456089019775,
      "learning_rate": 0.00015791623036649213,
      "loss": 0.872,
      "step": 9050
    },
    {
      "epoch": 47.43455497382199,
      "grad_norm": 0.12313726544380188,
      "learning_rate": 0.0001577591623036649,
      "loss": 0.8634,
      "step": 9060
    },
    {
      "epoch": 47.4869109947644,
      "grad_norm": 1.0321305990219116,
      "learning_rate": 0.0001576020942408377,
      "loss": 0.8648,
      "step": 9070
    },
    {
      "epoch": 47.539267015706805,
      "grad_norm": 4.352491855621338,
      "learning_rate": 0.00015744502617801045,
      "loss": 0.8668,
      "step": 9080
    },
    {
      "epoch": 47.59162303664922,
      "grad_norm": 7.431938171386719,
      "learning_rate": 0.00015728795811518323,
      "loss": 0.8665,
      "step": 9090
    },
    {
      "epoch": 47.64397905759162,
      "grad_norm": 1.0171667337417603,
      "learning_rate": 0.00015713089005235602,
      "loss": 0.8766,
      "step": 9100
    },
    {
      "epoch": 47.696335078534034,
      "grad_norm": 0.22449995577335358,
      "learning_rate": 0.00015697382198952877,
      "loss": 0.8636,
      "step": 9110
    },
    {
      "epoch": 47.74869109947644,
      "grad_norm": 0.39213886857032776,
      "learning_rate": 0.00015681675392670156,
      "loss": 0.8611,
      "step": 9120
    },
    {
      "epoch": 47.80104712041885,
      "grad_norm": 3.596480369567871,
      "learning_rate": 0.00015665968586387434,
      "loss": 0.8629,
      "step": 9130
    },
    {
      "epoch": 47.853403141361255,
      "grad_norm": 2.999150037765503,
      "learning_rate": 0.0001565026178010471,
      "loss": 0.8645,
      "step": 9140
    },
    {
      "epoch": 47.90575916230367,
      "grad_norm": 10.193937301635742,
      "learning_rate": 0.00015634554973821988,
      "loss": 0.8606,
      "step": 9150
    },
    {
      "epoch": 47.95811518324607,
      "grad_norm": 0.24862398207187653,
      "learning_rate": 0.00015618848167539266,
      "loss": 0.8646,
      "step": 9160
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.4397417503586801,
      "eval_loss": 3.6032803058624268,
      "eval_runtime": 1.1022,
      "eval_samples_per_second": 1264.697,
      "eval_steps_per_second": 19.959,
      "step": 9168
    },
    {
      "epoch": 48.010471204188484,
      "grad_norm": 2.0834686756134033,
      "learning_rate": 0.00015603141361256542,
      "loss": 0.8758,
      "step": 9170
    },
    {
      "epoch": 48.06282722513089,
      "grad_norm": 1.4905575513839722,
      "learning_rate": 0.00015587434554973823,
      "loss": 0.8606,
      "step": 9180
    },
    {
      "epoch": 48.1151832460733,
      "grad_norm": 0.08895306289196014,
      "learning_rate": 0.00015571727748691099,
      "loss": 0.8565,
      "step": 9190
    },
    {
      "epoch": 48.167539267015705,
      "grad_norm": 0.08869164437055588,
      "learning_rate": 0.00015556020942408374,
      "loss": 0.8571,
      "step": 9200
    },
    {
      "epoch": 48.21989528795812,
      "grad_norm": 0.07880596816539764,
      "learning_rate": 0.00015540314136125655,
      "loss": 0.8551,
      "step": 9210
    },
    {
      "epoch": 48.27225130890052,
      "grad_norm": 0.05497318133711815,
      "learning_rate": 0.0001552460732984293,
      "loss": 0.8584,
      "step": 9220
    },
    {
      "epoch": 48.324607329842934,
      "grad_norm": 0.8314473628997803,
      "learning_rate": 0.00015508900523560206,
      "loss": 0.8575,
      "step": 9230
    },
    {
      "epoch": 48.37696335078534,
      "grad_norm": 0.1285446286201477,
      "learning_rate": 0.00015493193717277487,
      "loss": 0.862,
      "step": 9240
    },
    {
      "epoch": 48.42931937172775,
      "grad_norm": 3.808007001876831,
      "learning_rate": 0.00015477486910994763,
      "loss": 0.8703,
      "step": 9250
    },
    {
      "epoch": 48.481675392670155,
      "grad_norm": 0.11602812260389328,
      "learning_rate": 0.0001546178010471204,
      "loss": 0.8571,
      "step": 9260
    },
    {
      "epoch": 48.53403141361257,
      "grad_norm": 0.09821480512619019,
      "learning_rate": 0.0001544607329842932,
      "loss": 0.8555,
      "step": 9270
    },
    {
      "epoch": 48.58638743455497,
      "grad_norm": 0.6439082026481628,
      "learning_rate": 0.00015430366492146595,
      "loss": 0.8749,
      "step": 9280
    },
    {
      "epoch": 48.638743455497384,
      "grad_norm": 10.109980583190918,
      "learning_rate": 0.0001541465968586387,
      "loss": 0.8615,
      "step": 9290
    },
    {
      "epoch": 48.69109947643979,
      "grad_norm": 2.6755123138427734,
      "learning_rate": 0.00015398952879581152,
      "loss": 0.8617,
      "step": 9300
    },
    {
      "epoch": 48.7434554973822,
      "grad_norm": 5.497951030731201,
      "learning_rate": 0.00015383246073298428,
      "loss": 0.8624,
      "step": 9310
    },
    {
      "epoch": 48.795811518324605,
      "grad_norm": 2.9365575313568115,
      "learning_rate": 0.00015367539267015703,
      "loss": 0.8731,
      "step": 9320
    },
    {
      "epoch": 48.84816753926702,
      "grad_norm": 0.07688285410404205,
      "learning_rate": 0.00015351832460732984,
      "loss": 0.8619,
      "step": 9330
    },
    {
      "epoch": 48.90052356020942,
      "grad_norm": 0.10444717109203339,
      "learning_rate": 0.0001533612565445026,
      "loss": 0.8707,
      "step": 9340
    },
    {
      "epoch": 48.952879581151834,
      "grad_norm": 6.9584150314331055,
      "learning_rate": 0.00015320418848167538,
      "loss": 0.8782,
      "step": 9350
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.43902439024390244,
      "eval_loss": 3.614027261734009,
      "eval_runtime": 0.9687,
      "eval_samples_per_second": 1439.106,
      "eval_steps_per_second": 22.712,
      "step": 9359
    },
    {
      "epoch": 49.00523560209424,
      "grad_norm": 0.27067065238952637,
      "learning_rate": 0.00015304712041884817,
      "loss": 0.8922,
      "step": 9360
    },
    {
      "epoch": 49.05759162303665,
      "grad_norm": 1.7130454778671265,
      "learning_rate": 0.00015289005235602092,
      "loss": 0.8685,
      "step": 9370
    },
    {
      "epoch": 49.109947643979055,
      "grad_norm": 5.475443363189697,
      "learning_rate": 0.0001527329842931937,
      "loss": 0.8648,
      "step": 9380
    },
    {
      "epoch": 49.16230366492147,
      "grad_norm": 0.49563345313072205,
      "learning_rate": 0.0001525759162303665,
      "loss": 0.8849,
      "step": 9390
    },
    {
      "epoch": 49.21465968586387,
      "grad_norm": 3.434161424636841,
      "learning_rate": 0.00015241884816753924,
      "loss": 0.8768,
      "step": 9400
    },
    {
      "epoch": 49.26701570680628,
      "grad_norm": 3.525745153427124,
      "learning_rate": 0.00015226178010471203,
      "loss": 0.8819,
      "step": 9410
    },
    {
      "epoch": 49.31937172774869,
      "grad_norm": 0.6105772256851196,
      "learning_rate": 0.0001521047120418848,
      "loss": 0.8666,
      "step": 9420
    },
    {
      "epoch": 49.3717277486911,
      "grad_norm": 4.451549530029297,
      "learning_rate": 0.00015194764397905757,
      "loss": 0.8801,
      "step": 9430
    },
    {
      "epoch": 49.424083769633505,
      "grad_norm": 0.09280972927808762,
      "learning_rate": 0.00015179057591623035,
      "loss": 0.872,
      "step": 9440
    },
    {
      "epoch": 49.47643979057592,
      "grad_norm": 2.277801513671875,
      "learning_rate": 0.00015163350785340313,
      "loss": 0.8807,
      "step": 9450
    },
    {
      "epoch": 49.52879581151832,
      "grad_norm": 1.0219844579696655,
      "learning_rate": 0.0001514764397905759,
      "loss": 0.864,
      "step": 9460
    },
    {
      "epoch": 49.58115183246073,
      "grad_norm": 9.513678550720215,
      "learning_rate": 0.00015131937172774867,
      "loss": 0.8741,
      "step": 9470
    },
    {
      "epoch": 49.63350785340314,
      "grad_norm": 5.040912628173828,
      "learning_rate": 0.00015116230366492146,
      "loss": 0.8632,
      "step": 9480
    },
    {
      "epoch": 49.68586387434555,
      "grad_norm": 0.41671472787857056,
      "learning_rate": 0.00015100523560209424,
      "loss": 0.886,
      "step": 9490
    },
    {
      "epoch": 49.738219895287955,
      "grad_norm": 0.1216418445110321,
      "learning_rate": 0.000150848167539267,
      "loss": 0.8619,
      "step": 9500
    },
    {
      "epoch": 49.79057591623037,
      "grad_norm": 0.9979985356330872,
      "learning_rate": 0.00015069109947643978,
      "loss": 0.8647,
      "step": 9510
    },
    {
      "epoch": 49.84293193717277,
      "grad_norm": 0.26385417580604553,
      "learning_rate": 0.00015053403141361256,
      "loss": 0.8566,
      "step": 9520
    },
    {
      "epoch": 49.89528795811518,
      "grad_norm": 1.5697623491287231,
      "learning_rate": 0.00015037696335078532,
      "loss": 0.8812,
      "step": 9530
    },
    {
      "epoch": 49.94764397905759,
      "grad_norm": 7.436017990112305,
      "learning_rate": 0.0001502198952879581,
      "loss": 0.8832,
      "step": 9540
    },
    {
      "epoch": 50.0,
      "grad_norm": 20.922401428222656,
      "learning_rate": 0.00015006282722513088,
      "loss": 0.8781,
      "step": 9550
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.4375896700143472,
      "eval_loss": 3.547532081604004,
      "eval_runtime": 1.0018,
      "eval_samples_per_second": 1391.517,
      "eval_steps_per_second": 21.961,
      "step": 9550
    },
    {
      "epoch": 50.05235602094241,
      "grad_norm": 0.08431365340948105,
      "learning_rate": 0.00014990575916230364,
      "loss": 0.8567,
      "step": 9560
    },
    {
      "epoch": 50.10471204188482,
      "grad_norm": 0.13500501215457916,
      "learning_rate": 0.00014974869109947642,
      "loss": 0.8697,
      "step": 9570
    },
    {
      "epoch": 50.15706806282723,
      "grad_norm": 0.17330145835876465,
      "learning_rate": 0.0001495916230366492,
      "loss": 0.8553,
      "step": 9580
    },
    {
      "epoch": 50.20942408376963,
      "grad_norm": 5.466397762298584,
      "learning_rate": 0.00014943455497382196,
      "loss": 0.871,
      "step": 9590
    },
    {
      "epoch": 50.261780104712045,
      "grad_norm": 0.38366150856018066,
      "learning_rate": 0.00014927748691099475,
      "loss": 0.8587,
      "step": 9600
    },
    {
      "epoch": 50.31413612565445,
      "grad_norm": 0.4164479970932007,
      "learning_rate": 0.00014912041884816753,
      "loss": 0.8684,
      "step": 9610
    },
    {
      "epoch": 50.36649214659686,
      "grad_norm": 0.592257022857666,
      "learning_rate": 0.00014896335078534029,
      "loss": 0.8601,
      "step": 9620
    },
    {
      "epoch": 50.41884816753927,
      "grad_norm": 0.5201643109321594,
      "learning_rate": 0.00014880628272251307,
      "loss": 0.8748,
      "step": 9630
    },
    {
      "epoch": 50.47120418848168,
      "grad_norm": 1.0676259994506836,
      "learning_rate": 0.00014864921465968585,
      "loss": 0.8588,
      "step": 9640
    },
    {
      "epoch": 50.52356020942408,
      "grad_norm": 0.0719355046749115,
      "learning_rate": 0.0001484921465968586,
      "loss": 0.8602,
      "step": 9650
    },
    {
      "epoch": 50.575916230366495,
      "grad_norm": 0.47481879591941833,
      "learning_rate": 0.0001483350785340314,
      "loss": 0.8665,
      "step": 9660
    },
    {
      "epoch": 50.6282722513089,
      "grad_norm": 0.9435774087905884,
      "learning_rate": 0.00014817801047120418,
      "loss": 0.8549,
      "step": 9670
    },
    {
      "epoch": 50.68062827225131,
      "grad_norm": 0.35277026891708374,
      "learning_rate": 0.00014802094240837696,
      "loss": 0.8638,
      "step": 9680
    },
    {
      "epoch": 50.73298429319372,
      "grad_norm": 0.1575048565864563,
      "learning_rate": 0.00014786387434554971,
      "loss": 0.8578,
      "step": 9690
    },
    {
      "epoch": 50.78534031413613,
      "grad_norm": 0.23799890279769897,
      "learning_rate": 0.0001477068062827225,
      "loss": 0.8664,
      "step": 9700
    },
    {
      "epoch": 50.83769633507853,
      "grad_norm": 4.24805212020874,
      "learning_rate": 0.00014754973821989528,
      "loss": 0.8623,
      "step": 9710
    },
    {
      "epoch": 50.890052356020945,
      "grad_norm": 0.35082000494003296,
      "learning_rate": 0.00014739267015706804,
      "loss": 0.8656,
      "step": 9720
    },
    {
      "epoch": 50.94240837696335,
      "grad_norm": 0.8429731726646423,
      "learning_rate": 0.00014723560209424082,
      "loss": 0.8609,
      "step": 9730
    },
    {
      "epoch": 50.99476439790576,
      "grad_norm": 5.354487419128418,
      "learning_rate": 0.0001470785340314136,
      "loss": 0.8716,
      "step": 9740
    },
    {
      "epoch": 51.0,
      "eval_accuracy": 0.42898134863701576,
      "eval_loss": 3.680901527404785,
      "eval_runtime": 1.0141,
      "eval_samples_per_second": 1374.56,
      "eval_steps_per_second": 21.693,
      "step": 9741
    },
    {
      "epoch": 51.047120418848166,
      "grad_norm": 0.3768581748008728,
      "learning_rate": 0.0001469214659685864,
      "loss": 0.8591,
      "step": 9750
    },
    {
      "epoch": 51.09947643979058,
      "grad_norm": 0.11218596994876862,
      "learning_rate": 0.00014676439790575914,
      "loss": 0.86,
      "step": 9760
    },
    {
      "epoch": 51.15183246073298,
      "grad_norm": 7.267467021942139,
      "learning_rate": 0.00014660732984293193,
      "loss": 0.8862,
      "step": 9770
    },
    {
      "epoch": 51.204188481675395,
      "grad_norm": 0.2590273320674896,
      "learning_rate": 0.00014646596858638742,
      "loss": 0.8618,
      "step": 9780
    },
    {
      "epoch": 51.2565445026178,
      "grad_norm": 0.5249505639076233,
      "learning_rate": 0.0001463089005235602,
      "loss": 0.8551,
      "step": 9790
    },
    {
      "epoch": 51.30890052356021,
      "grad_norm": 0.05898081883788109,
      "learning_rate": 0.00014615183246073296,
      "loss": 0.8626,
      "step": 9800
    },
    {
      "epoch": 51.361256544502616,
      "grad_norm": 0.15539643168449402,
      "learning_rate": 0.00014599476439790574,
      "loss": 0.8553,
      "step": 9810
    },
    {
      "epoch": 51.41361256544503,
      "grad_norm": 0.08132760226726532,
      "learning_rate": 0.00014583769633507853,
      "loss": 0.8603,
      "step": 9820
    },
    {
      "epoch": 51.46596858638743,
      "grad_norm": 6.770730972290039,
      "learning_rate": 0.0001456806282722513,
      "loss": 0.8616,
      "step": 9830
    },
    {
      "epoch": 51.518324607329845,
      "grad_norm": 1.4228291511535645,
      "learning_rate": 0.00014552356020942407,
      "loss": 0.8652,
      "step": 9840
    },
    {
      "epoch": 51.57068062827225,
      "grad_norm": 2.3389458656311035,
      "learning_rate": 0.00014536649214659685,
      "loss": 0.8666,
      "step": 9850
    },
    {
      "epoch": 51.62303664921466,
      "grad_norm": 0.23143555223941803,
      "learning_rate": 0.00014520942408376963,
      "loss": 0.8615,
      "step": 9860
    },
    {
      "epoch": 51.675392670157066,
      "grad_norm": 1.7019685506820679,
      "learning_rate": 0.0001450523560209424,
      "loss": 0.8648,
      "step": 9870
    },
    {
      "epoch": 51.72774869109948,
      "grad_norm": 1.4929687976837158,
      "learning_rate": 0.00014489528795811517,
      "loss": 0.8729,
      "step": 9880
    },
    {
      "epoch": 51.78010471204188,
      "grad_norm": 4.380250930786133,
      "learning_rate": 0.00014473821989528795,
      "loss": 0.9058,
      "step": 9890
    },
    {
      "epoch": 51.832460732984295,
      "grad_norm": 1.9263144731521606,
      "learning_rate": 0.0001445811518324607,
      "loss": 0.8627,
      "step": 9900
    },
    {
      "epoch": 51.8848167539267,
      "grad_norm": 0.41298049688339233,
      "learning_rate": 0.0001444240837696335,
      "loss": 0.8622,
      "step": 9910
    },
    {
      "epoch": 51.93717277486911,
      "grad_norm": 0.14840005338191986,
      "learning_rate": 0.00014426701570680628,
      "loss": 0.8706,
      "step": 9920
    },
    {
      "epoch": 51.989528795811516,
      "grad_norm": 4.864578723907471,
      "learning_rate": 0.00014410994764397906,
      "loss": 0.8686,
      "step": 9930
    },
    {
      "epoch": 52.0,
      "eval_accuracy": 0.4447632711621234,
      "eval_loss": 3.527099609375,
      "eval_runtime": 0.9942,
      "eval_samples_per_second": 1402.183,
      "eval_steps_per_second": 22.129,
      "step": 9932
    },
    {
      "epoch": 52.04188481675393,
      "grad_norm": 1.604156494140625,
      "learning_rate": 0.00014395287958115182,
      "loss": 0.8549,
      "step": 9940
    },
    {
      "epoch": 52.09424083769633,
      "grad_norm": 7.026030540466309,
      "learning_rate": 0.0001437958115183246,
      "loss": 0.8589,
      "step": 9950
    },
    {
      "epoch": 52.146596858638745,
      "grad_norm": 0.8292596340179443,
      "learning_rate": 0.00014363874345549738,
      "loss": 0.8663,
      "step": 9960
    },
    {
      "epoch": 52.19895287958115,
      "grad_norm": 10.354178428649902,
      "learning_rate": 0.00014348167539267014,
      "loss": 0.861,
      "step": 9970
    },
    {
      "epoch": 52.25130890052356,
      "grad_norm": 1.7959855794906616,
      "learning_rate": 0.00014332460732984292,
      "loss": 0.8591,
      "step": 9980
    },
    {
      "epoch": 52.303664921465966,
      "grad_norm": 5.947726249694824,
      "learning_rate": 0.0001431675392670157,
      "loss": 0.8723,
      "step": 9990
    },
    {
      "epoch": 52.35602094240838,
      "grad_norm": 0.7948188185691833,
      "learning_rate": 0.0001430104712041885,
      "loss": 0.8575,
      "step": 10000
    },
    {
      "epoch": 52.40837696335078,
      "grad_norm": 2.2126922607421875,
      "learning_rate": 0.00014285340314136125,
      "loss": 0.8646,
      "step": 10010
    },
    {
      "epoch": 52.460732984293195,
      "grad_norm": 0.06075079366564751,
      "learning_rate": 0.00014269633507853403,
      "loss": 0.8738,
      "step": 10020
    },
    {
      "epoch": 52.5130890052356,
      "grad_norm": 1.5848309993743896,
      "learning_rate": 0.00014253926701570678,
      "loss": 0.8709,
      "step": 10030
    },
    {
      "epoch": 52.56544502617801,
      "grad_norm": 14.175274848937988,
      "learning_rate": 0.00014238219895287957,
      "loss": 0.8633,
      "step": 10040
    },
    {
      "epoch": 52.617801047120416,
      "grad_norm": 5.580414772033691,
      "learning_rate": 0.00014222513089005235,
      "loss": 0.8623,
      "step": 10050
    },
    {
      "epoch": 52.67015706806283,
      "grad_norm": 2.877939462661743,
      "learning_rate": 0.0001420680628272251,
      "loss": 0.8591,
      "step": 10060
    },
    {
      "epoch": 52.72251308900523,
      "grad_norm": 6.363104343414307,
      "learning_rate": 0.0001419109947643979,
      "loss": 0.8771,
      "step": 10070
    },
    {
      "epoch": 52.774869109947645,
      "grad_norm": 0.39447253942489624,
      "learning_rate": 0.00014175392670157067,
      "loss": 0.8781,
      "step": 10080
    },
    {
      "epoch": 52.82722513089005,
      "grad_norm": 1.0668673515319824,
      "learning_rate": 0.00014159685863874343,
      "loss": 0.8718,
      "step": 10090
    },
    {
      "epoch": 52.87958115183246,
      "grad_norm": 0.14251895248889923,
      "learning_rate": 0.0001414397905759162,
      "loss": 0.871,
      "step": 10100
    },
    {
      "epoch": 52.931937172774866,
      "grad_norm": 6.970221996307373,
      "learning_rate": 0.000141282722513089,
      "loss": 0.8811,
      "step": 10110
    },
    {
      "epoch": 52.98429319371728,
      "grad_norm": 0.17027975618839264,
      "learning_rate": 0.00014112565445026175,
      "loss": 0.8638,
      "step": 10120
    },
    {
      "epoch": 53.0,
      "eval_accuracy": 0.4383070301291248,
      "eval_loss": 3.549471616744995,
      "eval_runtime": 1.1974,
      "eval_samples_per_second": 1164.174,
      "eval_steps_per_second": 18.373,
      "step": 10123
    },
    {
      "epoch": 53.03664921465968,
      "grad_norm": 0.22263674437999725,
      "learning_rate": 0.00014096858638743454,
      "loss": 0.8723,
      "step": 10130
    },
    {
      "epoch": 53.089005235602095,
      "grad_norm": 0.701492428779602,
      "learning_rate": 0.00014081151832460732,
      "loss": 0.855,
      "step": 10140
    },
    {
      "epoch": 53.1413612565445,
      "grad_norm": 4.517477035522461,
      "learning_rate": 0.00014065445026178008,
      "loss": 0.8687,
      "step": 10150
    },
    {
      "epoch": 53.19371727748691,
      "grad_norm": 0.4362083971500397,
      "learning_rate": 0.00014049738219895286,
      "loss": 0.8579,
      "step": 10160
    },
    {
      "epoch": 53.246073298429316,
      "grad_norm": 0.30646154284477234,
      "learning_rate": 0.00014034031413612564,
      "loss": 0.8649,
      "step": 10170
    },
    {
      "epoch": 53.29842931937173,
      "grad_norm": 0.3055818974971771,
      "learning_rate": 0.0001401832460732984,
      "loss": 0.8665,
      "step": 10180
    },
    {
      "epoch": 53.35078534031413,
      "grad_norm": 0.16278932988643646,
      "learning_rate": 0.00014002617801047118,
      "loss": 0.8716,
      "step": 10190
    },
    {
      "epoch": 53.403141361256544,
      "grad_norm": 0.3144684433937073,
      "learning_rate": 0.00013986910994764396,
      "loss": 0.8705,
      "step": 10200
    },
    {
      "epoch": 53.455497382198956,
      "grad_norm": 3.845985174179077,
      "learning_rate": 0.00013971204188481675,
      "loss": 0.8737,
      "step": 10210
    },
    {
      "epoch": 53.50785340314136,
      "grad_norm": 6.329539775848389,
      "learning_rate": 0.0001395549738219895,
      "loss": 0.877,
      "step": 10220
    },
    {
      "epoch": 53.56020942408377,
      "grad_norm": 0.08378209173679352,
      "learning_rate": 0.0001393979057591623,
      "loss": 0.8654,
      "step": 10230
    },
    {
      "epoch": 53.61256544502618,
      "grad_norm": 2.575054883956909,
      "learning_rate": 0.00013924083769633507,
      "loss": 0.8755,
      "step": 10240
    },
    {
      "epoch": 53.66492146596859,
      "grad_norm": 0.4505001902580261,
      "learning_rate": 0.00013908376963350783,
      "loss": 0.856,
      "step": 10250
    },
    {
      "epoch": 53.717277486910994,
      "grad_norm": 3.602252960205078,
      "learning_rate": 0.0001389267015706806,
      "loss": 0.8649,
      "step": 10260
    },
    {
      "epoch": 53.769633507853406,
      "grad_norm": 0.38784465193748474,
      "learning_rate": 0.0001387696335078534,
      "loss": 0.8598,
      "step": 10270
    },
    {
      "epoch": 53.82198952879581,
      "grad_norm": 5.388652324676514,
      "learning_rate": 0.00013861256544502615,
      "loss": 0.8793,
      "step": 10280
    },
    {
      "epoch": 53.87434554973822,
      "grad_norm": 0.8555106520652771,
      "learning_rate": 0.00013845549738219893,
      "loss": 0.8695,
      "step": 10290
    },
    {
      "epoch": 53.92670157068063,
      "grad_norm": 0.09858815371990204,
      "learning_rate": 0.00013829842931937172,
      "loss": 0.8612,
      "step": 10300
    },
    {
      "epoch": 53.97905759162304,
      "grad_norm": 1.3508166074752808,
      "learning_rate": 0.0001381413612565445,
      "loss": 0.8769,
      "step": 10310
    },
    {
      "epoch": 54.0,
      "eval_accuracy": 0.43113342898134865,
      "eval_loss": 3.612537384033203,
      "eval_runtime": 0.9986,
      "eval_samples_per_second": 1395.996,
      "eval_steps_per_second": 22.031,
      "step": 10314
    },
    {
      "epoch": 54.031413612565444,
      "grad_norm": 3.64178729057312,
      "learning_rate": 0.00013798429319371726,
      "loss": 0.8577,
      "step": 10320
    },
    {
      "epoch": 54.083769633507856,
      "grad_norm": 0.05809919536113739,
      "learning_rate": 0.00013782722513089004,
      "loss": 0.8771,
      "step": 10330
    },
    {
      "epoch": 54.13612565445026,
      "grad_norm": 0.09536252170801163,
      "learning_rate": 0.00013767015706806282,
      "loss": 0.8585,
      "step": 10340
    },
    {
      "epoch": 54.18848167539267,
      "grad_norm": 0.07765000313520432,
      "learning_rate": 0.00013751308900523558,
      "loss": 0.8612,
      "step": 10350
    },
    {
      "epoch": 54.24083769633508,
      "grad_norm": 0.614834725856781,
      "learning_rate": 0.00013735602094240836,
      "loss": 0.8694,
      "step": 10360
    },
    {
      "epoch": 54.29319371727749,
      "grad_norm": 0.8481613397598267,
      "learning_rate": 0.00013719895287958114,
      "loss": 0.8559,
      "step": 10370
    },
    {
      "epoch": 54.345549738219894,
      "grad_norm": 0.5558972954750061,
      "learning_rate": 0.00013704188481675393,
      "loss": 0.8537,
      "step": 10380
    },
    {
      "epoch": 54.397905759162306,
      "grad_norm": 3.84073543548584,
      "learning_rate": 0.00013688481675392668,
      "loss": 0.8559,
      "step": 10390
    },
    {
      "epoch": 54.45026178010471,
      "grad_norm": 0.6164037585258484,
      "learning_rate": 0.00013672774869109947,
      "loss": 0.8551,
      "step": 10400
    },
    {
      "epoch": 54.50261780104712,
      "grad_norm": 0.04048280790448189,
      "learning_rate": 0.00013657068062827225,
      "loss": 0.8536,
      "step": 10410
    },
    {
      "epoch": 54.55497382198953,
      "grad_norm": 0.22814209759235382,
      "learning_rate": 0.000136413612565445,
      "loss": 0.8628,
      "step": 10420
    },
    {
      "epoch": 54.60732984293194,
      "grad_norm": 0.9578104019165039,
      "learning_rate": 0.0001362565445026178,
      "loss": 0.8568,
      "step": 10430
    },
    {
      "epoch": 54.659685863874344,
      "grad_norm": 0.040466587990522385,
      "learning_rate": 0.00013609947643979057,
      "loss": 0.8536,
      "step": 10440
    },
    {
      "epoch": 54.712041884816756,
      "grad_norm": 0.060697510838508606,
      "learning_rate": 0.00013594240837696336,
      "loss": 0.866,
      "step": 10450
    },
    {
      "epoch": 54.76439790575916,
      "grad_norm": 0.230520561337471,
      "learning_rate": 0.0001357853403141361,
      "loss": 0.8617,
      "step": 10460
    },
    {
      "epoch": 54.81675392670157,
      "grad_norm": 0.04734830930829048,
      "learning_rate": 0.0001356282722513089,
      "loss": 0.8539,
      "step": 10470
    },
    {
      "epoch": 54.86910994764398,
      "grad_norm": 3.447538137435913,
      "learning_rate": 0.00013547120418848168,
      "loss": 0.8605,
      "step": 10480
    },
    {
      "epoch": 54.92146596858639,
      "grad_norm": 0.12747447192668915,
      "learning_rate": 0.00013531413612565444,
      "loss": 0.8563,
      "step": 10490
    },
    {
      "epoch": 54.973821989528794,
      "grad_norm": 0.5545139312744141,
      "learning_rate": 0.00013515706806282722,
      "loss": 0.8628,
      "step": 10500
    },
    {
      "epoch": 55.0,
      "eval_accuracy": 0.4490674318507891,
      "eval_loss": 3.5070748329162598,
      "eval_runtime": 1.0024,
      "eval_samples_per_second": 1390.617,
      "eval_steps_per_second": 21.947,
      "step": 10505
    },
    {
      "epoch": 55.026178010471206,
      "grad_norm": 0.09769583493471146,
      "learning_rate": 0.000135,
      "loss": 0.859,
      "step": 10510
    },
    {
      "epoch": 55.07853403141361,
      "grad_norm": 0.24711763858795166,
      "learning_rate": 0.00013484293193717276,
      "loss": 0.8543,
      "step": 10520
    },
    {
      "epoch": 55.13089005235602,
      "grad_norm": 0.05251475051045418,
      "learning_rate": 0.00013468586387434554,
      "loss": 0.862,
      "step": 10530
    },
    {
      "epoch": 55.18324607329843,
      "grad_norm": 0.30001628398895264,
      "learning_rate": 0.00013452879581151832,
      "loss": 0.8554,
      "step": 10540
    },
    {
      "epoch": 55.23560209424084,
      "grad_norm": 2.68390154838562,
      "learning_rate": 0.00013437172774869108,
      "loss": 0.8553,
      "step": 10550
    },
    {
      "epoch": 55.287958115183244,
      "grad_norm": 3.7984187602996826,
      "learning_rate": 0.00013421465968586386,
      "loss": 0.8586,
      "step": 10560
    },
    {
      "epoch": 55.340314136125656,
      "grad_norm": 0.07542329281568527,
      "learning_rate": 0.00013405759162303665,
      "loss": 0.8634,
      "step": 10570
    },
    {
      "epoch": 55.39267015706806,
      "grad_norm": 0.09515605866909027,
      "learning_rate": 0.0001339005235602094,
      "loss": 0.8539,
      "step": 10580
    },
    {
      "epoch": 55.44502617801047,
      "grad_norm": 1.627756953239441,
      "learning_rate": 0.0001337434554973822,
      "loss": 0.8583,
      "step": 10590
    },
    {
      "epoch": 55.49738219895288,
      "grad_norm": 0.06796354800462723,
      "learning_rate": 0.00013358638743455497,
      "loss": 0.8594,
      "step": 10600
    },
    {
      "epoch": 55.54973821989529,
      "grad_norm": 2.592149496078491,
      "learning_rate": 0.00013342931937172773,
      "loss": 0.8672,
      "step": 10610
    },
    {
      "epoch": 55.602094240837694,
      "grad_norm": 1.6282683610916138,
      "learning_rate": 0.0001332722513089005,
      "loss": 0.8667,
      "step": 10620
    },
    {
      "epoch": 55.654450261780106,
      "grad_norm": 1.9716596603393555,
      "learning_rate": 0.0001331151832460733,
      "loss": 0.8626,
      "step": 10630
    },
    {
      "epoch": 55.70680628272251,
      "grad_norm": 1.8205691576004028,
      "learning_rate": 0.00013295811518324605,
      "loss": 0.8636,
      "step": 10640
    },
    {
      "epoch": 55.75916230366492,
      "grad_norm": 1.071871280670166,
      "learning_rate": 0.00013280104712041883,
      "loss": 0.8658,
      "step": 10650
    },
    {
      "epoch": 55.81151832460733,
      "grad_norm": 0.06151121109724045,
      "learning_rate": 0.00013264397905759162,
      "loss": 0.8558,
      "step": 10660
    },
    {
      "epoch": 55.86387434554974,
      "grad_norm": 2.235428810119629,
      "learning_rate": 0.00013248691099476437,
      "loss": 0.8604,
      "step": 10670
    },
    {
      "epoch": 55.916230366492144,
      "grad_norm": 3.242851972579956,
      "learning_rate": 0.00013232984293193715,
      "loss": 0.8734,
      "step": 10680
    },
    {
      "epoch": 55.968586387434556,
      "grad_norm": 5.791597366333008,
      "learning_rate": 0.00013217277486910994,
      "loss": 0.856,
      "step": 10690
    },
    {
      "epoch": 56.0,
      "eval_accuracy": 0.43543758967001434,
      "eval_loss": 3.641493320465088,
      "eval_runtime": 0.9899,
      "eval_samples_per_second": 1408.251,
      "eval_steps_per_second": 22.225,
      "step": 10696
    },
    {
      "epoch": 56.02094240837696,
      "grad_norm": 5.694457054138184,
      "learning_rate": 0.0001320157068062827,
      "loss": 0.8579,
      "step": 10700
    },
    {
      "epoch": 56.07329842931937,
      "grad_norm": 0.8700372576713562,
      "learning_rate": 0.00013185863874345548,
      "loss": 0.8554,
      "step": 10710
    },
    {
      "epoch": 56.12565445026178,
      "grad_norm": 0.054063718765974045,
      "learning_rate": 0.00013170157068062826,
      "loss": 0.8578,
      "step": 10720
    },
    {
      "epoch": 56.17801047120419,
      "grad_norm": 0.09469261020421982,
      "learning_rate": 0.00013154450261780102,
      "loss": 0.8695,
      "step": 10730
    },
    {
      "epoch": 56.230366492146594,
      "grad_norm": 0.05283091962337494,
      "learning_rate": 0.0001313874345549738,
      "loss": 0.858,
      "step": 10740
    },
    {
      "epoch": 56.282722513089006,
      "grad_norm": 1.497544288635254,
      "learning_rate": 0.00013123036649214658,
      "loss": 0.8712,
      "step": 10750
    },
    {
      "epoch": 56.33507853403141,
      "grad_norm": 0.5940939784049988,
      "learning_rate": 0.00013107329842931937,
      "loss": 0.8558,
      "step": 10760
    },
    {
      "epoch": 56.38743455497382,
      "grad_norm": 0.14789964258670807,
      "learning_rate": 0.00013091623036649212,
      "loss": 0.8628,
      "step": 10770
    },
    {
      "epoch": 56.43979057591623,
      "grad_norm": 0.16231775283813477,
      "learning_rate": 0.0001307591623036649,
      "loss": 0.8539,
      "step": 10780
    },
    {
      "epoch": 56.49214659685864,
      "grad_norm": 0.058376140892505646,
      "learning_rate": 0.0001306020942408377,
      "loss": 0.8576,
      "step": 10790
    },
    {
      "epoch": 56.544502617801044,
      "grad_norm": 0.16295088827610016,
      "learning_rate": 0.00013044502617801045,
      "loss": 0.8562,
      "step": 10800
    },
    {
      "epoch": 56.596858638743456,
      "grad_norm": 0.08349199593067169,
      "learning_rate": 0.00013028795811518323,
      "loss": 0.8647,
      "step": 10810
    },
    {
      "epoch": 56.64921465968587,
      "grad_norm": 0.03410622477531433,
      "learning_rate": 0.000130130890052356,
      "loss": 0.8549,
      "step": 10820
    },
    {
      "epoch": 56.70157068062827,
      "grad_norm": 0.19854755699634552,
      "learning_rate": 0.0001299738219895288,
      "loss": 0.8621,
      "step": 10830
    },
    {
      "epoch": 56.753926701570684,
      "grad_norm": 4.420285701751709,
      "learning_rate": 0.00012981675392670155,
      "loss": 0.8658,
      "step": 10840
    },
    {
      "epoch": 56.80628272251309,
      "grad_norm": 7.009966850280762,
      "learning_rate": 0.00012965968586387433,
      "loss": 0.8593,
      "step": 10850
    },
    {
      "epoch": 56.8586387434555,
      "grad_norm": 0.05256492644548416,
      "learning_rate": 0.00012950261780104712,
      "loss": 0.8632,
      "step": 10860
    },
    {
      "epoch": 56.910994764397905,
      "grad_norm": 0.36787843704223633,
      "learning_rate": 0.00012934554973821987,
      "loss": 0.8622,
      "step": 10870
    },
    {
      "epoch": 56.96335078534032,
      "grad_norm": 0.10380220413208008,
      "learning_rate": 0.00012918848167539266,
      "loss": 0.873,
      "step": 10880
    },
    {
      "epoch": 57.0,
      "eval_accuracy": 0.44261119081779055,
      "eval_loss": 3.5743913650512695,
      "eval_runtime": 1.0041,
      "eval_samples_per_second": 1388.255,
      "eval_steps_per_second": 21.909,
      "step": 10887
    },
    {
      "epoch": 57.01570680628272,
      "grad_norm": 0.09081289917230606,
      "learning_rate": 0.00012903141361256544,
      "loss": 0.8561,
      "step": 10890
    },
    {
      "epoch": 57.068062827225134,
      "grad_norm": 0.05356711521744728,
      "learning_rate": 0.0001288743455497382,
      "loss": 0.8542,
      "step": 10900
    },
    {
      "epoch": 57.12041884816754,
      "grad_norm": 0.1095486581325531,
      "learning_rate": 0.00012871727748691098,
      "loss": 0.8714,
      "step": 10910
    },
    {
      "epoch": 57.17277486910995,
      "grad_norm": 2.93896746635437,
      "learning_rate": 0.00012856020942408376,
      "loss": 0.8549,
      "step": 10920
    },
    {
      "epoch": 57.225130890052355,
      "grad_norm": 2.2105884552001953,
      "learning_rate": 0.00012840314136125655,
      "loss": 0.8551,
      "step": 10930
    },
    {
      "epoch": 57.27748691099477,
      "grad_norm": 0.12626799941062927,
      "learning_rate": 0.0001282460732984293,
      "loss": 0.8533,
      "step": 10940
    },
    {
      "epoch": 57.32984293193717,
      "grad_norm": 0.8614980578422546,
      "learning_rate": 0.00012808900523560209,
      "loss": 0.859,
      "step": 10950
    },
    {
      "epoch": 57.382198952879584,
      "grad_norm": 3.607011556625366,
      "learning_rate": 0.00012793193717277487,
      "loss": 0.8594,
      "step": 10960
    },
    {
      "epoch": 57.43455497382199,
      "grad_norm": 0.6197425723075867,
      "learning_rate": 0.00012777486910994762,
      "loss": 0.8578,
      "step": 10970
    },
    {
      "epoch": 57.4869109947644,
      "grad_norm": 0.46986469626426697,
      "learning_rate": 0.0001276178010471204,
      "loss": 0.8636,
      "step": 10980
    },
    {
      "epoch": 57.539267015706805,
      "grad_norm": 5.05900239944458,
      "learning_rate": 0.0001274607329842932,
      "loss": 0.8696,
      "step": 10990
    },
    {
      "epoch": 57.59162303664922,
      "grad_norm": 0.13452045619487762,
      "learning_rate": 0.00012730366492146597,
      "loss": 0.8533,
      "step": 11000
    },
    {
      "epoch": 57.64397905759162,
      "grad_norm": 0.8024154901504517,
      "learning_rate": 0.00012714659685863873,
      "loss": 0.8583,
      "step": 11010
    },
    {
      "epoch": 57.696335078534034,
      "grad_norm": 1.144829273223877,
      "learning_rate": 0.00012698952879581151,
      "loss": 0.859,
      "step": 11020
    },
    {
      "epoch": 57.74869109947644,
      "grad_norm": 0.8978264927864075,
      "learning_rate": 0.0001268324607329843,
      "loss": 0.8542,
      "step": 11030
    },
    {
      "epoch": 57.80104712041885,
      "grad_norm": 0.06634794920682907,
      "learning_rate": 0.00012667539267015705,
      "loss": 0.8579,
      "step": 11040
    },
    {
      "epoch": 57.853403141361255,
      "grad_norm": 1.9041640758514404,
      "learning_rate": 0.00012651832460732984,
      "loss": 0.8754,
      "step": 11050
    },
    {
      "epoch": 57.90575916230367,
      "grad_norm": 0.42354071140289307,
      "learning_rate": 0.00012636125654450262,
      "loss": 0.8585,
      "step": 11060
    },
    {
      "epoch": 57.95811518324607,
      "grad_norm": 2.873833179473877,
      "learning_rate": 0.00012620418848167538,
      "loss": 0.8537,
      "step": 11070
    },
    {
      "epoch": 58.0,
      "eval_accuracy": 0.44261119081779055,
      "eval_loss": 3.590886116027832,
      "eval_runtime": 0.9934,
      "eval_samples_per_second": 1403.317,
      "eval_steps_per_second": 22.147,
      "step": 11078
    },
    {
      "epoch": 58.010471204188484,
      "grad_norm": 0.06621896475553513,
      "learning_rate": 0.00012604712041884816,
      "loss": 0.8715,
      "step": 11080
    },
    {
      "epoch": 58.06282722513089,
      "grad_norm": 0.09078530967235565,
      "learning_rate": 0.00012589005235602094,
      "loss": 0.8601,
      "step": 11090
    },
    {
      "epoch": 58.1151832460733,
      "grad_norm": 0.06785142421722412,
      "learning_rate": 0.0001257329842931937,
      "loss": 0.8601,
      "step": 11100
    },
    {
      "epoch": 58.167539267015705,
      "grad_norm": 0.0470079705119133,
      "learning_rate": 0.00012557591623036648,
      "loss": 0.8535,
      "step": 11110
    },
    {
      "epoch": 58.21989528795812,
      "grad_norm": 0.12421062588691711,
      "learning_rate": 0.00012541884816753927,
      "loss": 0.8536,
      "step": 11120
    },
    {
      "epoch": 58.27225130890052,
      "grad_norm": 0.07938310503959656,
      "learning_rate": 0.00012526178010471202,
      "loss": 0.8583,
      "step": 11130
    },
    {
      "epoch": 58.324607329842934,
      "grad_norm": 0.03843826800584793,
      "learning_rate": 0.0001251047120418848,
      "loss": 0.8588,
      "step": 11140
    },
    {
      "epoch": 58.37696335078534,
      "grad_norm": 0.04996147379279137,
      "learning_rate": 0.0001249476439790576,
      "loss": 0.8552,
      "step": 11150
    },
    {
      "epoch": 58.42931937172775,
      "grad_norm": 8.045953750610352,
      "learning_rate": 0.00012479057591623034,
      "loss": 0.8603,
      "step": 11160
    },
    {
      "epoch": 58.481675392670155,
      "grad_norm": 0.15125352144241333,
      "learning_rate": 0.00012463350785340313,
      "loss": 0.8528,
      "step": 11170
    },
    {
      "epoch": 58.53403141361257,
      "grad_norm": 0.08116891980171204,
      "learning_rate": 0.0001244764397905759,
      "loss": 0.8625,
      "step": 11180
    },
    {
      "epoch": 58.58638743455497,
      "grad_norm": 0.699836254119873,
      "learning_rate": 0.00012431937172774867,
      "loss": 0.8645,
      "step": 11190
    },
    {
      "epoch": 58.638743455497384,
      "grad_norm": 0.23500944674015045,
      "learning_rate": 0.00012416230366492145,
      "loss": 0.8627,
      "step": 11200
    },
    {
      "epoch": 58.69109947643979,
      "grad_norm": 0.5128166675567627,
      "learning_rate": 0.00012400523560209423,
      "loss": 0.8597,
      "step": 11210
    },
    {
      "epoch": 58.7434554973822,
      "grad_norm": 0.09780822694301605,
      "learning_rate": 0.000123848167539267,
      "loss": 0.8615,
      "step": 11220
    },
    {
      "epoch": 58.795811518324605,
      "grad_norm": 0.1797299087047577,
      "learning_rate": 0.00012369109947643977,
      "loss": 0.8698,
      "step": 11230
    },
    {
      "epoch": 58.84816753926702,
      "grad_norm": 14.922776222229004,
      "learning_rate": 0.00012353403141361256,
      "loss": 0.8661,
      "step": 11240
    },
    {
      "epoch": 58.90052356020942,
      "grad_norm": 0.10524104535579681,
      "learning_rate": 0.0001233769633507853,
      "loss": 0.856,
      "step": 11250
    },
    {
      "epoch": 58.952879581151834,
      "grad_norm": 0.1612488180398941,
      "learning_rate": 0.0001232198952879581,
      "loss": 0.8535,
      "step": 11260
    },
    {
      "epoch": 59.0,
      "eval_accuracy": 0.4375896700143472,
      "eval_loss": 3.5863072872161865,
      "eval_runtime": 1.0321,
      "eval_samples_per_second": 1350.619,
      "eval_steps_per_second": 21.315,
      "step": 11269
    },
    {
      "epoch": 59.00523560209424,
      "grad_norm": 0.032152045518159866,
      "learning_rate": 0.00012306282722513088,
      "loss": 0.8604,
      "step": 11270
    },
    {
      "epoch": 59.05759162303665,
      "grad_norm": 0.06461010128259659,
      "learning_rate": 0.00012290575916230363,
      "loss": 0.8526,
      "step": 11280
    },
    {
      "epoch": 59.109947643979055,
      "grad_norm": 1.892662525177002,
      "learning_rate": 0.00012274869109947642,
      "loss": 0.8545,
      "step": 11290
    },
    {
      "epoch": 59.16230366492147,
      "grad_norm": 0.04209465906023979,
      "learning_rate": 0.0001225916230366492,
      "loss": 0.8555,
      "step": 11300
    },
    {
      "epoch": 59.21465968586387,
      "grad_norm": 0.09078776091337204,
      "learning_rate": 0.00012243455497382198,
      "loss": 0.8529,
      "step": 11310
    },
    {
      "epoch": 59.26701570680628,
      "grad_norm": 0.034237224608659744,
      "learning_rate": 0.00012227748691099474,
      "loss": 0.855,
      "step": 11320
    },
    {
      "epoch": 59.31937172774869,
      "grad_norm": 0.050121355801820755,
      "learning_rate": 0.00012212041884816752,
      "loss": 0.8544,
      "step": 11330
    },
    {
      "epoch": 59.3717277486911,
      "grad_norm": 0.08044767379760742,
      "learning_rate": 0.00012196335078534031,
      "loss": 0.8588,
      "step": 11340
    },
    {
      "epoch": 59.424083769633505,
      "grad_norm": 0.035557638853788376,
      "learning_rate": 0.00012180628272251308,
      "loss": 0.8591,
      "step": 11350
    },
    {
      "epoch": 59.47643979057592,
      "grad_norm": 0.04420771822333336,
      "learning_rate": 0.00012164921465968585,
      "loss": 0.8532,
      "step": 11360
    },
    {
      "epoch": 59.52879581151832,
      "grad_norm": 0.339417040348053,
      "learning_rate": 0.00012149214659685863,
      "loss": 0.8605,
      "step": 11370
    },
    {
      "epoch": 59.58115183246073,
      "grad_norm": 0.16161426901817322,
      "learning_rate": 0.00012133507853403141,
      "loss": 0.8566,
      "step": 11380
    },
    {
      "epoch": 59.63350785340314,
      "grad_norm": 1.0996543169021606,
      "learning_rate": 0.00012117801047120417,
      "loss": 0.8612,
      "step": 11390
    },
    {
      "epoch": 59.68586387434555,
      "grad_norm": 0.03012308105826378,
      "learning_rate": 0.00012102094240837695,
      "loss": 0.8556,
      "step": 11400
    },
    {
      "epoch": 59.738219895287955,
      "grad_norm": 0.07688236236572266,
      "learning_rate": 0.00012086387434554974,
      "loss": 0.8641,
      "step": 11410
    },
    {
      "epoch": 59.79057591623037,
      "grad_norm": 0.13390988111495972,
      "learning_rate": 0.00012070680628272249,
      "loss": 0.8615,
      "step": 11420
    },
    {
      "epoch": 59.84293193717277,
      "grad_norm": 0.05862124636769295,
      "learning_rate": 0.00012054973821989528,
      "loss": 0.8579,
      "step": 11430
    },
    {
      "epoch": 59.89528795811518,
      "grad_norm": 2.1277260780334473,
      "learning_rate": 0.00012039267015706806,
      "loss": 0.856,
      "step": 11440
    },
    {
      "epoch": 59.94764397905759,
      "grad_norm": 0.0516553670167923,
      "learning_rate": 0.00012023560209424083,
      "loss": 0.8561,
      "step": 11450
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.10766830295324326,
      "learning_rate": 0.0001200785340314136,
      "loss": 0.8563,
      "step": 11460
    },
    {
      "epoch": 60.0,
      "eval_accuracy": 0.41750358680057387,
      "eval_loss": 3.715684413909912,
      "eval_runtime": 1.0353,
      "eval_samples_per_second": 1346.523,
      "eval_steps_per_second": 21.251,
      "step": 11460
    },
    {
      "epoch": 60.05235602094241,
      "grad_norm": 6.445023536682129,
      "learning_rate": 0.00011992146596858638,
      "loss": 0.8595,
      "step": 11470
    },
    {
      "epoch": 60.10471204188482,
      "grad_norm": 0.09812888503074646,
      "learning_rate": 0.00011976439790575915,
      "loss": 0.8533,
      "step": 11480
    },
    {
      "epoch": 60.15706806282723,
      "grad_norm": 0.05808457359671593,
      "learning_rate": 0.00011960732984293192,
      "loss": 0.8549,
      "step": 11490
    },
    {
      "epoch": 60.20942408376963,
      "grad_norm": 0.6222182512283325,
      "learning_rate": 0.0001194502617801047,
      "loss": 0.8529,
      "step": 11500
    },
    {
      "epoch": 60.261780104712045,
      "grad_norm": 0.2221851497888565,
      "learning_rate": 0.00011929319371727747,
      "loss": 0.8531,
      "step": 11510
    },
    {
      "epoch": 60.31413612565445,
      "grad_norm": 0.053282346576452255,
      "learning_rate": 0.00011913612565445026,
      "loss": 0.853,
      "step": 11520
    },
    {
      "epoch": 60.36649214659686,
      "grad_norm": 0.2468239963054657,
      "learning_rate": 0.00011897905759162303,
      "loss": 0.8617,
      "step": 11530
    },
    {
      "epoch": 60.41884816753927,
      "grad_norm": 0.039288073778152466,
      "learning_rate": 0.0001188219895287958,
      "loss": 0.8532,
      "step": 11540
    },
    {
      "epoch": 60.47120418848168,
      "grad_norm": 0.05078555643558502,
      "learning_rate": 0.00011866492146596858,
      "loss": 0.8623,
      "step": 11550
    },
    {
      "epoch": 60.52356020942408,
      "grad_norm": 0.22970329225063324,
      "learning_rate": 0.00011850785340314135,
      "loss": 0.8611,
      "step": 11560
    },
    {
      "epoch": 60.575916230366495,
      "grad_norm": 0.03028678707778454,
      "learning_rate": 0.00011835078534031412,
      "loss": 0.8565,
      "step": 11570
    },
    {
      "epoch": 60.6282722513089,
      "grad_norm": 0.0812172144651413,
      "learning_rate": 0.0001181937172774869,
      "loss": 0.8564,
      "step": 11580
    },
    {
      "epoch": 60.68062827225131,
      "grad_norm": 0.056082628667354584,
      "learning_rate": 0.00011803664921465967,
      "loss": 0.8543,
      "step": 11590
    },
    {
      "epoch": 60.73298429319372,
      "grad_norm": 0.09063249081373215,
      "learning_rate": 0.00011787958115183244,
      "loss": 0.8604,
      "step": 11600
    },
    {
      "epoch": 60.78534031413613,
      "grad_norm": 0.05585988238453865,
      "learning_rate": 0.00011772251308900522,
      "loss": 0.8595,
      "step": 11610
    },
    {
      "epoch": 60.83769633507853,
      "grad_norm": 0.03652498498558998,
      "learning_rate": 0.00011756544502617801,
      "loss": 0.8537,
      "step": 11620
    },
    {
      "epoch": 60.890052356020945,
      "grad_norm": 0.07836898416280746,
      "learning_rate": 0.00011740837696335076,
      "loss": 0.8561,
      "step": 11630
    },
    {
      "epoch": 60.94240837696335,
      "grad_norm": 0.0309015903621912,
      "learning_rate": 0.00011725130890052355,
      "loss": 0.8597,
      "step": 11640
    },
    {
      "epoch": 60.99476439790576,
      "grad_norm": 0.118840292096138,
      "learning_rate": 0.00011709424083769633,
      "loss": 0.8603,
      "step": 11650
    },
    {
      "epoch": 61.0,
      "eval_accuracy": 0.42898134863701576,
      "eval_loss": 3.654731273651123,
      "eval_runtime": 0.9962,
      "eval_samples_per_second": 1399.332,
      "eval_steps_per_second": 22.084,
      "step": 11651
    },
    {
      "epoch": 61.047120418848166,
      "grad_norm": 8.285982131958008,
      "learning_rate": 0.00011693717277486909,
      "loss": 0.8589,
      "step": 11660
    },
    {
      "epoch": 61.09947643979058,
      "grad_norm": 1.2078473567962646,
      "learning_rate": 0.00011678010471204187,
      "loss": 0.8533,
      "step": 11670
    },
    {
      "epoch": 61.15183246073298,
      "grad_norm": 0.5436002016067505,
      "learning_rate": 0.00011662303664921465,
      "loss": 0.855,
      "step": 11680
    },
    {
      "epoch": 61.204188481675395,
      "grad_norm": 0.03807665780186653,
      "learning_rate": 0.00011646596858638744,
      "loss": 0.8541,
      "step": 11690
    },
    {
      "epoch": 61.2565445026178,
      "grad_norm": 0.04368271306157112,
      "learning_rate": 0.00011630890052356019,
      "loss": 0.8544,
      "step": 11700
    },
    {
      "epoch": 61.30890052356021,
      "grad_norm": 0.05087527260184288,
      "learning_rate": 0.00011615183246073298,
      "loss": 0.855,
      "step": 11710
    },
    {
      "epoch": 61.361256544502616,
      "grad_norm": 0.13062742352485657,
      "learning_rate": 0.00011599476439790576,
      "loss": 0.8548,
      "step": 11720
    },
    {
      "epoch": 61.41361256544503,
      "grad_norm": 0.758633017539978,
      "learning_rate": 0.00011583769633507852,
      "loss": 0.8526,
      "step": 11730
    },
    {
      "epoch": 61.46596858638743,
      "grad_norm": 0.040460314601659775,
      "learning_rate": 0.0001156806282722513,
      "loss": 0.8524,
      "step": 11740
    },
    {
      "epoch": 61.518324607329845,
      "grad_norm": 0.16830769181251526,
      "learning_rate": 0.00011552356020942408,
      "loss": 0.8523,
      "step": 11750
    },
    {
      "epoch": 61.57068062827225,
      "grad_norm": 0.03723596781492233,
      "learning_rate": 0.00011536649214659685,
      "loss": 0.8529,
      "step": 11760
    },
    {
      "epoch": 61.62303664921466,
      "grad_norm": 0.03989584371447563,
      "learning_rate": 0.00011520942408376962,
      "loss": 0.855,
      "step": 11770
    },
    {
      "epoch": 61.675392670157066,
      "grad_norm": 0.03515249863266945,
      "learning_rate": 0.0001150523560209424,
      "loss": 0.8554,
      "step": 11780
    },
    {
      "epoch": 61.72774869109948,
      "grad_norm": 0.043547373265028,
      "learning_rate": 0.00011489528795811517,
      "loss": 0.8527,
      "step": 11790
    },
    {
      "epoch": 61.78010471204188,
      "grad_norm": 0.045436371117830276,
      "learning_rate": 0.00011473821989528794,
      "loss": 0.8527,
      "step": 11800
    },
    {
      "epoch": 61.832460732984295,
      "grad_norm": 0.049096547067165375,
      "learning_rate": 0.00011458115183246073,
      "loss": 0.8576,
      "step": 11810
    },
    {
      "epoch": 61.8848167539267,
      "grad_norm": 0.132023423910141,
      "learning_rate": 0.0001144240837696335,
      "loss": 0.8526,
      "step": 11820
    },
    {
      "epoch": 61.93717277486911,
      "grad_norm": 0.046100202947854996,
      "learning_rate": 0.00011426701570680628,
      "loss": 0.8538,
      "step": 11830
    },
    {
      "epoch": 61.989528795811516,
      "grad_norm": 0.14619190990924835,
      "learning_rate": 0.00011410994764397905,
      "loss": 0.8633,
      "step": 11840
    },
    {
      "epoch": 62.0,
      "eval_accuracy": 0.4411764705882353,
      "eval_loss": 3.6725118160247803,
      "eval_runtime": 1.0203,
      "eval_samples_per_second": 1366.274,
      "eval_steps_per_second": 21.562,
      "step": 11842
    },
    {
      "epoch": 62.04188481675393,
      "grad_norm": 9.250431060791016,
      "learning_rate": 0.00011395287958115182,
      "loss": 0.8584,
      "step": 11850
    },
    {
      "epoch": 62.09424083769633,
      "grad_norm": 0.4586236774921417,
      "learning_rate": 0.0001137958115183246,
      "loss": 0.8551,
      "step": 11860
    },
    {
      "epoch": 62.146596858638745,
      "grad_norm": 0.059566255658864975,
      "learning_rate": 0.00011363874345549737,
      "loss": 0.855,
      "step": 11870
    },
    {
      "epoch": 62.19895287958115,
      "grad_norm": 0.9403448104858398,
      "learning_rate": 0.00011348167539267014,
      "loss": 0.856,
      "step": 11880
    },
    {
      "epoch": 62.25130890052356,
      "grad_norm": 0.6527080535888672,
      "learning_rate": 0.00011332460732984293,
      "loss": 0.8573,
      "step": 11890
    },
    {
      "epoch": 62.303664921465966,
      "grad_norm": 0.874464750289917,
      "learning_rate": 0.0001131675392670157,
      "loss": 0.8559,
      "step": 11900
    },
    {
      "epoch": 62.35602094240838,
      "grad_norm": 0.1923288106918335,
      "learning_rate": 0.00011301047120418846,
      "loss": 0.8638,
      "step": 11910
    },
    {
      "epoch": 62.40837696335078,
      "grad_norm": 0.10056781023740768,
      "learning_rate": 0.00011285340314136125,
      "loss": 0.854,
      "step": 11920
    },
    {
      "epoch": 62.460732984293195,
      "grad_norm": 0.06485103815793991,
      "learning_rate": 0.00011269633507853403,
      "loss": 0.8537,
      "step": 11930
    },
    {
      "epoch": 62.5130890052356,
      "grad_norm": 0.374063104391098,
      "learning_rate": 0.00011253926701570679,
      "loss": 0.8575,
      "step": 11940
    },
    {
      "epoch": 62.56544502617801,
      "grad_norm": 0.06189781799912453,
      "learning_rate": 0.00011238219895287957,
      "loss": 0.8542,
      "step": 11950
    },
    {
      "epoch": 62.617801047120416,
      "grad_norm": 7.292430877685547,
      "learning_rate": 0.00011222513089005235,
      "loss": 0.8568,
      "step": 11960
    },
    {
      "epoch": 62.67015706806283,
      "grad_norm": 0.1886478066444397,
      "learning_rate": 0.00011206806282722511,
      "loss": 0.8627,
      "step": 11970
    },
    {
      "epoch": 62.72251308900523,
      "grad_norm": 6.4109272956848145,
      "learning_rate": 0.0001119109947643979,
      "loss": 0.8577,
      "step": 11980
    },
    {
      "epoch": 62.774869109947645,
      "grad_norm": 0.0779518410563469,
      "learning_rate": 0.00011175392670157068,
      "loss": 0.8536,
      "step": 11990
    },
    {
      "epoch": 62.82722513089005,
      "grad_norm": 0.044379886239767075,
      "learning_rate": 0.00011161256544502617,
      "loss": 0.8581,
      "step": 12000
    },
    {
      "epoch": 62.87958115183246,
      "grad_norm": 0.050118397921323776,
      "learning_rate": 0.00011145549738219895,
      "loss": 0.8533,
      "step": 12010
    },
    {
      "epoch": 62.931937172774866,
      "grad_norm": 0.06690877676010132,
      "learning_rate": 0.00011129842931937171,
      "loss": 0.8538,
      "step": 12020
    },
    {
      "epoch": 62.98429319371728,
      "grad_norm": 0.6849760413169861,
      "learning_rate": 0.0001111413612565445,
      "loss": 0.8572,
      "step": 12030
    },
    {
      "epoch": 63.0,
      "eval_accuracy": 0.43615494978479197,
      "eval_loss": 3.6965527534484863,
      "eval_runtime": 1.0019,
      "eval_samples_per_second": 1391.402,
      "eval_steps_per_second": 21.959,
      "step": 12033
    },
    {
      "epoch": 63.03664921465968,
      "grad_norm": 0.4254612922668457,
      "learning_rate": 0.00011098429319371728,
      "loss": 0.8589,
      "step": 12040
    },
    {
      "epoch": 63.089005235602095,
      "grad_norm": 0.06449127942323685,
      "learning_rate": 0.00011082722513089003,
      "loss": 0.8528,
      "step": 12050
    },
    {
      "epoch": 63.1413612565445,
      "grad_norm": 0.10606836527585983,
      "learning_rate": 0.00011067015706806282,
      "loss": 0.8523,
      "step": 12060
    },
    {
      "epoch": 63.19371727748691,
      "grad_norm": 7.643337249755859,
      "learning_rate": 0.0001105130890052356,
      "loss": 0.8561,
      "step": 12070
    },
    {
      "epoch": 63.246073298429316,
      "grad_norm": 0.03877194598317146,
      "learning_rate": 0.00011035602094240837,
      "loss": 0.8549,
      "step": 12080
    },
    {
      "epoch": 63.29842931937173,
      "grad_norm": 0.04360108822584152,
      "learning_rate": 0.00011019895287958114,
      "loss": 0.8641,
      "step": 12090
    },
    {
      "epoch": 63.35078534031413,
      "grad_norm": 0.03645214065909386,
      "learning_rate": 0.00011004188481675392,
      "loss": 0.8584,
      "step": 12100
    },
    {
      "epoch": 63.403141361256544,
      "grad_norm": 0.35337093472480774,
      "learning_rate": 0.00010988481675392669,
      "loss": 0.8628,
      "step": 12110
    },
    {
      "epoch": 63.455497382198956,
      "grad_norm": 4.683455467224121,
      "learning_rate": 0.00010972774869109946,
      "loss": 0.8633,
      "step": 12120
    },
    {
      "epoch": 63.50785340314136,
      "grad_norm": 0.18827466666698456,
      "learning_rate": 0.00010957068062827224,
      "loss": 0.8573,
      "step": 12130
    },
    {
      "epoch": 63.56020942408377,
      "grad_norm": 2.727137565612793,
      "learning_rate": 0.00010941361256544501,
      "loss": 0.8635,
      "step": 12140
    },
    {
      "epoch": 63.61256544502618,
      "grad_norm": 10.695719718933105,
      "learning_rate": 0.0001092565445026178,
      "loss": 0.8647,
      "step": 12150
    },
    {
      "epoch": 63.66492146596859,
      "grad_norm": 0.6682590246200562,
      "learning_rate": 0.00010909947643979057,
      "loss": 0.868,
      "step": 12160
    },
    {
      "epoch": 63.717277486910994,
      "grad_norm": 0.27102863788604736,
      "learning_rate": 0.00010894240837696334,
      "loss": 0.8664,
      "step": 12170
    },
    {
      "epoch": 63.769633507853406,
      "grad_norm": 0.07521586120128632,
      "learning_rate": 0.00010878534031413612,
      "loss": 0.8694,
      "step": 12180
    },
    {
      "epoch": 63.82198952879581,
      "grad_norm": 0.08078539371490479,
      "learning_rate": 0.00010862827225130889,
      "loss": 0.8588,
      "step": 12190
    },
    {
      "epoch": 63.87434554973822,
      "grad_norm": 0.03988886624574661,
      "learning_rate": 0.00010847120418848166,
      "loss": 0.8606,
      "step": 12200
    },
    {
      "epoch": 63.92670157068063,
      "grad_norm": 1.5530225038528442,
      "learning_rate": 0.00010831413612565444,
      "loss": 0.8562,
      "step": 12210
    },
    {
      "epoch": 63.97905759162304,
      "grad_norm": 0.6790584921836853,
      "learning_rate": 0.00010815706806282723,
      "loss": 0.8817,
      "step": 12220
    },
    {
      "epoch": 64.0,
      "eval_accuracy": 0.430416068866571,
      "eval_loss": 3.6858067512512207,
      "eval_runtime": 1.0592,
      "eval_samples_per_second": 1316.12,
      "eval_steps_per_second": 20.771,
      "step": 12224
    },
    {
      "epoch": 64.03141361256544,
      "grad_norm": 0.12202795594930649,
      "learning_rate": 0.00010799999999999998,
      "loss": 0.8697,
      "step": 12230
    },
    {
      "epoch": 64.08376963350786,
      "grad_norm": 0.04727562889456749,
      "learning_rate": 0.00010784293193717277,
      "loss": 0.866,
      "step": 12240
    },
    {
      "epoch": 64.13612565445027,
      "grad_norm": 0.7272592186927795,
      "learning_rate": 0.00010768586387434555,
      "loss": 0.8672,
      "step": 12250
    },
    {
      "epoch": 64.18848167539267,
      "grad_norm": 0.4878327548503876,
      "learning_rate": 0.0001075287958115183,
      "loss": 0.8543,
      "step": 12260
    },
    {
      "epoch": 64.24083769633508,
      "grad_norm": 1.3700413703918457,
      "learning_rate": 0.00010737172774869109,
      "loss": 0.8671,
      "step": 12270
    },
    {
      "epoch": 64.29319371727749,
      "grad_norm": 1.140432357788086,
      "learning_rate": 0.00010721465968586387,
      "loss": 0.8562,
      "step": 12280
    },
    {
      "epoch": 64.3455497382199,
      "grad_norm": 3.9390220642089844,
      "learning_rate": 0.00010705759162303663,
      "loss": 0.8588,
      "step": 12290
    },
    {
      "epoch": 64.3979057591623,
      "grad_norm": 2.73073148727417,
      "learning_rate": 0.00010690052356020941,
      "loss": 0.8647,
      "step": 12300
    },
    {
      "epoch": 64.45026178010471,
      "grad_norm": 0.06461026519536972,
      "learning_rate": 0.0001067434554973822,
      "loss": 0.8692,
      "step": 12310
    },
    {
      "epoch": 64.50261780104712,
      "grad_norm": 0.9175108075141907,
      "learning_rate": 0.00010658638743455496,
      "loss": 0.8538,
      "step": 12320
    },
    {
      "epoch": 64.55497382198953,
      "grad_norm": 0.14907854795455933,
      "learning_rate": 0.00010642931937172773,
      "loss": 0.8546,
      "step": 12330
    },
    {
      "epoch": 64.60732984293193,
      "grad_norm": 0.34311699867248535,
      "learning_rate": 0.00010627225130890052,
      "loss": 0.8535,
      "step": 12340
    },
    {
      "epoch": 64.65968586387434,
      "grad_norm": 0.24290649592876434,
      "learning_rate": 0.00010611518324607329,
      "loss": 0.8566,
      "step": 12350
    },
    {
      "epoch": 64.71204188481676,
      "grad_norm": 3.773066520690918,
      "learning_rate": 0.00010595811518324606,
      "loss": 0.8634,
      "step": 12360
    },
    {
      "epoch": 64.76439790575917,
      "grad_norm": 2.7423954010009766,
      "learning_rate": 0.00010580104712041884,
      "loss": 0.8591,
      "step": 12370
    },
    {
      "epoch": 64.81675392670157,
      "grad_norm": 10.25271987915039,
      "learning_rate": 0.00010564397905759161,
      "loss": 0.8581,
      "step": 12380
    },
    {
      "epoch": 64.86910994764398,
      "grad_norm": 0.08097584545612335,
      "learning_rate": 0.00010548691099476439,
      "loss": 0.8587,
      "step": 12390
    },
    {
      "epoch": 64.92146596858639,
      "grad_norm": 1.0635676383972168,
      "learning_rate": 0.00010532984293193716,
      "loss": 0.8708,
      "step": 12400
    },
    {
      "epoch": 64.9738219895288,
      "grad_norm": 0.0673932433128357,
      "learning_rate": 0.00010517277486910993,
      "loss": 0.8558,
      "step": 12410
    },
    {
      "epoch": 65.0,
      "eval_accuracy": 0.42395982783357244,
      "eval_loss": 3.7119481563568115,
      "eval_runtime": 0.9644,
      "eval_samples_per_second": 1445.428,
      "eval_steps_per_second": 22.812,
      "step": 12415
    },
    {
      "epoch": 65.0261780104712,
      "grad_norm": 0.04472440481185913,
      "learning_rate": 0.00010501570680628272,
      "loss": 0.8591,
      "step": 12420
    },
    {
      "epoch": 65.07853403141361,
      "grad_norm": 6.231815338134766,
      "learning_rate": 0.00010485863874345548,
      "loss": 0.8571,
      "step": 12430
    },
    {
      "epoch": 65.13089005235602,
      "grad_norm": 0.1942661851644516,
      "learning_rate": 0.00010470157068062825,
      "loss": 0.8643,
      "step": 12440
    },
    {
      "epoch": 65.18324607329843,
      "grad_norm": 0.12020490318536758,
      "learning_rate": 0.00010454450261780104,
      "loss": 0.8537,
      "step": 12450
    },
    {
      "epoch": 65.23560209424083,
      "grad_norm": 0.053414180874824524,
      "learning_rate": 0.00010438743455497382,
      "loss": 0.8522,
      "step": 12460
    },
    {
      "epoch": 65.28795811518324,
      "grad_norm": 0.12065603584051132,
      "learning_rate": 0.00010423036649214658,
      "loss": 0.855,
      "step": 12470
    },
    {
      "epoch": 65.34031413612566,
      "grad_norm": 0.7522015571594238,
      "learning_rate": 0.00010407329842931936,
      "loss": 0.8545,
      "step": 12480
    },
    {
      "epoch": 65.39267015706807,
      "grad_norm": 0.09304848313331604,
      "learning_rate": 0.00010391623036649214,
      "loss": 0.8592,
      "step": 12490
    },
    {
      "epoch": 65.44502617801047,
      "grad_norm": 0.07749123126268387,
      "learning_rate": 0.0001037591623036649,
      "loss": 0.8526,
      "step": 12500
    },
    {
      "epoch": 65.49738219895288,
      "grad_norm": 3.7878148555755615,
      "learning_rate": 0.00010360209424083768,
      "loss": 0.8594,
      "step": 12510
    },
    {
      "epoch": 65.54973821989529,
      "grad_norm": 0.16169844567775726,
      "learning_rate": 0.00010344502617801047,
      "loss": 0.8607,
      "step": 12520
    },
    {
      "epoch": 65.6020942408377,
      "grad_norm": 10.925678253173828,
      "learning_rate": 0.00010328795811518325,
      "loss": 0.8608,
      "step": 12530
    },
    {
      "epoch": 65.6544502617801,
      "grad_norm": 0.03717183694243431,
      "learning_rate": 0.000103130890052356,
      "loss": 0.869,
      "step": 12540
    },
    {
      "epoch": 65.70680628272251,
      "grad_norm": 0.646449863910675,
      "learning_rate": 0.00010297382198952879,
      "loss": 0.8578,
      "step": 12550
    },
    {
      "epoch": 65.75916230366492,
      "grad_norm": 0.364662230014801,
      "learning_rate": 0.00010281675392670157,
      "loss": 0.8568,
      "step": 12560
    },
    {
      "epoch": 65.81151832460733,
      "grad_norm": 0.9566548466682434,
      "learning_rate": 0.00010265968586387433,
      "loss": 0.8693,
      "step": 12570
    },
    {
      "epoch": 65.86387434554973,
      "grad_norm": 0.03467347472906113,
      "learning_rate": 0.00010250261780104711,
      "loss": 0.8545,
      "step": 12580
    },
    {
      "epoch": 65.91623036649214,
      "grad_norm": 0.051876746118068695,
      "learning_rate": 0.0001023455497382199,
      "loss": 0.8592,
      "step": 12590
    },
    {
      "epoch": 65.96858638743456,
      "grad_norm": 0.05660998448729515,
      "learning_rate": 0.00010218848167539266,
      "loss": 0.8537,
      "step": 12600
    },
    {
      "epoch": 66.0,
      "eval_accuracy": 0.43902439024390244,
      "eval_loss": 3.66090726852417,
      "eval_runtime": 0.9956,
      "eval_samples_per_second": 1400.191,
      "eval_steps_per_second": 22.098,
      "step": 12606
    },
    {
      "epoch": 66.02094240837697,
      "grad_norm": 0.047412604093551636,
      "learning_rate": 0.00010204712041884817,
      "loss": 0.8628,
      "step": 12610
    },
    {
      "epoch": 66.07329842931937,
      "grad_norm": 0.12895122170448303,
      "learning_rate": 0.00010189005235602093,
      "loss": 0.8528,
      "step": 12620
    },
    {
      "epoch": 66.12565445026178,
      "grad_norm": 0.07975324243307114,
      "learning_rate": 0.00010173298429319371,
      "loss": 0.8529,
      "step": 12630
    },
    {
      "epoch": 66.17801047120419,
      "grad_norm": 1.9466607570648193,
      "learning_rate": 0.0001015759162303665,
      "loss": 0.8579,
      "step": 12640
    },
    {
      "epoch": 66.2303664921466,
      "grad_norm": 0.03315950930118561,
      "learning_rate": 0.00010141884816753925,
      "loss": 0.8544,
      "step": 12650
    },
    {
      "epoch": 66.282722513089,
      "grad_norm": 0.04901808500289917,
      "learning_rate": 0.00010126178010471203,
      "loss": 0.8521,
      "step": 12660
    },
    {
      "epoch": 66.33507853403141,
      "grad_norm": 0.03248600289225578,
      "learning_rate": 0.00010110471204188482,
      "loss": 0.8607,
      "step": 12670
    },
    {
      "epoch": 66.38743455497382,
      "grad_norm": 0.0289766825735569,
      "learning_rate": 0.00010094764397905759,
      "loss": 0.8539,
      "step": 12680
    },
    {
      "epoch": 66.43979057591623,
      "grad_norm": 0.22311733663082123,
      "learning_rate": 0.00010079057591623036,
      "loss": 0.8526,
      "step": 12690
    },
    {
      "epoch": 66.49214659685863,
      "grad_norm": 2.005253791809082,
      "learning_rate": 0.00010063350785340314,
      "loss": 0.8609,
      "step": 12700
    },
    {
      "epoch": 66.54450261780104,
      "grad_norm": 0.04659494012594223,
      "learning_rate": 0.00010047643979057591,
      "loss": 0.8568,
      "step": 12710
    },
    {
      "epoch": 66.59685863874346,
      "grad_norm": 0.19024497270584106,
      "learning_rate": 0.00010031937172774868,
      "loss": 0.8526,
      "step": 12720
    },
    {
      "epoch": 66.64921465968587,
      "grad_norm": 0.05323997884988785,
      "learning_rate": 0.00010016230366492145,
      "loss": 0.8564,
      "step": 12730
    },
    {
      "epoch": 66.70157068062827,
      "grad_norm": 0.08307238668203354,
      "learning_rate": 0.00010000523560209423,
      "loss": 0.8521,
      "step": 12740
    },
    {
      "epoch": 66.75392670157068,
      "grad_norm": 0.11251155287027359,
      "learning_rate": 9.9848167539267e-05,
      "loss": 0.8533,
      "step": 12750
    },
    {
      "epoch": 66.80628272251309,
      "grad_norm": 0.026391467079520226,
      "learning_rate": 9.969109947643977e-05,
      "loss": 0.8541,
      "step": 12760
    },
    {
      "epoch": 66.8586387434555,
      "grad_norm": 0.04168364778161049,
      "learning_rate": 9.953403141361256e-05,
      "loss": 0.8523,
      "step": 12770
    },
    {
      "epoch": 66.91099476439791,
      "grad_norm": 0.0238097682595253,
      "learning_rate": 9.937696335078534e-05,
      "loss": 0.8528,
      "step": 12780
    },
    {
      "epoch": 66.96335078534031,
      "grad_norm": 0.10967793315649033,
      "learning_rate": 9.92198952879581e-05,
      "loss": 0.856,
      "step": 12790
    },
    {
      "epoch": 67.0,
      "eval_accuracy": 0.43185078909612623,
      "eval_loss": 3.6355512142181396,
      "eval_runtime": 1.0189,
      "eval_samples_per_second": 1368.142,
      "eval_steps_per_second": 21.592,
      "step": 12797
    },
    {
      "epoch": 67.01570680628272,
      "grad_norm": 1.4822293519973755,
      "learning_rate": 9.906282722513088e-05,
      "loss": 0.8526,
      "step": 12800
    },
    {
      "epoch": 67.06806282722513,
      "grad_norm": 2.3407294750213623,
      "learning_rate": 9.890575916230366e-05,
      "loss": 0.8532,
      "step": 12810
    },
    {
      "epoch": 67.12041884816755,
      "grad_norm": 0.02438085712492466,
      "learning_rate": 9.874869109947642e-05,
      "loss": 0.8558,
      "step": 12820
    },
    {
      "epoch": 67.17277486910994,
      "grad_norm": 0.0575626976788044,
      "learning_rate": 9.85916230366492e-05,
      "loss": 0.8532,
      "step": 12830
    },
    {
      "epoch": 67.22513089005236,
      "grad_norm": 0.027987666428089142,
      "learning_rate": 9.843455497382198e-05,
      "loss": 0.8519,
      "step": 12840
    },
    {
      "epoch": 67.27748691099477,
      "grad_norm": 0.20440107583999634,
      "learning_rate": 9.827748691099477e-05,
      "loss": 0.852,
      "step": 12850
    },
    {
      "epoch": 67.32984293193718,
      "grad_norm": 0.3529309630393982,
      "learning_rate": 9.812041884816752e-05,
      "loss": 0.8542,
      "step": 12860
    },
    {
      "epoch": 67.38219895287958,
      "grad_norm": 0.20581288635730743,
      "learning_rate": 9.79633507853403e-05,
      "loss": 0.8523,
      "step": 12870
    },
    {
      "epoch": 67.43455497382199,
      "grad_norm": 0.05051723122596741,
      "learning_rate": 9.780628272251309e-05,
      "loss": 0.8569,
      "step": 12880
    },
    {
      "epoch": 67.4869109947644,
      "grad_norm": 0.08023973554372787,
      "learning_rate": 9.764921465968585e-05,
      "loss": 0.8572,
      "step": 12890
    },
    {
      "epoch": 67.53926701570681,
      "grad_norm": 0.025928962975740433,
      "learning_rate": 9.749214659685863e-05,
      "loss": 0.852,
      "step": 12900
    },
    {
      "epoch": 67.59162303664921,
      "grad_norm": 3.751373529434204,
      "learning_rate": 9.733507853403141e-05,
      "loss": 0.8528,
      "step": 12910
    },
    {
      "epoch": 67.64397905759162,
      "grad_norm": 0.03889743238687515,
      "learning_rate": 9.717801047120418e-05,
      "loss": 0.8519,
      "step": 12920
    },
    {
      "epoch": 67.69633507853403,
      "grad_norm": 0.030046427622437477,
      "learning_rate": 9.702094240837695e-05,
      "loss": 0.8526,
      "step": 12930
    },
    {
      "epoch": 67.74869109947645,
      "grad_norm": 0.04930196702480316,
      "learning_rate": 9.686387434554974e-05,
      "loss": 0.8518,
      "step": 12940
    },
    {
      "epoch": 67.80104712041884,
      "grad_norm": 0.06391464173793793,
      "learning_rate": 9.67068062827225e-05,
      "loss": 0.8546,
      "step": 12950
    },
    {
      "epoch": 67.85340314136126,
      "grad_norm": 0.0739329606294632,
      "learning_rate": 9.654973821989527e-05,
      "loss": 0.852,
      "step": 12960
    },
    {
      "epoch": 67.90575916230367,
      "grad_norm": 0.019396992400288582,
      "learning_rate": 9.639267015706806e-05,
      "loss": 0.8527,
      "step": 12970
    },
    {
      "epoch": 67.95811518324608,
      "grad_norm": 0.02305782213807106,
      "learning_rate": 9.623560209424083e-05,
      "loss": 0.852,
      "step": 12980
    },
    {
      "epoch": 68.0,
      "eval_accuracy": 0.44261119081779055,
      "eval_loss": 3.576646089553833,
      "eval_runtime": 1.0387,
      "eval_samples_per_second": 1342.093,
      "eval_steps_per_second": 21.181,
      "step": 12988
    },
    {
      "epoch": 68.01047120418848,
      "grad_norm": 2.3110392093658447,
      "learning_rate": 9.607853403141361e-05,
      "loss": 0.8534,
      "step": 12990
    },
    {
      "epoch": 68.06282722513089,
      "grad_norm": 0.028378119692206383,
      "learning_rate": 9.592146596858638e-05,
      "loss": 0.8522,
      "step": 13000
    },
    {
      "epoch": 68.1151832460733,
      "grad_norm": 0.05137932300567627,
      "learning_rate": 9.576439790575915e-05,
      "loss": 0.8517,
      "step": 13010
    },
    {
      "epoch": 68.16753926701571,
      "grad_norm": 0.02224888652563095,
      "learning_rate": 9.560732984293193e-05,
      "loss": 0.8517,
      "step": 13020
    },
    {
      "epoch": 68.21989528795811,
      "grad_norm": 2.252018451690674,
      "learning_rate": 9.54502617801047e-05,
      "loss": 0.8523,
      "step": 13030
    },
    {
      "epoch": 68.27225130890052,
      "grad_norm": 0.022137917578220367,
      "learning_rate": 9.529319371727747e-05,
      "loss": 0.8518,
      "step": 13040
    },
    {
      "epoch": 68.32460732984293,
      "grad_norm": 0.018674630671739578,
      "learning_rate": 9.513612565445026e-05,
      "loss": 0.8518,
      "step": 13050
    },
    {
      "epoch": 68.37696335078535,
      "grad_norm": 0.07029881328344345,
      "learning_rate": 9.497905759162303e-05,
      "loss": 0.8521,
      "step": 13060
    },
    {
      "epoch": 68.42931937172774,
      "grad_norm": 0.03780854493379593,
      "learning_rate": 9.48219895287958e-05,
      "loss": 0.8516,
      "step": 13070
    },
    {
      "epoch": 68.48167539267016,
      "grad_norm": 0.029115945100784302,
      "learning_rate": 9.466492146596858e-05,
      "loss": 0.8516,
      "step": 13080
    },
    {
      "epoch": 68.53403141361257,
      "grad_norm": 0.025584343820810318,
      "learning_rate": 9.450785340314136e-05,
      "loss": 0.8518,
      "step": 13090
    },
    {
      "epoch": 68.58638743455498,
      "grad_norm": 0.06520432233810425,
      "learning_rate": 9.435078534031412e-05,
      "loss": 0.8675,
      "step": 13100
    },
    {
      "epoch": 68.63874345549738,
      "grad_norm": 0.027511244639754295,
      "learning_rate": 9.41937172774869e-05,
      "loss": 0.8518,
      "step": 13110
    },
    {
      "epoch": 68.69109947643979,
      "grad_norm": 0.025096861645579338,
      "learning_rate": 9.403664921465968e-05,
      "loss": 0.8517,
      "step": 13120
    },
    {
      "epoch": 68.7434554973822,
      "grad_norm": 0.023952778428792953,
      "learning_rate": 9.387958115183244e-05,
      "loss": 0.852,
      "step": 13130
    },
    {
      "epoch": 68.79581151832461,
      "grad_norm": 0.02294984459877014,
      "learning_rate": 9.372251308900522e-05,
      "loss": 0.8516,
      "step": 13140
    },
    {
      "epoch": 68.84816753926701,
      "grad_norm": 0.03419656306505203,
      "learning_rate": 9.356544502617801e-05,
      "loss": 0.8517,
      "step": 13150
    },
    {
      "epoch": 68.90052356020942,
      "grad_norm": 0.021446142345666885,
      "learning_rate": 9.340837696335079e-05,
      "loss": 0.8516,
      "step": 13160
    },
    {
      "epoch": 68.95287958115183,
      "grad_norm": 0.025594264268875122,
      "learning_rate": 9.325130890052355e-05,
      "loss": 0.8515,
      "step": 13170
    },
    {
      "epoch": 69.0,
      "eval_accuracy": 0.45911047345767575,
      "eval_loss": 3.5547919273376465,
      "eval_runtime": 0.9087,
      "eval_samples_per_second": 1534.027,
      "eval_steps_per_second": 24.21,
      "step": 13179
    },
    {
      "epoch": 69.00523560209425,
      "grad_norm": 0.018739933148026466,
      "learning_rate": 9.309424083769633e-05,
      "loss": 0.8515,
      "step": 13180
    },
    {
      "epoch": 69.05759162303664,
      "grad_norm": 0.025351498275995255,
      "learning_rate": 9.29371727748691e-05,
      "loss": 0.8515,
      "step": 13190
    },
    {
      "epoch": 69.10994764397905,
      "grad_norm": 0.028803233057260513,
      "learning_rate": 9.278010471204187e-05,
      "loss": 0.8514,
      "step": 13200
    },
    {
      "epoch": 69.16230366492147,
      "grad_norm": 0.020756350830197334,
      "learning_rate": 9.262303664921465e-05,
      "loss": 0.8515,
      "step": 13210
    },
    {
      "epoch": 69.21465968586388,
      "grad_norm": 0.01845880225300789,
      "learning_rate": 9.246596858638742e-05,
      "loss": 0.8514,
      "step": 13220
    },
    {
      "epoch": 69.26701570680628,
      "grad_norm": 0.018754933029413223,
      "learning_rate": 9.23089005235602e-05,
      "loss": 0.8514,
      "step": 13230
    },
    {
      "epoch": 69.31937172774869,
      "grad_norm": 0.017094379290938377,
      "learning_rate": 9.215183246073298e-05,
      "loss": 0.8514,
      "step": 13240
    },
    {
      "epoch": 69.3717277486911,
      "grad_norm": 0.13016174733638763,
      "learning_rate": 9.199476439790575e-05,
      "loss": 0.8514,
      "step": 13250
    },
    {
      "epoch": 69.42408376963351,
      "grad_norm": 0.02235768362879753,
      "learning_rate": 9.183769633507853e-05,
      "loss": 0.8514,
      "step": 13260
    },
    {
      "epoch": 69.47643979057591,
      "grad_norm": 0.022781645879149437,
      "learning_rate": 9.16806282722513e-05,
      "loss": 0.8514,
      "step": 13270
    },
    {
      "epoch": 69.52879581151832,
      "grad_norm": 0.02008846029639244,
      "learning_rate": 9.152356020942407e-05,
      "loss": 0.8514,
      "step": 13280
    },
    {
      "epoch": 69.58115183246073,
      "grad_norm": 0.015631550922989845,
      "learning_rate": 9.136649214659685e-05,
      "loss": 0.8514,
      "step": 13290
    },
    {
      "epoch": 69.63350785340315,
      "grad_norm": 0.015516422688961029,
      "learning_rate": 9.120942408376963e-05,
      "loss": 0.8513,
      "step": 13300
    },
    {
      "epoch": 69.68586387434554,
      "grad_norm": 0.01644844561815262,
      "learning_rate": 9.105235602094239e-05,
      "loss": 0.8514,
      "step": 13310
    },
    {
      "epoch": 69.73821989528795,
      "grad_norm": 0.018362876027822495,
      "learning_rate": 9.089528795811517e-05,
      "loss": 0.8513,
      "step": 13320
    },
    {
      "epoch": 69.79057591623037,
      "grad_norm": 0.018962495028972626,
      "learning_rate": 9.073821989528796e-05,
      "loss": 0.8513,
      "step": 13330
    },
    {
      "epoch": 69.84293193717278,
      "grad_norm": 0.020285693928599358,
      "learning_rate": 9.058115183246071e-05,
      "loss": 0.8514,
      "step": 13340
    },
    {
      "epoch": 69.89528795811518,
      "grad_norm": 0.018267393112182617,
      "learning_rate": 9.04240837696335e-05,
      "loss": 0.8513,
      "step": 13350
    },
    {
      "epoch": 69.94764397905759,
      "grad_norm": 0.01780022867023945,
      "learning_rate": 9.026701570680628e-05,
      "loss": 0.8513,
      "step": 13360
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.032302748411893845,
      "learning_rate": 9.010994764397906e-05,
      "loss": 0.8514,
      "step": 13370
    },
    {
      "epoch": 70.0,
      "eval_accuracy": 0.4598278335724534,
      "eval_loss": 3.556889772415161,
      "eval_runtime": 1.0587,
      "eval_samples_per_second": 1316.763,
      "eval_steps_per_second": 20.781,
      "step": 13370
    },
    {
      "epoch": 70.05235602094241,
      "grad_norm": 0.01620650477707386,
      "learning_rate": 8.995287958115182e-05,
      "loss": 0.8513,
      "step": 13380
    },
    {
      "epoch": 70.10471204188482,
      "grad_norm": 0.018928121775388718,
      "learning_rate": 8.97958115183246e-05,
      "loss": 0.8513,
      "step": 13390
    },
    {
      "epoch": 70.15706806282722,
      "grad_norm": 0.013476104475557804,
      "learning_rate": 8.963874345549739e-05,
      "loss": 0.8513,
      "step": 13400
    },
    {
      "epoch": 70.20942408376963,
      "grad_norm": 0.01563802734017372,
      "learning_rate": 8.948167539267014e-05,
      "loss": 0.8512,
      "step": 13410
    },
    {
      "epoch": 70.26178010471205,
      "grad_norm": 0.016704723238945007,
      "learning_rate": 8.932460732984292e-05,
      "loss": 0.8513,
      "step": 13420
    },
    {
      "epoch": 70.31413612565446,
      "grad_norm": 0.019956689327955246,
      "learning_rate": 8.916753926701571e-05,
      "loss": 0.8513,
      "step": 13430
    },
    {
      "epoch": 70.36649214659685,
      "grad_norm": 0.012965028174221516,
      "learning_rate": 8.901047120418846e-05,
      "loss": 0.8513,
      "step": 13440
    },
    {
      "epoch": 70.41884816753927,
      "grad_norm": 0.018419642001390457,
      "learning_rate": 8.885340314136125e-05,
      "loss": 0.8513,
      "step": 13450
    },
    {
      "epoch": 70.47120418848168,
      "grad_norm": 0.017821183428168297,
      "learning_rate": 8.869633507853403e-05,
      "loss": 0.8513,
      "step": 13460
    },
    {
      "epoch": 70.52356020942409,
      "grad_norm": 0.017506984993815422,
      "learning_rate": 8.85392670157068e-05,
      "loss": 0.8513,
      "step": 13470
    },
    {
      "epoch": 70.57591623036649,
      "grad_norm": 0.017494114115834236,
      "learning_rate": 8.838219895287957e-05,
      "loss": 0.8513,
      "step": 13480
    },
    {
      "epoch": 70.6282722513089,
      "grad_norm": 0.01642010174691677,
      "learning_rate": 8.822513089005235e-05,
      "loss": 0.8512,
      "step": 13490
    },
    {
      "epoch": 70.68062827225131,
      "grad_norm": 0.014199630357325077,
      "learning_rate": 8.806806282722512e-05,
      "loss": 0.8513,
      "step": 13500
    },
    {
      "epoch": 70.73298429319372,
      "grad_norm": 0.018490348011255264,
      "learning_rate": 8.791099476439789e-05,
      "loss": 0.8513,
      "step": 13510
    },
    {
      "epoch": 70.78534031413612,
      "grad_norm": 0.015012930147349834,
      "learning_rate": 8.775392670157068e-05,
      "loss": 0.8513,
      "step": 13520
    },
    {
      "epoch": 70.83769633507853,
      "grad_norm": 0.017245100811123848,
      "learning_rate": 8.759685863874345e-05,
      "loss": 0.8513,
      "step": 13530
    },
    {
      "epoch": 70.89005235602095,
      "grad_norm": 0.015426010824739933,
      "learning_rate": 8.743979057591623e-05,
      "loss": 0.8512,
      "step": 13540
    },
    {
      "epoch": 70.94240837696336,
      "grad_norm": 0.012910932302474976,
      "learning_rate": 8.7282722513089e-05,
      "loss": 0.8512,
      "step": 13550
    },
    {
      "epoch": 70.99476439790575,
      "grad_norm": 0.017818322405219078,
      "learning_rate": 8.712565445026177e-05,
      "loss": 0.8513,
      "step": 13560
    },
    {
      "epoch": 71.0,
      "eval_accuracy": 0.45911047345767575,
      "eval_loss": 3.565180540084839,
      "eval_runtime": 1.0134,
      "eval_samples_per_second": 1375.518,
      "eval_steps_per_second": 21.708,
      "step": 13561
    },
    {
      "epoch": 71.04712041884817,
      "grad_norm": 0.016746142879128456,
      "learning_rate": 8.696858638743455e-05,
      "loss": 0.8512,
      "step": 13570
    },
    {
      "epoch": 71.09947643979058,
      "grad_norm": 0.019058886915445328,
      "learning_rate": 8.681151832460732e-05,
      "loss": 0.8512,
      "step": 13580
    },
    {
      "epoch": 71.15183246073299,
      "grad_norm": 0.014830187894403934,
      "learning_rate": 8.665445026178009e-05,
      "loss": 0.8512,
      "step": 13590
    },
    {
      "epoch": 71.20418848167539,
      "grad_norm": 0.013429232873022556,
      "learning_rate": 8.649738219895287e-05,
      "loss": 0.8512,
      "step": 13600
    },
    {
      "epoch": 71.2565445026178,
      "grad_norm": 0.017079174518585205,
      "learning_rate": 8.634031413612566e-05,
      "loss": 0.8512,
      "step": 13610
    },
    {
      "epoch": 71.30890052356021,
      "grad_norm": 0.014274350367486477,
      "learning_rate": 8.618324607329841e-05,
      "loss": 0.8512,
      "step": 13620
    },
    {
      "epoch": 71.36125654450262,
      "grad_norm": 0.014927365817129612,
      "learning_rate": 8.60261780104712e-05,
      "loss": 0.8512,
      "step": 13630
    },
    {
      "epoch": 71.41361256544502,
      "grad_norm": 0.01335584931075573,
      "learning_rate": 8.586910994764398e-05,
      "loss": 0.8512,
      "step": 13640
    },
    {
      "epoch": 71.46596858638743,
      "grad_norm": 0.016830096021294594,
      "learning_rate": 8.571204188481674e-05,
      "loss": 0.8512,
      "step": 13650
    },
    {
      "epoch": 71.51832460732984,
      "grad_norm": 0.013080935925245285,
      "learning_rate": 8.555497382198952e-05,
      "loss": 0.8512,
      "step": 13660
    },
    {
      "epoch": 71.57068062827226,
      "grad_norm": 0.01296236366033554,
      "learning_rate": 8.53979057591623e-05,
      "loss": 0.8512,
      "step": 13670
    },
    {
      "epoch": 71.62303664921465,
      "grad_norm": 0.011494960635900497,
      "learning_rate": 8.524083769633507e-05,
      "loss": 0.8512,
      "step": 13680
    },
    {
      "epoch": 71.67539267015707,
      "grad_norm": 0.01367010548710823,
      "learning_rate": 8.508376963350784e-05,
      "loss": 0.8512,
      "step": 13690
    },
    {
      "epoch": 71.72774869109948,
      "grad_norm": 0.013801131397485733,
      "learning_rate": 8.492670157068063e-05,
      "loss": 0.8512,
      "step": 13700
    },
    {
      "epoch": 71.78010471204189,
      "grad_norm": 0.01395508088171482,
      "learning_rate": 8.47696335078534e-05,
      "loss": 0.8512,
      "step": 13710
    },
    {
      "epoch": 71.83246073298429,
      "grad_norm": 0.016517508774995804,
      "learning_rate": 8.461256544502617e-05,
      "loss": 0.8512,
      "step": 13720
    },
    {
      "epoch": 71.8848167539267,
      "grad_norm": 0.016571301966905594,
      "learning_rate": 8.445549738219895e-05,
      "loss": 0.8512,
      "step": 13730
    },
    {
      "epoch": 71.93717277486911,
      "grad_norm": 0.013943403959274292,
      "learning_rate": 8.429842931937172e-05,
      "loss": 0.8512,
      "step": 13740
    },
    {
      "epoch": 71.98952879581152,
      "grad_norm": 0.01659887284040451,
      "learning_rate": 8.414136125654449e-05,
      "loss": 0.8512,
      "step": 13750
    },
    {
      "epoch": 72.0,
      "eval_accuracy": 0.4569583931133429,
      "eval_loss": 3.572014093399048,
      "eval_runtime": 1.053,
      "eval_samples_per_second": 1323.826,
      "eval_steps_per_second": 20.893,
      "step": 13752
    },
    {
      "epoch": 72.04188481675392,
      "grad_norm": 0.015545112080872059,
      "learning_rate": 8.398429319371727e-05,
      "loss": 0.8512,
      "step": 13760
    },
    {
      "epoch": 72.09424083769633,
      "grad_norm": 0.013224204070866108,
      "learning_rate": 8.382722513089004e-05,
      "loss": 0.8512,
      "step": 13770
    },
    {
      "epoch": 72.14659685863874,
      "grad_norm": 0.014231724664568901,
      "learning_rate": 8.367015706806282e-05,
      "loss": 0.8512,
      "step": 13780
    },
    {
      "epoch": 72.19895287958116,
      "grad_norm": 0.016676975414156914,
      "learning_rate": 8.35130890052356e-05,
      "loss": 0.8512,
      "step": 13790
    },
    {
      "epoch": 72.25130890052355,
      "grad_norm": 0.014846104197204113,
      "learning_rate": 8.335602094240836e-05,
      "loss": 0.8511,
      "step": 13800
    },
    {
      "epoch": 72.30366492146597,
      "grad_norm": 0.014532998204231262,
      "learning_rate": 8.319895287958115e-05,
      "loss": 0.8512,
      "step": 13810
    },
    {
      "epoch": 72.35602094240838,
      "grad_norm": 0.012803548946976662,
      "learning_rate": 8.304188481675392e-05,
      "loss": 0.8512,
      "step": 13820
    },
    {
      "epoch": 72.40837696335079,
      "grad_norm": 0.01585419662296772,
      "learning_rate": 8.288481675392669e-05,
      "loss": 0.8511,
      "step": 13830
    },
    {
      "epoch": 72.46073298429319,
      "grad_norm": 0.013089405372738838,
      "learning_rate": 8.272774869109947e-05,
      "loss": 0.8512,
      "step": 13840
    },
    {
      "epoch": 72.5130890052356,
      "grad_norm": 0.013568549416959286,
      "learning_rate": 8.257068062827225e-05,
      "loss": 0.8512,
      "step": 13850
    },
    {
      "epoch": 72.56544502617801,
      "grad_norm": 0.014746377244591713,
      "learning_rate": 8.241361256544501e-05,
      "loss": 0.8512,
      "step": 13860
    },
    {
      "epoch": 72.61780104712042,
      "grad_norm": 0.015109941363334656,
      "learning_rate": 8.225654450261779e-05,
      "loss": 0.8512,
      "step": 13870
    },
    {
      "epoch": 72.67015706806282,
      "grad_norm": 0.015885792672634125,
      "learning_rate": 8.209947643979058e-05,
      "loss": 0.8512,
      "step": 13880
    },
    {
      "epoch": 72.72251308900523,
      "grad_norm": 0.015331776812672615,
      "learning_rate": 8.194240837696333e-05,
      "loss": 0.8512,
      "step": 13890
    },
    {
      "epoch": 72.77486910994764,
      "grad_norm": 0.013707216829061508,
      "learning_rate": 8.178534031413611e-05,
      "loss": 0.8511,
      "step": 13900
    },
    {
      "epoch": 72.82722513089006,
      "grad_norm": 0.013059052638709545,
      "learning_rate": 8.16282722513089e-05,
      "loss": 0.8512,
      "step": 13910
    },
    {
      "epoch": 72.87958115183245,
      "grad_norm": 0.013850187882781029,
      "learning_rate": 8.147120418848168e-05,
      "loss": 0.8511,
      "step": 13920
    },
    {
      "epoch": 72.93193717277487,
      "grad_norm": 0.011951166205108166,
      "learning_rate": 8.131413612565444e-05,
      "loss": 0.8511,
      "step": 13930
    },
    {
      "epoch": 72.98429319371728,
      "grad_norm": 0.013990828767418861,
      "learning_rate": 8.115706806282722e-05,
      "loss": 0.8511,
      "step": 13940
    },
    {
      "epoch": 73.0,
      "eval_accuracy": 0.4598278335724534,
      "eval_loss": 3.5779240131378174,
      "eval_runtime": 0.9994,
      "eval_samples_per_second": 1394.785,
      "eval_steps_per_second": 22.012,
      "step": 13943
    },
    {
      "epoch": 73.03664921465969,
      "grad_norm": 0.01320304162800312,
      "learning_rate": 8.1e-05,
      "loss": 0.8511,
      "step": 13950
    },
    {
      "epoch": 73.08900523560209,
      "grad_norm": 0.01391649805009365,
      "learning_rate": 8.084293193717276e-05,
      "loss": 0.8511,
      "step": 13960
    },
    {
      "epoch": 73.1413612565445,
      "grad_norm": 0.013243057765066624,
      "learning_rate": 8.068586387434554e-05,
      "loss": 0.8511,
      "step": 13970
    },
    {
      "epoch": 73.19371727748691,
      "grad_norm": 0.016516320407390594,
      "learning_rate": 8.052879581151833e-05,
      "loss": 0.8511,
      "step": 13980
    },
    {
      "epoch": 73.24607329842932,
      "grad_norm": 0.013512445613741875,
      "learning_rate": 8.03717277486911e-05,
      "loss": 0.8511,
      "step": 13990
    },
    {
      "epoch": 73.29842931937172,
      "grad_norm": 0.013974045403301716,
      "learning_rate": 8.021465968586387e-05,
      "loss": 0.8511,
      "step": 14000
    },
    {
      "epoch": 73.35078534031413,
      "grad_norm": 0.012282592244446278,
      "learning_rate": 8.005759162303665e-05,
      "loss": 0.8511,
      "step": 14010
    },
    {
      "epoch": 73.40314136125654,
      "grad_norm": 0.010854977183043957,
      "learning_rate": 7.990052356020942e-05,
      "loss": 0.8511,
      "step": 14020
    },
    {
      "epoch": 73.45549738219896,
      "grad_norm": 0.01192545797675848,
      "learning_rate": 7.974345549738219e-05,
      "loss": 0.8511,
      "step": 14030
    },
    {
      "epoch": 73.50785340314137,
      "grad_norm": 0.01425178349018097,
      "learning_rate": 7.958638743455497e-05,
      "loss": 0.8511,
      "step": 14040
    },
    {
      "epoch": 73.56020942408377,
      "grad_norm": 0.013895942829549313,
      "learning_rate": 7.942931937172774e-05,
      "loss": 0.8511,
      "step": 14050
    },
    {
      "epoch": 73.61256544502618,
      "grad_norm": 0.011933126486837864,
      "learning_rate": 7.927225130890051e-05,
      "loss": 0.8511,
      "step": 14060
    },
    {
      "epoch": 73.66492146596859,
      "grad_norm": 0.010808366350829601,
      "learning_rate": 7.91151832460733e-05,
      "loss": 0.8511,
      "step": 14070
    },
    {
      "epoch": 73.717277486911,
      "grad_norm": 0.014675181359052658,
      "learning_rate": 7.895811518324606e-05,
      "loss": 0.8511,
      "step": 14080
    },
    {
      "epoch": 73.7696335078534,
      "grad_norm": 0.012234733439981937,
      "learning_rate": 7.880104712041885e-05,
      "loss": 0.8511,
      "step": 14090
    },
    {
      "epoch": 73.82198952879581,
      "grad_norm": 0.0106603829190135,
      "learning_rate": 7.864397905759162e-05,
      "loss": 0.8511,
      "step": 14100
    },
    {
      "epoch": 73.87434554973822,
      "grad_norm": 0.012903020717203617,
      "learning_rate": 7.848691099476439e-05,
      "loss": 0.8511,
      "step": 14110
    },
    {
      "epoch": 73.92670157068063,
      "grad_norm": 0.012738503515720367,
      "learning_rate": 7.832984293193717e-05,
      "loss": 0.8511,
      "step": 14120
    },
    {
      "epoch": 73.97905759162303,
      "grad_norm": 0.012848972342908382,
      "learning_rate": 7.817277486910994e-05,
      "loss": 0.8511,
      "step": 14130
    },
    {
      "epoch": 74.0,
      "eval_accuracy": 0.4619799139167862,
      "eval_loss": 3.584571123123169,
      "eval_runtime": 1.0169,
      "eval_samples_per_second": 1370.8,
      "eval_steps_per_second": 21.634,
      "step": 14134
    },
    {
      "epoch": 74.03141361256544,
      "grad_norm": 0.013749298639595509,
      "learning_rate": 7.801570680628271e-05,
      "loss": 0.8511,
      "step": 14140
    },
    {
      "epoch": 74.08376963350786,
      "grad_norm": 0.011448226869106293,
      "learning_rate": 7.785863874345549e-05,
      "loss": 0.8511,
      "step": 14150
    },
    {
      "epoch": 74.13612565445027,
      "grad_norm": 0.01139139011502266,
      "learning_rate": 7.770157068062828e-05,
      "loss": 0.8511,
      "step": 14160
    },
    {
      "epoch": 74.18848167539267,
      "grad_norm": 0.013903677463531494,
      "learning_rate": 7.754450261780103e-05,
      "loss": 0.8511,
      "step": 14170
    },
    {
      "epoch": 74.24083769633508,
      "grad_norm": 0.012564007192850113,
      "learning_rate": 7.738743455497382e-05,
      "loss": 0.8511,
      "step": 14180
    },
    {
      "epoch": 74.29319371727749,
      "grad_norm": 0.012336176820099354,
      "learning_rate": 7.72303664921466e-05,
      "loss": 0.8511,
      "step": 14190
    },
    {
      "epoch": 74.3455497382199,
      "grad_norm": 0.013166949152946472,
      "learning_rate": 7.707329842931935e-05,
      "loss": 0.8511,
      "step": 14200
    },
    {
      "epoch": 74.3979057591623,
      "grad_norm": 0.010983520187437534,
      "learning_rate": 7.691623036649214e-05,
      "loss": 0.8511,
      "step": 14210
    },
    {
      "epoch": 74.45026178010471,
      "grad_norm": 0.011589637026190758,
      "learning_rate": 7.675916230366492e-05,
      "loss": 0.8511,
      "step": 14220
    },
    {
      "epoch": 74.50261780104712,
      "grad_norm": 0.009746745228767395,
      "learning_rate": 7.660209424083769e-05,
      "loss": 0.8511,
      "step": 14230
    },
    {
      "epoch": 74.55497382198953,
      "grad_norm": 0.012347699142992496,
      "learning_rate": 7.644502617801046e-05,
      "loss": 0.8511,
      "step": 14240
    },
    {
      "epoch": 74.60732984293193,
      "grad_norm": 0.011190335266292095,
      "learning_rate": 7.628795811518324e-05,
      "loss": 0.8511,
      "step": 14250
    },
    {
      "epoch": 74.65968586387434,
      "grad_norm": 0.016087109223008156,
      "learning_rate": 7.613089005235601e-05,
      "loss": 0.8511,
      "step": 14260
    },
    {
      "epoch": 74.71204188481676,
      "grad_norm": 0.012949693016707897,
      "learning_rate": 7.597382198952878e-05,
      "loss": 0.8511,
      "step": 14270
    },
    {
      "epoch": 74.76439790575917,
      "grad_norm": 0.010892125777900219,
      "learning_rate": 7.581675392670157e-05,
      "loss": 0.8511,
      "step": 14280
    },
    {
      "epoch": 74.81675392670157,
      "grad_norm": 0.015406284481287003,
      "learning_rate": 7.565968586387434e-05,
      "loss": 0.8511,
      "step": 14290
    },
    {
      "epoch": 74.86910994764398,
      "grad_norm": 0.014125111512839794,
      "learning_rate": 7.550261780104712e-05,
      "loss": 0.8511,
      "step": 14300
    },
    {
      "epoch": 74.92146596858639,
      "grad_norm": 0.013197923079133034,
      "learning_rate": 7.534554973821989e-05,
      "loss": 0.8511,
      "step": 14310
    },
    {
      "epoch": 74.9738219895288,
      "grad_norm": 0.011875232681632042,
      "learning_rate": 7.518848167539266e-05,
      "loss": 0.8511,
      "step": 14320
    },
    {
      "epoch": 75.0,
      "eval_accuracy": 0.46413199426111906,
      "eval_loss": 3.5911054611206055,
      "eval_runtime": 1.0539,
      "eval_samples_per_second": 1322.709,
      "eval_steps_per_second": 20.875,
      "step": 14325
    },
    {
      "epoch": 75.0261780104712,
      "grad_norm": 0.015241631306707859,
      "learning_rate": 7.503141361256544e-05,
      "loss": 0.8511,
      "step": 14330
    },
    {
      "epoch": 75.07853403141361,
      "grad_norm": 0.011082377284765244,
      "learning_rate": 7.487434554973821e-05,
      "loss": 0.8511,
      "step": 14340
    },
    {
      "epoch": 75.13089005235602,
      "grad_norm": 0.011268851347267628,
      "learning_rate": 7.471727748691098e-05,
      "loss": 0.8511,
      "step": 14350
    },
    {
      "epoch": 75.18324607329843,
      "grad_norm": 0.011252078227698803,
      "learning_rate": 7.456020942408376e-05,
      "loss": 0.8511,
      "step": 14360
    },
    {
      "epoch": 75.23560209424083,
      "grad_norm": 0.011863538064062595,
      "learning_rate": 7.440314136125653e-05,
      "loss": 0.8511,
      "step": 14370
    },
    {
      "epoch": 75.28795811518324,
      "grad_norm": 0.01182403601706028,
      "learning_rate": 7.42460732984293e-05,
      "loss": 0.8511,
      "step": 14380
    },
    {
      "epoch": 75.34031413612566,
      "grad_norm": 0.014046133495867252,
      "learning_rate": 7.408900523560209e-05,
      "loss": 0.8511,
      "step": 14390
    },
    {
      "epoch": 75.39267015706807,
      "grad_norm": 0.009002594277262688,
      "learning_rate": 7.393193717277486e-05,
      "loss": 0.8511,
      "step": 14400
    },
    {
      "epoch": 75.44502617801047,
      "grad_norm": 0.012548955157399178,
      "learning_rate": 7.377486910994764e-05,
      "loss": 0.8511,
      "step": 14410
    },
    {
      "epoch": 75.49738219895288,
      "grad_norm": 0.011147260665893555,
      "learning_rate": 7.361780104712041e-05,
      "loss": 0.851,
      "step": 14420
    },
    {
      "epoch": 75.54973821989529,
      "grad_norm": 0.01049572043120861,
      "learning_rate": 7.34607329842932e-05,
      "loss": 0.8511,
      "step": 14430
    },
    {
      "epoch": 75.6020942408377,
      "grad_norm": 0.010927511379122734,
      "learning_rate": 7.330366492146596e-05,
      "loss": 0.8511,
      "step": 14440
    },
    {
      "epoch": 75.6544502617801,
      "grad_norm": 0.01100368145853281,
      "learning_rate": 7.314659685863873e-05,
      "loss": 0.8511,
      "step": 14450
    },
    {
      "epoch": 75.70680628272251,
      "grad_norm": 0.010961612686514854,
      "learning_rate": 7.298952879581152e-05,
      "loss": 0.8511,
      "step": 14460
    },
    {
      "epoch": 75.75916230366492,
      "grad_norm": 0.011681115254759789,
      "learning_rate": 7.283246073298429e-05,
      "loss": 0.8511,
      "step": 14470
    },
    {
      "epoch": 75.81151832460733,
      "grad_norm": 0.010511325672268867,
      "learning_rate": 7.267539267015707e-05,
      "loss": 0.8511,
      "step": 14480
    },
    {
      "epoch": 75.86387434554973,
      "grad_norm": 0.012024003081023693,
      "learning_rate": 7.251832460732984e-05,
      "loss": 0.8511,
      "step": 14490
    },
    {
      "epoch": 75.91623036649214,
      "grad_norm": 0.012819916941225529,
      "learning_rate": 7.236125654450261e-05,
      "loss": 0.8511,
      "step": 14500
    },
    {
      "epoch": 75.96858638743456,
      "grad_norm": 0.0108539629727602,
      "learning_rate": 7.220418848167539e-05,
      "loss": 0.8511,
      "step": 14510
    },
    {
      "epoch": 76.0,
      "eval_accuracy": 0.46413199426111906,
      "eval_loss": 3.595860719680786,
      "eval_runtime": 1.079,
      "eval_samples_per_second": 1291.962,
      "eval_steps_per_second": 20.39,
      "step": 14516
    },
    {
      "epoch": 76.02094240837697,
      "grad_norm": 0.011528218165040016,
      "learning_rate": 7.204712041884816e-05,
      "loss": 0.851,
      "step": 14520
    },
    {
      "epoch": 76.07329842931937,
      "grad_norm": 0.011671051383018494,
      "learning_rate": 7.189005235602094e-05,
      "loss": 0.851,
      "step": 14530
    },
    {
      "epoch": 76.12565445026178,
      "grad_norm": 0.009906157851219177,
      "learning_rate": 7.173298429319371e-05,
      "loss": 0.8511,
      "step": 14540
    },
    {
      "epoch": 76.17801047120419,
      "grad_norm": 0.011816363781690598,
      "learning_rate": 7.157591623036648e-05,
      "loss": 0.851,
      "step": 14550
    },
    {
      "epoch": 76.2303664921466,
      "grad_norm": 0.01192804891616106,
      "learning_rate": 7.141884816753927e-05,
      "loss": 0.8511,
      "step": 14560
    },
    {
      "epoch": 76.282722513089,
      "grad_norm": 0.012472940608859062,
      "learning_rate": 7.126178010471204e-05,
      "loss": 0.851,
      "step": 14570
    },
    {
      "epoch": 76.33507853403141,
      "grad_norm": 0.01183233316987753,
      "learning_rate": 7.11047120418848e-05,
      "loss": 0.851,
      "step": 14580
    },
    {
      "epoch": 76.38743455497382,
      "grad_norm": 0.010488783940672874,
      "learning_rate": 7.094764397905759e-05,
      "loss": 0.8511,
      "step": 14590
    },
    {
      "epoch": 76.43979057591623,
      "grad_norm": 0.012729301117360592,
      "learning_rate": 7.079057591623036e-05,
      "loss": 0.851,
      "step": 14600
    },
    {
      "epoch": 76.49214659685863,
      "grad_norm": 0.010107479058206081,
      "learning_rate": 7.063350785340313e-05,
      "loss": 0.851,
      "step": 14610
    },
    {
      "epoch": 76.54450261780104,
      "grad_norm": 0.012882987968623638,
      "learning_rate": 7.047643979057591e-05,
      "loss": 0.851,
      "step": 14620
    },
    {
      "epoch": 76.59685863874346,
      "grad_norm": 0.012755119241774082,
      "learning_rate": 7.031937172774868e-05,
      "loss": 0.851,
      "step": 14630
    },
    {
      "epoch": 76.64921465968587,
      "grad_norm": 0.011149427853524685,
      "learning_rate": 7.016230366492145e-05,
      "loss": 0.851,
      "step": 14640
    },
    {
      "epoch": 76.70157068062827,
      "grad_norm": 0.009672975167632103,
      "learning_rate": 7.000523560209424e-05,
      "loss": 0.851,
      "step": 14650
    },
    {
      "epoch": 76.75392670157068,
      "grad_norm": 0.011251898482441902,
      "learning_rate": 6.9848167539267e-05,
      "loss": 0.851,
      "step": 14660
    },
    {
      "epoch": 76.80628272251309,
      "grad_norm": 0.01097185630351305,
      "learning_rate": 6.969109947643979e-05,
      "loss": 0.851,
      "step": 14670
    },
    {
      "epoch": 76.8586387434555,
      "grad_norm": 0.012164203450083733,
      "learning_rate": 6.953403141361256e-05,
      "loss": 0.851,
      "step": 14680
    },
    {
      "epoch": 76.91099476439791,
      "grad_norm": 0.010217010974884033,
      "learning_rate": 6.937696335078533e-05,
      "loss": 0.851,
      "step": 14690
    },
    {
      "epoch": 76.96335078534031,
      "grad_norm": 0.012426168657839298,
      "learning_rate": 6.921989528795811e-05,
      "loss": 0.851,
      "step": 14700
    },
    {
      "epoch": 77.0,
      "eval_accuracy": 0.4634146341463415,
      "eval_loss": 3.60318922996521,
      "eval_runtime": 1.2,
      "eval_samples_per_second": 1161.707,
      "eval_steps_per_second": 18.334,
      "step": 14707
    },
    {
      "epoch": 77.01570680628272,
      "grad_norm": 0.009370417334139347,
      "learning_rate": 6.906282722513088e-05,
      "loss": 0.851,
      "step": 14710
    },
    {
      "epoch": 77.06806282722513,
      "grad_norm": 0.009179703891277313,
      "learning_rate": 6.890575916230366e-05,
      "loss": 0.851,
      "step": 14720
    },
    {
      "epoch": 77.12041884816755,
      "grad_norm": 0.010126386769115925,
      "learning_rate": 6.874869109947643e-05,
      "loss": 0.851,
      "step": 14730
    },
    {
      "epoch": 77.17277486910994,
      "grad_norm": 0.011227237991988659,
      "learning_rate": 6.859162303664922e-05,
      "loss": 0.851,
      "step": 14740
    },
    {
      "epoch": 77.22513089005236,
      "grad_norm": 0.01020947378128767,
      "learning_rate": 6.843455497382199e-05,
      "loss": 0.851,
      "step": 14750
    },
    {
      "epoch": 77.27748691099477,
      "grad_norm": 0.011383047327399254,
      "learning_rate": 6.827748691099476e-05,
      "loss": 0.851,
      "step": 14760
    },
    {
      "epoch": 77.32984293193718,
      "grad_norm": 0.009211466647684574,
      "learning_rate": 6.812041884816754e-05,
      "loss": 0.851,
      "step": 14770
    },
    {
      "epoch": 77.38219895287958,
      "grad_norm": 0.01289448793977499,
      "learning_rate": 6.796335078534031e-05,
      "loss": 0.851,
      "step": 14780
    },
    {
      "epoch": 77.43455497382199,
      "grad_norm": 0.01271723210811615,
      "learning_rate": 6.780628272251309e-05,
      "loss": 0.851,
      "step": 14790
    },
    {
      "epoch": 77.4869109947644,
      "grad_norm": 0.008805450052022934,
      "learning_rate": 6.764921465968586e-05,
      "loss": 0.851,
      "step": 14800
    },
    {
      "epoch": 77.53926701570681,
      "grad_norm": 0.01034980732947588,
      "learning_rate": 6.749214659685863e-05,
      "loss": 0.851,
      "step": 14810
    },
    {
      "epoch": 77.59162303664921,
      "grad_norm": 0.010476886294782162,
      "learning_rate": 6.733507853403142e-05,
      "loss": 0.851,
      "step": 14820
    },
    {
      "epoch": 77.64397905759162,
      "grad_norm": 0.011771447956562042,
      "learning_rate": 6.717801047120418e-05,
      "loss": 0.851,
      "step": 14830
    },
    {
      "epoch": 77.69633507853403,
      "grad_norm": 0.010691724717617035,
      "learning_rate": 6.702094240837695e-05,
      "loss": 0.851,
      "step": 14840
    },
    {
      "epoch": 77.74869109947645,
      "grad_norm": 0.009378324262797832,
      "learning_rate": 6.686387434554974e-05,
      "loss": 0.851,
      "step": 14850
    },
    {
      "epoch": 77.80104712041884,
      "grad_norm": 0.011984349228441715,
      "learning_rate": 6.670680628272251e-05,
      "loss": 0.851,
      "step": 14860
    },
    {
      "epoch": 77.85340314136126,
      "grad_norm": 0.009934197179973125,
      "learning_rate": 6.654973821989528e-05,
      "loss": 0.851,
      "step": 14870
    },
    {
      "epoch": 77.90575916230367,
      "grad_norm": 0.01425508875399828,
      "learning_rate": 6.639267015706805e-05,
      "loss": 0.851,
      "step": 14880
    },
    {
      "epoch": 77.95811518324608,
      "grad_norm": 0.011638151481747627,
      "learning_rate": 6.623560209424083e-05,
      "loss": 0.851,
      "step": 14890
    },
    {
      "epoch": 78.0,
      "eval_accuracy": 0.4648493543758967,
      "eval_loss": 3.6085567474365234,
      "eval_runtime": 1.0125,
      "eval_samples_per_second": 1376.799,
      "eval_steps_per_second": 21.729,
      "step": 14898
    },
    {
      "epoch": 78.01047120418848,
      "grad_norm": 0.0099817318841815,
      "learning_rate": 6.60785340314136e-05,
      "loss": 0.851,
      "step": 14900
    },
    {
      "epoch": 78.06282722513089,
      "grad_norm": 0.010148772038519382,
      "learning_rate": 6.592146596858638e-05,
      "loss": 0.851,
      "step": 14910
    },
    {
      "epoch": 78.1151832460733,
      "grad_norm": 0.009652931243181229,
      "learning_rate": 6.576439790575915e-05,
      "loss": 0.851,
      "step": 14920
    },
    {
      "epoch": 78.16753926701571,
      "grad_norm": 0.01095978356897831,
      "learning_rate": 6.560732984293194e-05,
      "loss": 0.851,
      "step": 14930
    },
    {
      "epoch": 78.21989528795811,
      "grad_norm": 0.008950102142989635,
      "learning_rate": 6.54502617801047e-05,
      "loss": 0.851,
      "step": 14940
    },
    {
      "epoch": 78.27225130890052,
      "grad_norm": 0.013269886374473572,
      "learning_rate": 6.529319371727748e-05,
      "loss": 0.851,
      "step": 14950
    },
    {
      "epoch": 78.32460732984293,
      "grad_norm": 0.011719582602381706,
      "learning_rate": 6.513612565445026e-05,
      "loss": 0.851,
      "step": 14960
    },
    {
      "epoch": 78.37696335078535,
      "grad_norm": 0.012041260488331318,
      "learning_rate": 6.497905759162303e-05,
      "loss": 0.851,
      "step": 14970
    },
    {
      "epoch": 78.42931937172774,
      "grad_norm": 0.009820651262998581,
      "learning_rate": 6.482198952879581e-05,
      "loss": 0.851,
      "step": 14980
    },
    {
      "epoch": 78.48167539267016,
      "grad_norm": 0.01330525241792202,
      "learning_rate": 6.466492146596858e-05,
      "loss": 0.851,
      "step": 14990
    },
    {
      "epoch": 78.53403141361257,
      "grad_norm": 0.013589468784630299,
      "learning_rate": 6.450785340314135e-05,
      "loss": 0.851,
      "step": 15000
    },
    {
      "epoch": 78.58638743455498,
      "grad_norm": 0.009411575272679329,
      "learning_rate": 6.435078534031413e-05,
      "loss": 0.851,
      "step": 15010
    },
    {
      "epoch": 78.63874345549738,
      "grad_norm": 0.009513292461633682,
      "learning_rate": 6.41937172774869e-05,
      "loss": 0.851,
      "step": 15020
    },
    {
      "epoch": 78.69109947643979,
      "grad_norm": 0.01056153979152441,
      "learning_rate": 6.403664921465969e-05,
      "loss": 0.851,
      "step": 15030
    },
    {
      "epoch": 78.7434554973822,
      "grad_norm": 0.012179894372820854,
      "learning_rate": 6.387958115183246e-05,
      "loss": 0.851,
      "step": 15040
    },
    {
      "epoch": 78.79581151832461,
      "grad_norm": 0.010695581324398518,
      "learning_rate": 6.372251308900524e-05,
      "loss": 0.851,
      "step": 15050
    },
    {
      "epoch": 78.84816753926701,
      "grad_norm": 0.011298157274723053,
      "learning_rate": 6.356544502617801e-05,
      "loss": 0.851,
      "step": 15060
    },
    {
      "epoch": 78.90052356020942,
      "grad_norm": 0.011508245021104813,
      "learning_rate": 6.340837696335078e-05,
      "loss": 0.851,
      "step": 15070
    },
    {
      "epoch": 78.95287958115183,
      "grad_norm": 0.0115427291020751,
      "learning_rate": 6.325130890052356e-05,
      "loss": 0.851,
      "step": 15080
    },
    {
      "epoch": 79.0,
      "eval_accuracy": 0.46628407460545196,
      "eval_loss": 3.6146421432495117,
      "eval_runtime": 1.0373,
      "eval_samples_per_second": 1343.924,
      "eval_steps_per_second": 21.21,
      "step": 15089
    },
    {
      "epoch": 79.00523560209425,
      "grad_norm": 0.010034590028226376,
      "learning_rate": 6.309424083769633e-05,
      "loss": 0.851,
      "step": 15090
    },
    {
      "epoch": 79.05759162303664,
      "grad_norm": 0.010136506520211697,
      "learning_rate": 6.29371727748691e-05,
      "loss": 0.851,
      "step": 15100
    },
    {
      "epoch": 79.10994764397905,
      "grad_norm": 0.008496398106217384,
      "learning_rate": 6.278010471204187e-05,
      "loss": 0.851,
      "step": 15110
    },
    {
      "epoch": 79.16230366492147,
      "grad_norm": 0.011071759276092052,
      "learning_rate": 6.262303664921466e-05,
      "loss": 0.851,
      "step": 15120
    },
    {
      "epoch": 79.21465968586388,
      "grad_norm": 0.008977324701845646,
      "learning_rate": 6.246596858638743e-05,
      "loss": 0.851,
      "step": 15130
    },
    {
      "epoch": 79.26701570680628,
      "grad_norm": 0.011103748343884945,
      "learning_rate": 6.23089005235602e-05,
      "loss": 0.851,
      "step": 15140
    },
    {
      "epoch": 79.31937172774869,
      "grad_norm": 0.009905239567160606,
      "learning_rate": 6.215183246073298e-05,
      "loss": 0.851,
      "step": 15150
    },
    {
      "epoch": 79.3717277486911,
      "grad_norm": 0.008586677722632885,
      "learning_rate": 6.199476439790575e-05,
      "loss": 0.851,
      "step": 15160
    },
    {
      "epoch": 79.42408376963351,
      "grad_norm": 0.008443945087492466,
      "learning_rate": 6.183769633507853e-05,
      "loss": 0.851,
      "step": 15170
    },
    {
      "epoch": 79.47643979057591,
      "grad_norm": 0.010335847735404968,
      "learning_rate": 6.16806282722513e-05,
      "loss": 0.851,
      "step": 15180
    },
    {
      "epoch": 79.52879581151832,
      "grad_norm": 0.010593262501060963,
      "learning_rate": 6.152356020942407e-05,
      "loss": 0.851,
      "step": 15190
    },
    {
      "epoch": 79.58115183246073,
      "grad_norm": 0.008553274907171726,
      "learning_rate": 6.136649214659685e-05,
      "loss": 0.851,
      "step": 15200
    },
    {
      "epoch": 79.63350785340315,
      "grad_norm": 0.008827419020235538,
      "learning_rate": 6.120942408376962e-05,
      "loss": 0.851,
      "step": 15210
    },
    {
      "epoch": 79.68586387434554,
      "grad_norm": 0.007818195968866348,
      "learning_rate": 6.10523560209424e-05,
      "loss": 0.851,
      "step": 15220
    },
    {
      "epoch": 79.73821989528795,
      "grad_norm": 0.007687586825340986,
      "learning_rate": 6.0895287958115176e-05,
      "loss": 0.851,
      "step": 15230
    },
    {
      "epoch": 79.79057591623037,
      "grad_norm": 0.008487232960760593,
      "learning_rate": 6.073821989528796e-05,
      "loss": 0.851,
      "step": 15240
    },
    {
      "epoch": 79.84293193717278,
      "grad_norm": 0.009901910088956356,
      "learning_rate": 6.058115183246073e-05,
      "loss": 0.851,
      "step": 15250
    },
    {
      "epoch": 79.89528795811518,
      "grad_norm": 0.009980499744415283,
      "learning_rate": 6.04240837696335e-05,
      "loss": 0.851,
      "step": 15260
    },
    {
      "epoch": 79.94764397905759,
      "grad_norm": 0.010411050170660019,
      "learning_rate": 6.026701570680628e-05,
      "loss": 0.851,
      "step": 15270
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.01743343099951744,
      "learning_rate": 6.010994764397905e-05,
      "loss": 0.851,
      "step": 15280
    },
    {
      "epoch": 80.0,
      "eval_accuracy": 0.46771879483500717,
      "eval_loss": 3.619805097579956,
      "eval_runtime": 1.0178,
      "eval_samples_per_second": 1369.564,
      "eval_steps_per_second": 21.614,
      "step": 15280
    },
    {
      "epoch": 80.05235602094241,
      "grad_norm": 0.010610450059175491,
      "learning_rate": 5.995287958115183e-05,
      "loss": 0.851,
      "step": 15290
    },
    {
      "epoch": 80.10471204188482,
      "grad_norm": 0.009631930850446224,
      "learning_rate": 5.9795811518324605e-05,
      "loss": 0.851,
      "step": 15300
    },
    {
      "epoch": 80.15706806282722,
      "grad_norm": 0.011081568896770477,
      "learning_rate": 5.9638743455497375e-05,
      "loss": 0.8509,
      "step": 15310
    },
    {
      "epoch": 80.20942408376963,
      "grad_norm": 0.010098688304424286,
      "learning_rate": 5.948167539267015e-05,
      "loss": 0.851,
      "step": 15320
    },
    {
      "epoch": 80.26178010471205,
      "grad_norm": 0.009363340213894844,
      "learning_rate": 5.932460732984293e-05,
      "loss": 0.851,
      "step": 15330
    },
    {
      "epoch": 80.31413612565446,
      "grad_norm": 0.010642683133482933,
      "learning_rate": 5.9167539267015704e-05,
      "loss": 0.851,
      "step": 15340
    },
    {
      "epoch": 80.36649214659685,
      "grad_norm": 0.00984969362616539,
      "learning_rate": 5.9010471204188474e-05,
      "loss": 0.851,
      "step": 15350
    },
    {
      "epoch": 80.41884816753927,
      "grad_norm": 0.00874259788542986,
      "learning_rate": 5.885340314136126e-05,
      "loss": 0.851,
      "step": 15360
    },
    {
      "epoch": 80.47120418848168,
      "grad_norm": 0.009379012510180473,
      "learning_rate": 5.869633507853403e-05,
      "loss": 0.851,
      "step": 15370
    },
    {
      "epoch": 80.52356020942409,
      "grad_norm": 0.009036068804562092,
      "learning_rate": 5.8539267015706796e-05,
      "loss": 0.851,
      "step": 15380
    },
    {
      "epoch": 80.57591623036649,
      "grad_norm": 0.007960066199302673,
      "learning_rate": 5.838219895287958e-05,
      "loss": 0.851,
      "step": 15390
    },
    {
      "epoch": 80.6282722513089,
      "grad_norm": 0.008304019458591938,
      "learning_rate": 5.822513089005235e-05,
      "loss": 0.851,
      "step": 15400
    },
    {
      "epoch": 80.68062827225131,
      "grad_norm": 0.010843934491276741,
      "learning_rate": 5.8068062827225126e-05,
      "loss": 0.851,
      "step": 15410
    },
    {
      "epoch": 80.73298429319372,
      "grad_norm": 0.010481364093720913,
      "learning_rate": 5.79109947643979e-05,
      "loss": 0.851,
      "step": 15420
    },
    {
      "epoch": 80.78534031413612,
      "grad_norm": 0.008492895402014256,
      "learning_rate": 5.775392670157068e-05,
      "loss": 0.851,
      "step": 15430
    },
    {
      "epoch": 80.83769633507853,
      "grad_norm": 0.009933434426784515,
      "learning_rate": 5.759685863874345e-05,
      "loss": 0.851,
      "step": 15440
    },
    {
      "epoch": 80.89005235602095,
      "grad_norm": 0.008148271590471268,
      "learning_rate": 5.7439790575916225e-05,
      "loss": 0.851,
      "step": 15450
    },
    {
      "epoch": 80.94240837696336,
      "grad_norm": 0.009129811078310013,
      "learning_rate": 5.7282722513089e-05,
      "loss": 0.851,
      "step": 15460
    },
    {
      "epoch": 80.99476439790575,
      "grad_norm": 0.009909168817102909,
      "learning_rate": 5.712565445026177e-05,
      "loss": 0.851,
      "step": 15470
    },
    {
      "epoch": 81.0,
      "eval_accuracy": 0.46700143472022954,
      "eval_loss": 3.6251308917999268,
      "eval_runtime": 1.0122,
      "eval_samples_per_second": 1377.162,
      "eval_steps_per_second": 21.734,
      "step": 15471
    },
    {
      "epoch": 81.04712041884817,
      "grad_norm": 0.008712463080883026,
      "learning_rate": 5.6968586387434554e-05,
      "loss": 0.8509,
      "step": 15480
    },
    {
      "epoch": 81.09947643979058,
      "grad_norm": 0.01017142366617918,
      "learning_rate": 5.6811518324607324e-05,
      "loss": 0.851,
      "step": 15490
    },
    {
      "epoch": 81.15183246073299,
      "grad_norm": 0.009935769252479076,
      "learning_rate": 5.6654450261780094e-05,
      "loss": 0.851,
      "step": 15500
    },
    {
      "epoch": 81.20418848167539,
      "grad_norm": 0.011152751743793488,
      "learning_rate": 5.649738219895288e-05,
      "loss": 0.851,
      "step": 15510
    },
    {
      "epoch": 81.2565445026178,
      "grad_norm": 0.007856244221329689,
      "learning_rate": 5.634031413612565e-05,
      "loss": 0.851,
      "step": 15520
    },
    {
      "epoch": 81.30890052356021,
      "grad_norm": 0.009341771714389324,
      "learning_rate": 5.618324607329843e-05,
      "loss": 0.8509,
      "step": 15530
    },
    {
      "epoch": 81.36125654450262,
      "grad_norm": 0.011561622843146324,
      "learning_rate": 5.60261780104712e-05,
      "loss": 0.851,
      "step": 15540
    },
    {
      "epoch": 81.41361256544502,
      "grad_norm": 0.010743217542767525,
      "learning_rate": 5.5869109947643976e-05,
      "loss": 0.851,
      "step": 15550
    },
    {
      "epoch": 81.46596858638743,
      "grad_norm": 0.009443920105695724,
      "learning_rate": 5.571204188481675e-05,
      "loss": 0.8509,
      "step": 15560
    },
    {
      "epoch": 81.51832460732984,
      "grad_norm": 0.00895976647734642,
      "learning_rate": 5.555497382198952e-05,
      "loss": 0.851,
      "step": 15570
    },
    {
      "epoch": 81.57068062827226,
      "grad_norm": 0.009249051101505756,
      "learning_rate": 5.53979057591623e-05,
      "loss": 0.8509,
      "step": 15580
    },
    {
      "epoch": 81.62303664921465,
      "grad_norm": 0.010180425830185413,
      "learning_rate": 5.524083769633507e-05,
      "loss": 0.8509,
      "step": 15590
    },
    {
      "epoch": 81.67539267015707,
      "grad_norm": 0.007943565957248211,
      "learning_rate": 5.508376963350785e-05,
      "loss": 0.8509,
      "step": 15600
    },
    {
      "epoch": 81.72774869109948,
      "grad_norm": 0.009930484928190708,
      "learning_rate": 5.492670157068062e-05,
      "loss": 0.8509,
      "step": 15610
    },
    {
      "epoch": 81.78010471204189,
      "grad_norm": 0.009288021363317966,
      "learning_rate": 5.476963350785339e-05,
      "loss": 0.8509,
      "step": 15620
    },
    {
      "epoch": 81.83246073298429,
      "grad_norm": 0.008707284927368164,
      "learning_rate": 5.4612565445026174e-05,
      "loss": 0.8509,
      "step": 15630
    },
    {
      "epoch": 81.8848167539267,
      "grad_norm": 0.008152641355991364,
      "learning_rate": 5.4455497382198944e-05,
      "loss": 0.8509,
      "step": 15640
    },
    {
      "epoch": 81.93717277486911,
      "grad_norm": 0.007355253677815199,
      "learning_rate": 5.429842931937173e-05,
      "loss": 0.8509,
      "step": 15650
    },
    {
      "epoch": 81.98952879581152,
      "grad_norm": 0.007337122689932585,
      "learning_rate": 5.41413612565445e-05,
      "loss": 0.8509,
      "step": 15660
    },
    {
      "epoch": 82.0,
      "eval_accuracy": 0.46700143472022954,
      "eval_loss": 3.629927396774292,
      "eval_runtime": 1.014,
      "eval_samples_per_second": 1374.812,
      "eval_steps_per_second": 21.697,
      "step": 15662
    },
    {
      "epoch": 82.04188481675392,
      "grad_norm": 0.012149687856435776,
      "learning_rate": 5.3984293193717274e-05,
      "loss": 0.8509,
      "step": 15670
    },
    {
      "epoch": 82.09424083769633,
      "grad_norm": 0.007841162383556366,
      "learning_rate": 5.382722513089005e-05,
      "loss": 0.8509,
      "step": 15680
    },
    {
      "epoch": 82.14659685863874,
      "grad_norm": 0.009549915790557861,
      "learning_rate": 5.367015706806282e-05,
      "loss": 0.8509,
      "step": 15690
    },
    {
      "epoch": 82.19895287958116,
      "grad_norm": 0.00817093811929226,
      "learning_rate": 5.3513089005235596e-05,
      "loss": 0.8509,
      "step": 15700
    },
    {
      "epoch": 82.25130890052355,
      "grad_norm": 0.008446753956377506,
      "learning_rate": 5.335602094240837e-05,
      "loss": 0.8509,
      "step": 15710
    },
    {
      "epoch": 82.30366492146597,
      "grad_norm": 0.008171619847416878,
      "learning_rate": 5.319895287958115e-05,
      "loss": 0.8509,
      "step": 15720
    },
    {
      "epoch": 82.35602094240838,
      "grad_norm": 0.010187876410782337,
      "learning_rate": 5.304188481675392e-05,
      "loss": 0.8509,
      "step": 15730
    },
    {
      "epoch": 82.40837696335079,
      "grad_norm": 0.008183425292372704,
      "learning_rate": 5.28848167539267e-05,
      "loss": 0.8509,
      "step": 15740
    },
    {
      "epoch": 82.46073298429319,
      "grad_norm": 0.008128792978823185,
      "learning_rate": 5.272774869109947e-05,
      "loss": 0.8509,
      "step": 15750
    },
    {
      "epoch": 82.5130890052356,
      "grad_norm": 0.010419202037155628,
      "learning_rate": 5.257068062827224e-05,
      "loss": 0.8509,
      "step": 15760
    },
    {
      "epoch": 82.56544502617801,
      "grad_norm": 0.008870151825249195,
      "learning_rate": 5.2413612565445025e-05,
      "loss": 0.8509,
      "step": 15770
    },
    {
      "epoch": 82.61780104712042,
      "grad_norm": 0.009503578767180443,
      "learning_rate": 5.2256544502617795e-05,
      "loss": 0.8509,
      "step": 15780
    },
    {
      "epoch": 82.67015706806282,
      "grad_norm": 0.008729732595384121,
      "learning_rate": 5.209947643979058e-05,
      "loss": 0.8509,
      "step": 15790
    },
    {
      "epoch": 82.72251308900523,
      "grad_norm": 0.008659247308969498,
      "learning_rate": 5.194240837696335e-05,
      "loss": 0.8509,
      "step": 15800
    },
    {
      "epoch": 82.77486910994764,
      "grad_norm": 0.007651492953300476,
      "learning_rate": 5.178534031413612e-05,
      "loss": 0.8509,
      "step": 15810
    },
    {
      "epoch": 82.82722513089006,
      "grad_norm": 0.00970851443707943,
      "learning_rate": 5.1628272251308894e-05,
      "loss": 0.8509,
      "step": 15820
    },
    {
      "epoch": 82.87958115183245,
      "grad_norm": 0.00956371147185564,
      "learning_rate": 5.147120418848167e-05,
      "loss": 0.8509,
      "step": 15830
    },
    {
      "epoch": 82.93193717277487,
      "grad_norm": 0.008381906896829605,
      "learning_rate": 5.131413612565445e-05,
      "loss": 0.8509,
      "step": 15840
    },
    {
      "epoch": 82.98429319371728,
      "grad_norm": 0.009080352261662483,
      "learning_rate": 5.1157068062827216e-05,
      "loss": 0.8509,
      "step": 15850
    },
    {
      "epoch": 83.0,
      "eval_accuracy": 0.46771879483500717,
      "eval_loss": 3.635265827178955,
      "eval_runtime": 1.0239,
      "eval_samples_per_second": 1361.455,
      "eval_steps_per_second": 21.486,
      "step": 15853
    },
    {
      "epoch": 83.03664921465969,
      "grad_norm": 0.00733856949955225,
      "learning_rate": 5.1e-05,
      "loss": 0.8509,
      "step": 15860
    },
    {
      "epoch": 83.08900523560209,
      "grad_norm": 0.007911638356745243,
      "learning_rate": 5.084293193717277e-05,
      "loss": 0.8509,
      "step": 15870
    },
    {
      "epoch": 83.1413612565445,
      "grad_norm": 0.008340438827872276,
      "learning_rate": 5.068586387434554e-05,
      "loss": 0.8509,
      "step": 15880
    },
    {
      "epoch": 83.19371727748691,
      "grad_norm": 0.009791175834834576,
      "learning_rate": 5.052879581151832e-05,
      "loss": 0.8509,
      "step": 15890
    },
    {
      "epoch": 83.24607329842932,
      "grad_norm": 0.007855853997170925,
      "learning_rate": 5.037172774869109e-05,
      "loss": 0.8509,
      "step": 15900
    },
    {
      "epoch": 83.29842931937172,
      "grad_norm": 0.008961385115981102,
      "learning_rate": 5.0214659685863875e-05,
      "loss": 0.8509,
      "step": 15910
    },
    {
      "epoch": 83.35078534031413,
      "grad_norm": 0.008347065187990665,
      "learning_rate": 5.0057591623036645e-05,
      "loss": 0.8509,
      "step": 15920
    },
    {
      "epoch": 83.40314136125654,
      "grad_norm": 0.00734245590865612,
      "learning_rate": 4.9900523560209415e-05,
      "loss": 0.8509,
      "step": 15930
    },
    {
      "epoch": 83.45549738219896,
      "grad_norm": 0.008404761552810669,
      "learning_rate": 4.97434554973822e-05,
      "loss": 0.8509,
      "step": 15940
    },
    {
      "epoch": 83.50785340314137,
      "grad_norm": 0.008594995364546776,
      "learning_rate": 4.958638743455497e-05,
      "loss": 0.8509,
      "step": 15950
    },
    {
      "epoch": 83.56020942408377,
      "grad_norm": 0.0074745286256074905,
      "learning_rate": 4.9429319371727744e-05,
      "loss": 0.8509,
      "step": 15960
    },
    {
      "epoch": 83.61256544502618,
      "grad_norm": 0.00810948759317398,
      "learning_rate": 4.927225130890052e-05,
      "loss": 0.8509,
      "step": 15970
    },
    {
      "epoch": 83.66492146596859,
      "grad_norm": 0.007794548291712999,
      "learning_rate": 4.91151832460733e-05,
      "loss": 0.8509,
      "step": 15980
    },
    {
      "epoch": 83.717277486911,
      "grad_norm": 0.007875530049204826,
      "learning_rate": 4.895811518324607e-05,
      "loss": 0.8509,
      "step": 15990
    },
    {
      "epoch": 83.7696335078534,
      "grad_norm": 0.008502216078341007,
      "learning_rate": 4.880104712041884e-05,
      "loss": 0.8509,
      "step": 16000
    },
    {
      "epoch": 83.82198952879581,
      "grad_norm": 0.008477576076984406,
      "learning_rate": 4.864397905759162e-05,
      "loss": 0.8509,
      "step": 16010
    },
    {
      "epoch": 83.87434554973822,
      "grad_norm": 0.007943161763250828,
      "learning_rate": 4.848691099476439e-05,
      "loss": 0.8509,
      "step": 16020
    },
    {
      "epoch": 83.92670157068063,
      "grad_norm": 0.010230641812086105,
      "learning_rate": 4.832984293193717e-05,
      "loss": 0.8509,
      "step": 16030
    },
    {
      "epoch": 83.97905759162303,
      "grad_norm": 0.009923692792654037,
      "learning_rate": 4.817277486910994e-05,
      "loss": 0.8509,
      "step": 16040
    },
    {
      "epoch": 84.0,
      "eval_accuracy": 0.4684361549497848,
      "eval_loss": 3.6404407024383545,
      "eval_runtime": 1.0333,
      "eval_samples_per_second": 1349.138,
      "eval_steps_per_second": 21.292,
      "step": 16044
    }
  ],
  "logging_steps": 10,
  "max_steps": 19100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
